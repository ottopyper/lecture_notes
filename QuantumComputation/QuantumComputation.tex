\documentclass[]{article}


\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{parskip}
\usepackage{xcolor}
\usepackage{pagecolor}
\usepackage[margin=1.2in]{geometry}
\usepackage{enumerate}
\usepackage{enumitem}

\usepackage[utf8]{inputenc}
\usepackage[english]{babel}

\usepackage{mathtools}
\DeclarePairedDelimiter\bra{\langle}{\rvert}
\DeclarePairedDelimiter\ket{\lvert}{\rangle}
\DeclarePairedDelimiterX\braket[2]{\langle}{\rangle}{#1 \delimsize\vert #2}

\definecolor{thmcolour}{rgb}{0,0,0}
\definecolor{defcolour}{rgb}{0,0,0}
\definecolor{textcolour}{rgb}{0,0,0}
\definecolor{backgroundcolour}{rgb}{1,1,1}

\pagecolor{backgroundcolour}
\color{textcolour}

\newtheoremstyle{custhm}
{%space above
	1em
}{%space below
	1em
}{%body font
	\color{thmcolour}\itshape
}{%indent amount
	-0em
}{%head font
	\bfseries\color{thmcolour}
}{%head punct
}{%after head space
	1em
}{%head spec
\thmname{#1}\if\relax\detokenize{#2}\relax: \else\thmnumber{ #2}: \fi\if\relax\detokenize{#3}\relax\else\thmnote{(#3)}\fi
}

\newtheoremstyle{remark}
{%space above
}{%space below
}{% body font
}{%indent amount	-0em
}{%head font
\bfseries
}{%head punct
}{%after head space
0em
}{%head spec
\if\relax\detokenize{#3}\relax\thmname{#1}: \else\thmname{#3}: \fi
}

\newtheoremstyle{cusdef}
{%space above
	1em
}{%space below
	1em
}{%body font
	\color{defcolour}
}{%indent amount
	-0em
}{%head font
	\bfseries\color{defcolour}
}{%head punct
}{%after head space
	1em
}{%head spec
	%if numbered, include number
	%if named, include name
	\thmname{#1}
	\if\relax\detokenize{#2}\relax:
	\else\thmnumber{ #2}:\fi
	\if\relax\detokenize{#3}\relax
	\else\thmnote{ (#3)}\fi
}

\theoremstyle{custhm}
\newtheorem{theorem}{Theorem}[section]
\theoremstyle{cusdef}
\newtheorem{defin}[theorem]{Definition}
\theoremstyle{custhm}
\newtheorem{lemma}[theorem]{Lemma}
\theoremstyle{custhm}
\newtheorem{cor}[theorem]{Corollary}

\theoremstyle{custhm}
\newtheorem{prop}[theorem]{Proposition}

\theoremstyle{custhm}
\newtheorem*{theorem*}{Theorem}

\theoremstyle{cusdef}
\newtheorem*{defin*}{Definition}

\theoremstyle{remark}
\newtheorem*{remark*}{Remark}


%\marginpar{to describe which lecture it is}

\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\e}{\mathrm{e}}
\newcommand{\ra}{\rightarrow}
\newcommand{\lef}{\left(}
\newcommand{\res}{\right)}
\newcommand{\ie}{\textit{i.e. }}
\newcommand{\eps}{\varepsilon}
\newcommand{\E}{\mathbb{E}}
\newcommand{\suminf}{\sum_{n=0}^{\infty}}
\newcommand{\suminfa}[1]{\sum_{#1=0}^{\infty}}
\renewcommand{\P}{\mathbb{P}}
\newcommand{\undf}[1]{\textit{\textbf{#1}}}
\renewcommand{\L}{\mathcal{L}}
\renewcommand{\it}[1]{\textit{#1}}
\newcommand{\M}{\mathcal{M}}
\renewcommand{\phi}{\varphi}
\newcommand{\proves}{\vdash}
\newcommand{\lra}{\leftrightarrow}
\renewcommand{\value}{|\cdot|}
\newcommand{\val}[1]{\left|#1\right|}
\newcommand{\valk}{(K,|\cdot|)}
\renewcommand{\bar}{\overline}
\renewcommand{\O}{\mathcal{O}}
\newcommand{\A}{\mathcal{A}}
\newcommand{\qft}{\textrm{QFT}}

\newcommand{\poly}{\textrm{poly}}
\newcommand{\U}{\mathcal{U}}
\newcommand{\QFT}{\textrm{QFT}}
\newcommand{\per}{\ket{\textrm{per}}}


\renewcommand{\lnot}{\neg}
\newcommand{\false}{\bot}
\newcommand{\true}{\top}
%opening
\title{Quantum Computation}
\author{Lectures by Richard Jozsa}
\date{}

\begin{document}

\maketitle

\tableofcontents
\clearpage
\marginpar{Lecture 1}
\section{Review of Shor's Algorithm}

This result is powered by the \textbf{quantum period finding algorithm}, and will lead us to the \textbf{hidden subgroup problem} (henceforce HSP).

\subsection{Factoring Problem}

Given an integer $N$, with $n = O(\log N)$ digits, we want to find a non-trivial factor in time complexity $O(\textrm{poly}(n))$.

The important concept here is that of \textbf{polynomial time complexity}: any computation has an input, from which we obtain an input \textit{size} $n$. Then by polynomial time complexity, we mean that the number of steps/gates (either classical or quantum) grows only polynomially with $n$ (\textit{i.e.} is $O(\textrm{poly}(n))$).

When we refer to \textbf{efficient} computation, we are always referring to polynomial time complexity.

The best known \textit{classical} factoring algorithm has complexity $\e^{O\lef n^{\frac{1}{3}}(\log n)^{\frac{2}{3}}\res}$. However, the best known quantum algorithm (due to Shor) runs in $O(n^3)$, a considerable improvement.

\subsection{Quantum Factoring Algorithm Summary}

First, we convert factoring into period determination:

Given $N$, choose $a<N$ with $(a,N) = 1$ and consider $f:\Z \ra \Z_N,\ x\mapsto a^x \mod N$. Euler's Theorem tells us that $f$ is periodic, and the period $r$ is the order of $a$ modulo $N$, \ie the least $m > 1$ such that $a^m \equiv 1 \mod N$ - this exists if and only if $a,N$ are coprime. Through knowledge of $r$ we are able to compute a factor of $N$.

While the process of determining $r$ is \textit{mathematically} very simple, it is in fact as difficult to compute from a classical perspective as factoring $N$ itself. Instead we use the \textbf{Quantum algorithm for periodicity determination}.

\textbf{\underline{The task}:} Given an oracle/black box for $f:\Z_M \ra \Z_N$ with promises:
\begin{itemize}
	\item $f$ is periodic, with (unknown) period $r\in \Z_M$, \ie f(x+r) = f(x) for all $x\in \Z_M$.
	\item $f$ is $1-1$ in each period, \ie $f(x_1)\ne f(x_2)$ for any $0\le x_1 < x_2 < r$.
\end{itemize}

We want to find $r$ in time $O(\poly(m)),\ m = \log M$ (with any prescribed success probability $1-\eps,\ \eps > 0$).

\begin{remark*}
	Queries to the oracle count as 1 step. In the quantum context we assume the oracle is a unitary gate $\U_f$ on $\U_M\otimes \U_N$, where $\U_M$ is the state space with dimension $M$, basis $\{ \ket{i} \}_{i\in\Z_M}$. $U_f$ acts on basis states as
	\[
	U_f\underbrace{\ket{i}}_{\textrm{\tiny input}}\underbrace{\ket{j}}_{\textrm{\tiny output}} = \ket{i}\ket{j+f(i)},\qquad i\in\Z_M,\ j\in\Z_M
	\]
	
	The \textbf{Query complexity} of an algorithm is the number of times the oracle is queried, which is also required to be $O(\poly(m))$.
\end{remark*}

To solve the periodicity problem classically, it can be shown that it is both necessary and sufficient to query the oracle $O(\sqrt{N})$ times, so there is no polynomial algorithm. However, there \textit{is} a quantum algorithm.

\subsection{Quantum Algorithm for Periodicity Determination}

For further details \textit{c.f.} Part II notes pp.60-64.

Write $A = M/r = \#$periods. We work in the state space $\U_M\otimes\U_N$ with basis $\{\ket{i}\ket{k}:\ i\in\Z_M,\ k\in\Z_N\}$.

\underline{\textbf{Step 1}}: obtain the state \[ \frac{1}{\sqrt{M}} \sum_{i=0}^{M-1}\ket{i}\ket{0}\]

\underline{\textbf{Step 2}}: apply $U_f$ to obtain \[\frac{1}{\sqrt{M}}\sum_{i=0}^{M-1}\ket{i}\ket{f(i)}\]

\underline{\textbf{Step 3}}: measure the output register, obtaining result $y$. By the \textbf{Born rule}, the input register collapses to all those $i$ such that $f(i) = y$, \ie $i = x_0,\ x_0+r,\cdots,\ x_0+(A-1)r$ where $0\le x_0 < r$ in the first period has $f(x_0) = y$.

We discard the output reigister to obtain \[\ket{\textrm{per}} = \frac{1}{\sqrt{A}}\sum_{j=0}^{A-1}\ket{x_0+jr}\]

Note that each $0\le x_0 < r$ occurs with probability $1/r$.

If we naively measure $\ket{\textrm{per}}$, the Born rule implies we get $x_0 + jr$ with $j = 0,\cdots,A-1$ chosen uniformly with probability $1/A$, \ie a random element of a random period; this is a uniformly random integer in $\Z_M$. This is useless to us. Instead...

\underline{\textbf{Step 4}}: apply \textbf{Quantum Fourier Transform} (QFT).
\marginpar{Lecture 2}
Recall that
\[
\textrm{QFT}\ket{x} = \frac{1}{\sqrt{M}} \sum_{y=0}^{M-1} \omega^{xy} \ket{y}
\]
\begin{remark*}[Fact]
QFT modulo $M$ is unitary, and can be implemented in $O(m^2)$ time, $m = \log M$. See Part II QIC notes for circuit details of implementation.
\end{remark*}

Then
\begin{align*}
	\QFT\ket{\textrm{per}} &= \frac{1}{\sqrt{MA}}\sum_{j=0}^{A-1} \left(\sum_{j=0}^{M-1}\omega^{(x_0+jr)y}\ket{y}\right)\\
	&=\frac{1}{\sqrt{MA}}\sum_{y=0}^{M-1}\omega^{x_0y}\left[\sum_{j=0}^{A-1}\omega^{jry}\right]\ket{y}
\end{align*}
Note that $[\cdots]$ is a geometric series, with ratio $\omega^{ry} = \e^{2\pi iry/M} = \left(\e^{e\pi i/A}\right)^y$. So the sum equals zero unless $y$ is a multiple of $A = M/r$, in which case it every term in the sum is 1 so the sum equals $A$. So the non-multiples of $A$ get sifted out by QFT.

Hence, we have
\begin{align*}
\QFT\ket{\textrm{per}} = \sqrt{\frac{A}{M}}\sum_{k=0}^{r-1}\omega^{x_0kM/r}\ket{k\frac{M}{r}}
\end{align*}
Then measuring $\QFT\ket{\textrm{per}}$ we get a value $c = k_0 M/r$, with $0\le k_0\le r-1$ chosen uniformly at random. Thus we have $k_0/r = c/M$, where the values $c,M$ are known and $k_0$ has been chosen at random; we want $r$. Note that if we are fortunate enough to have $(k_0,r) = 1$, then we can (efficiently) cancel $c/M$ down to its lowest terms, and read off $r$ as the denominator. But in general this will not be the case:

\begin{theorem*}[Coprimality Theorem]
The number of positive integers $<r$ that are coprime to $r$ grows as $O\left(r/\log\log r\right)$ for large $r$.
\end{theorem*}
Hence the above $\P(k_0 \textrm{ coprime to }r = O\left(1/\log\log r\right)$. So if we do it enough times, we will almost surely be successful:
	
\begin{remark*}[Probability Lemma]
If a single trial has success probability $p$, then we repeat $k$ times, and for any $0 < 1 - \eps < 1$, we have that
\begin{align*}
	\textrm{if }&\quad k= -\frac{\log \eps}{p}\\
	\textrm{then }&\quad\P(\ge 1 \textrm{ success in }k \textrm{ trials}) > 1 - \eps
\end{align*}
\end{remark*}
So after finding $c$, cancel $c/M$ down to its lowest terms $a/b$ (classically, in polynomial time using Euclid's algorithm). We get $r$ as denominator $b$ if $(k_0,r) = 1$, which happens with probability $O(1/\log\log r)$, otherwise $c,M$ have more common factors, so $b < r$.

We don't know immediately whether that has happened or not, but we can check the $b$ value by making two more queries to the oracle, $f(0)$ and $f(b)$; these are equal iff $b = r$.

So if we repeat this $K = O(\log\log r)$ times, then we will obtain $r$ with any high probability we desire - and this runs in polynomial time.

\undf{Origin and utility of QFT here}

Write $R = \{0,r,2r,\dots,(A-1)r\}\subset \Z_M$, and
\begin{align*}
\ket{R} &= \frac{1}{\sqrt{A}}\sum_{k=0}^{A-1}\ket{kr}\\
\per = \ket{x_0+R} = \frac{1}{\sqrt{A}}\sum_{k=0}^{A-1}\ket{x_0+kr}
\end{align*}
The problem is that the $\ket{x_0+kr}$ terms are distributed randomly.

For each $x_0\in\Z_M$, consider the map $k\mapsto k+x_0$ on $\Z_M$; this is the 1-1 reversible map ``shift by $x_0$''.

This gives rise to a linear map $U(x_0)$ on $\U_M$, and $U(x_0):\ket{k}\ra\ket{k+x_0}$ is unitary, and $\ket{x_0+R} = U(x_0)\ket{R}$.

Since $(\Z_M,+)$ is an \it{abelian} group, these shift operators all commute, \it{i.e.} $U(x_0)U(x_1) = U(x_0+x_1) = U(x_1)U(x_0)$. So they have an orthonormal basis of common eigenvectors $\{\ket{\chi_k}\}_{k\in\Z_M}$, called the \it{shift-invariant} states. Note that they are not left entirely unchanged by the $U(x_0)$ operators, but they are shifted only by a constant phase factor, \textrm{i.e.} $U(x_0)\ket{\chi_k} = \omega(x_0,k)\ket{\chi_k}$ for all $x_0,k\in\Z_M$, and $|\omega(x_0,k)| = 1$.

Now consider $\ket{R}$ written in the $\chi$-basis
\begin{align*}
\ket{R} = \sum_{k=0}^{M-1}a_k\ket{\chi_k}
\end{align*}
where the amplitudes $a_k$ depend only on $r$, and not on $x_0$ (obviously). Then $\per = U(x_0)\ket{R} = \sum a_k\omega(x_0,k)\ket{\chi_k}$, and measurement in the $\chi$-basis has $\P(k) = |a_k\omega(x_0,k)|^2 = |a_k|^2$, independent of $x_0$, depending only on $r$. So we want to measure in this basis, but aren't allowed to do that (computationally) since the basis is too complicated.

So we introduce QFT as the unitary mapping that rotates the $\chi_k$-basis onto the standard basis $\ket{k}$, and follow this up by a standard basis measurement.

But what does this mapping look like, and where does it come from? We need the explicit form of the shift-invariant eigenstates:
\begin{align*}
	\ket{\chi_k} &= \frac{1}{\sqrt{M}}\sum_{\ell = 0}^{M-1}\e^{-2\pi ik\ell/M}\ket{\ell}\\
	\implies \U(x_0)\ket{\chi_k} &= \frac{1}{\sqrt{M}}\sum_{\ell = 0}^{M-1}\e^{-2\pi ik\ell/M}\ket{\ell + x_0}\\
	&= \frac{1}{\sqrt{M}}\sum_{\tilde{\ell} = 0}^{M-1}\e^{-2\pi i k(\tilde{\ell} - x_0)}\ket{\tilde{\ell}}\\
	&= \e^{2\pi i kx_0/M}\ket{\chi_k}
\end{align*}
So $\omega(x_0,k) = \e^{2\pi i k x_0/M}$.

The matrix of $\QFT^{-1}$ (mapping $\ket{k}$ to $\ket{\chi_k}$) has components of $\ket{\chi_k}$ as the $k^{\textrm{th}}$ column, so $[\QFT^{-1}]_{\ell k} = \frac{1}{\sqrt{M}}\e^{-2\pi i\ell k/M}$. Since QFT is unitary, to find the inverse we need only take the conjugate transpose.

Hence $[QFT]_{k\ell} = \frac{1}{\sqrt{M}}\e^{2\pi ik\ell/M}$, as previously defined.

This notion of QFT in fact occurs very naturally in group theory as the \it{discrete Fourier transform}. The fact that this QFT is unitary means that all the group theoretic results it relies on slot in perfectly, allowing us to make as much use of this as we want in a way that we are not able classically.

\marginpar{Lecture 3}

The following algorithm was inspired by a desire to generalise the successful technique of Shor's celebrated algorithm.

\section{The Hidden Subgroup Problem (HSP)}

Let $G$ be a finite group, of size $|G|$.

We are given an oracle $f : G\ra X$ (where $X$ is some set), and a promise that there is a subgroup $K < G$ such that
\begin{itemize}
	\item $f$ is constant on (left) cosets of $K$ in $G$
	\item $f$ is distinct on distinct cosets.
\end{itemize}
\begin{remark*}[Problem]
Determine the ``hidden subgroup'' $K$.

For instance, this might entail outputting a set of generators, or we might be happy enough with just sampling uniformly from the elements of $K$.

$\ast$ we want to solve this in time $O(\poly\log|G|)$, with any constant probability $1 - \eps$.
\end{remark*}
\begin{remark*}[Examples of problems that can be seen as HSPs]\ 
\begin{enumerate}[label = (\alph*)]
	\item \underline{Periodicity}. $f:\Z_M \ra X$ periodic, period $r$, bijective within periods.
	
	Then let $G = \Z_M$, $K = \{0,r,2r,\dots\} < G$, and the cosets are $x_0 + K = \{x_0,x_0+r,x_0+2r\dots\}$. It is then clear that $f$ is constant/distinct on the cosets in the desired way.
	
	\item \underline{Discrete Logarithms}: this was also solved by Shor in his original paper.
	
	Take $p$ prime, and consider $\Z_p^\ast$ the group of units modulo $p$ = $\{1,2,\dots,p-1\}$. We say that $g\in \Z_p^\ast$ is a \it{generator}, or a \it{primitive root modulo} $p$, if the powers of $g$ generate all of $\Z_p^\ast$.
	
	\underline{Fact}: generators always exist, \it{i.e.} $\Z_p^\ast$ is always cyclic. For instance, $2,3$ both generate $\Z_5^\ast$ - though $1,4$ do not.
	
	So any $x\in \Z^\ast_p$ can be written as $x = g^y$ for $y \in \Z_{p-1}$. We thus write $y = \log_g x$ for the \undf{discrete logarithm} of $x$, to base $g$.
	
	The discrete log problem is then: given a generator $g$ and $x\in \Z^\ast p$, compute $y = \log_g x$. This is very difficult classically, and it underpins public key cryptography.
	
	To express this as a hidden subgroup problem, consider $f:\Z_{p-1}\times\Z_{p-1}\ra\Z_p^\ast$ by $f(a,b) = g^ax^{-b} = g^{a-yb} \mod p$. Then (\it{check}) $f(a_1,b_1) = f(a_2,b_2)$ iff $(a_2,b_2) = (a_1,b_1)+\lambda (y,1),\ \lambda \in \Z_{p-1}$.
	
	So we let $G = \Z_{p-1}\times\Z_{p-1}$, and $K = \{\lambda(y,1):\lambda \in \Z_{p-1}\} < G$. Then $f$ is constant/distinct as appropriate on the cosets of $K$, and the generator $(y,1)$ of $K$ gives $y = \log_g x$.
	
	\item \underline{Graph Problems}.
	
	Consider a graph $A = (V,E)$, $|V| = n$. We stipulate that these are undirected, that there is at most one edge between any pair of vertices, and that the vertices are labelled by $[n] = \{1,2,\dots,n\}$. We also might be interested in the adjacency matrix $M_A$, the $n\times n$ matrix given by $[M_A]_{ij} = \mathbb{I}[\{i,j\}\in E]$, which is always symmetric for an undirected graph.
	
	The group that will be of interest to us is $P_n \coloneqq$ the permutation group of $[n]$. So $|P_n| = n! \sim \sqrt{2\pi n}(n/e)^n$ has $|P_n|\sim O(n\log n) < O(n^2)$, which is polynomial in the number of vertices. This is what we want for the running time of a graph algorithm.
	
	The subgroup of interest is $\textrm{Aut}(A)$, the \undf{automorphism group} of $A < P_n$ the set of permutations $\pi \in P_n$ such that for all $i,j$, $\{i,j\}\in E$ iff $\{\pi(i),\pi(j)\}\in E$. What this means is that after permuting the labels of the graph, we are left with the same labelled graph.
	
	An associated HSP (non-abelian $G$):
	
	Take $G = P_n$, and $X = $ the set of all labelled graphs on $n$ vertices (equivalent to the set of all symmetric $n\times n$ 0/1-matrices).
	
	For any $A\in X$, we consider $f_A : G\ra X$, with $f_A(\pi) = \pi(A)$, \it{i.e.} the graph $A$ with its vertex labels permuted by $\pi$. A little bit of thought shows that $K = \textrm{Aut}(A)$ is the hidden subgroup for this problem; $f_A$ is constant on the automorphisms of $A$, for instance.
	
	An important application of this is that if we can sample uniformly from $K$, then we can solve the \undf{Graph Isomorphism Problem} (GI), which has received a lot of attention in complexity theory in recent years.
	
	Two labelled graphs $A,B$ each on $n$ vertices are \undf{isomorphic} if there is a bijective map (permutation) on the labels $\pi :[n]\ra[n]$ such that for all $i,j\in [n]$, $\{i,j\}\in A$ iff $\{\pi(i),\pi(j)\}\in B$. In other words, $A$,$B$ are the same underlying graph (\it{i.e.} ignoring their labels they are indistinguishable). We write $A\cong B$.
	
	The GI Problem is then: given graphs $A$ and $B$, determine whether or not they are isomorphic. This has many useful applications; \it{e.g.} if you can see some proteins and their structure, you may want to be able to tell which proteins are actually the same.
	
	This can again be expressed as a non-abelian HSP, \it{c.f.} Sheet 1.
	
	There is no known polynomial time classical algorithm, and in fact there is no known polynomial time quantum algorithm either. The problem is in NP, but is \it{not} believed to be NP-complete. A problem is NP if it is, roughly speaking, difficult to solve but easy to validate that you have the right answer once you've solved it. A problem is NP-complete if you can rephrase any other NP problem as this one, and then solve it that way - so solving an NP-complete problem solves all NP problems; it is the hardest problem in NP.
	
	We currently do not believe that even quantum algorithms are able to solve NP-complete problems efficiently, so it is in some sense hopeless to try and work on these problems even from a quantum perspective. However, they can do NP-incomplete problems, so factoring and GI \it{etc}... are good candidates to attempt.
	
	Laslo Babai (2017) found a \it{quasi}-polynomial time \it{classical} algorithm for GI; it has runtime $n^{O((\log n)^2)}$. This is slower than polynomial time, but faster than exponential time. We have the following hierarchy:
	
	\begin{align*}
		\poly (n) < n^{O((\log n)^2)} < \textrm{exp}\\
		2^{O(\log n)} < 2^O((\log n)^3) < 2^{O(n)}
	\end{align*}

So in terms of exponents, these are linear/polynomial/exponential in $\log n$.
\item Another non-abelian example is the \undf{dihedral group}; there is a connection to the HSP `shortest vector in a lattice'. We are given $n$ linearly independent vectors in $\R^n$, and consider their lattice; the problem is to find the lattice point closest to the origin.
\end{enumerate}
\end{remark*}

\marginpar{Lecture 4}

What we {\it do} have is:

\section*{Quantum Algorithm for Finite Abelian HSP}

We write the group $(G,+)$, additively. We need a couple of components:

\subsection*{Construction of shift invariant states \& Fourier transform for $G$}
\begin{defin*}[Representation of $G$]
A group homomorphism $\chi :G\ra\C^\ast = (\C\backslash\{0\},\cdot)$ is called a \undf{representation} of $G$.

For abelian groups, any such map is called an \undf{irreducible representation} (henceforth {\it irrep}) of $G$.
\end{defin*}

These have the following properties:

\begin{theorem*}[Theorem A]\ 
\begin{enumerate}[label=(\roman*)]
	\item any value $\chi(g)$ is a $|G|^{\textrm{th}}$ root of unity (so $\chi : G\ra S^1$, the unit circle in $\C$)
	\item (Schur's Lemma/Orthogonality) If $\chi_i$ and $\chi_j$ are representations, then
	\begin{align*}
		\frac{1}{|G|} \sum_{g\in G} \chi_i(g)\overline{\chi_j(g)} = \delta_{ij}
	\end{align*}
	\item There are exactly $|G|$ different representations of $G$.
\end{enumerate}
\end{theorem*}

By (iii) we can label the $\chi$'s as $\chi_g: g\in G$.

\begin{remark*}[Example]
$\chi(g) = 1$ for all $g\in G$ is always an irrep, called the \undf{trivial} irrep; label it as $\chi_0$ for $0\in G$.

Then for any other irrep $\chi\ne \chi_0$, orthogonality to $\chi_0$ gives
\begin{align*}
	\sum_{g\in G}\chi(g) = 0
\end{align*}
\end{remark*}

We now introduce:

\begin{defin*}[Shift-Invariant States, Shift Operators]
Consider the state sapce $\mathcal{H}_G$, dimension $|G|$, basis $\ket{g}:g\in G$.

The \undf{shift operators} are
\begin{align*}
	U(k) : \ket{g} \mapsto \ket{g+k},\ \ k,g\in G
\end{align*}
These all commute, so we have a simultaneous eigenbasis:

For each $\chi_k$, $k\in G$, consider the state
\begin{align*}
\ket{\chi_k} = \frac{1}{\sqrt{|G|}}\sum_{g\in G}\overline{\chi_k(g)}\ket{g}
\end{align*}

By Theorem A (ii), these form an orthonormal basis, and it follow from the group homomorphism property of irreps that these are in fact the simultaneous eigenbasis, $U(g)\ket{\chi_k} = \chi_k(g)\ket{\chi_k}$. These are the \undf{shift-invariant states}.
\end{defin*}
\begin{proof}
We have that
\begin{align*}
U(g)\ket{\chi_k} &= \frac{1}{\sqrt{|G|}}\sum_{h\in G}\overline{\chi_k}(h)\ket{g+h}\\
&= \frac{1}{\sqrt{|G|}}\sum_{h'\in G}\overline{\chi_k}(h'-g)\ket{h'}\\
&= \frac{1}{\sqrt{|G|}}\chi_k(g)\sum_{h'\in G}\overline{\chi_k}(h')\ket{h'}\\
&= \chi_k(g)\ket{\chi_k}
\end{align*}
Which follows since $\chi_k(g^{-1}) = \overline{\chi_k}(g)$.
\end{proof}
\begin{defin*}[Fourier Transform QFT]
The unitary gate on $\mathcal{H}_G$ mapping $\ket{\chi_g}$ basis to the $\ket{g}$ basis is known as the \undf{Quantum Fourier Transform (QFT)} {\it i.e.}
\begin{align*}
\qft\ket{\chi_g} &= \ket{g},\ \forall g\in G\\
\qft^{-1}\ket{g} &= \ket{\chi_g}
\end{align*}
In particular, the $k^{\textrm{th}}$ column of $\qft^{-1}$ in $\ket{g}$-basis is given by components of $\ket{\chi_k}$, {\it i.e.}
\begin{align*}
	\left[\qft^{-1}\right]_{gk} = \frac{1}{\sqrt{|G|}}\overline{\chi_k}(g)\ \ \forall g,k\in G
\end{align*}
so $QFT$ (as the conjugate transpose) has the matrix
\begin{align*}
\left[\qft\right]_{kg} &= \frac{1}{\sqrt{|G|}}\chi_k(g)\\
\implies \qft\ket{g} &= \frac{1}{\sqrt{|G|}}\sum_{k\in G}\chi_k(g)\ket{k}
\end{align*}
\end{defin*}
\begin{remark*}[Examples] $G = \Z_M$
Check $\chi_a(b) = \e^{2\pi i ab/M}$ for all $a,b\in \Z_M$ satisfies (Hom), so we have irreps naturally labelled by $a\in \Z_M$, $\chi_0(b) = 1$ for all $b$, giving the `usual' $\qft_M$ for $\Z_M$.

Similarly for $G = \Z_{M_1}\times\dots\times\Z_{M_r}$, where we have
\begin{align*}
\left.\begin{array}{c} (a_1,\dots,a_r) = g_1 \\ (b_1,\dots,b_r) = g_2\end{array}\right\rbrace \in G\\
\chi_{g_1}(g_2) \coloneqq \e^{2\pi i\left( \frac{a_1b_1}{M_1}+\dots+\frac{a_rb_r}{M_r}  \right)}
\end{align*}
which satisfies (Hom), and we get
\begin{align*}
\qft_G = \qft_{M_1}\otimes \cdots \otimes \qft_{M_r}
\end{align*}
\end{remark*}

Importantly, the above is exhaustive due to the classification of all finite abelian groups, which states that they are all isomorphic to a direct product $G\cong \Z_{M_1}\otimes\cdots\otimes\Z_{M_r}$, and furthermore we can take all the $M_i$'s to be (not necessarily distinct) prime powers. 

\subsection*{Quantum Algorithm for Finite Abelian HSP}

We have $f: G\ra X$, hidden subgroup $K$, cosets $K = 0 + K, g_2 + K,\dots,g_m+ K$, where $m = |G|/|K|$ is the number of cosets.

This works on the state space $\mathcal{H}_{|G|}\otimes\mathcal{H}_{|X|}$, with basis $\ket{g}\ket{x}$ for $g\in G$, $x\in X$.

\begin{itemize}
	\item Make the initial state
	\begin{align*}
		\frac{1}{\sqrt{|G|}}\sum_{g\in G} \ket{g}\ket{0}
	\end{align*}
	\item Apply $\mathcal{U}_f$, to obtain
	\begin{align*}
		\frac{1}{\sqrt{|G|}}\sum_{g\in G}\ket{g}\ket{f(g_0)}
	\end{align*}
	\item Measure the second register to see a value $f(g_0)$. Then the first register will give a coset state:
	\begin{align*}
		\ket{g_0 + K} = \frac{1}{\sqrt{|K|}} \sum_{k\in K}\ket{g_0 + k} = U(g_0)\ket{K}
	\end{align*}
	Where we are writing $\ket{K} = \frac{1}{\sqrt{|K|}}\sum_{k\in K}\ket{k}$.
	
	Here the coset has been chosen uniformly at random from all $|G|/|K|$ cosets.
	
	\item Apply $\qft$ and measure, to obtain a result $g\in G$.
	
	How does the output $g$ relate to $K$? Observe that
	\begin{itemize}
		\item The output distribution of $g$ is {\it independent} of $g_0$, so it is the same as that obtained from $\qft\ket{K}$, ({\it i.e.} $g_0 = 0$).
		
		This is since if we write $\ket{K}$ in the shift-invariant basis basis $\ket{\chi_g}$, $\ket{K} = \sum_{g\in G}a_g \ket{\chi_g}$, then $\ket{g_0+K} = U(g_0)\ket{K} = \sum a_g\chi_g(g_0)\ket{\chi_g}$. But $\qft \ket{\chi_g} = \ket{g}$, so after $\qft$ we have that $\P[g] = |a_g\chi_g(g_0)|^2 = |a_g|^2$ as $|\chi_g(g_0)| = 1$. Hence we have independence of $g_0$.
		
		But what is the distribution?
		
		\item How does it relate to $K$?
		\marginpar{Lecture 5}
		
		Recall that $$\qft\ket{k} = \frac{1}{\sqrt{|G|}} \sum_{\ell \in G} \chi_{\ell}(k)\ket{\ell}$$
		
		In particular
		\begin{align*}
			\qft\ket{K} = \frac{1}{\sqrt{|G|}} \frac{1}{\sqrt{K}} \sum_{\ell \in G} \left[\sum_{k\in K}\chi_{\ell}(k)\right] \ket{\ell}
		\end{align*}
	where $[\cdots]$ invovles irreps $\chi_\ell$ of $G$ restricted to $K < G$, which are irreps of $K$. Hence
	\begin{align*}
		[\cdots] = \left\lbrace \begin{array}{cc} |K|&\quad \textrm{ if }\chi_{\ell}\textrm{ restricts to trivial irrep on }$K$ \\ 0&\quad \textrm{ otherwise}\end{array}  \right.
	\end{align*}
So the measurement gives a uniformly random choice of $\ell$, such that $\chi_{\ell}(k) = 1$ for all $k \in K$, giving information about $K$.

	For instance, if $K$ has generators $k_1,\dots,k_M$, where $M = O(\log |K|) = O(\log |G|)$ (this is true for all finite groups), then the output has $\chi_{\ell}(k_i) = 1$ for all $i$.
	
	It can be shown that if $O(\log |G|)$ such $\ell$s are chosen uniformly at random, then with probability $> 2/3$ they suffice to determine the generating set via the equation $\chi_{\ell}(k) = 1$.
	
	See Sheet 1 \# 2 for an example of this problem and calculation.
	\end{itemize}
\end{itemize}

A trivial but nonetheless useful fact about irreps of $G$ is that they restrict to irreps of $K$, and in fact we could have a trivial irrep of $G$ that restricts to the trivial irrep of $K$ - as we saw above.

\begin{remark*}[Example]\
If $G = \Z_{M_1}\times\cdots\times \Z_{M_q}$, we had for $\ell = (\ell_1,\dots,\ell_q), g\in (b_1,\dots,b_q)\in G$ irreps $$\chi_{\ell}(g) = \e^{2\pi i\sum_{j=1}^{q}\left(\frac{\ell_j b_j}{m_j}\right)}$$

So for $k = (k_1,\dots,k_q)\in K$, the equation $\chi_{\ell}(k) = 1$ becomes
\[
\frac{\ell_1 k_1}{m_1} +\dots + \frac{\ell_q k_q}{m_q} \equiv 0\mod 1
\]
- that is to say, it is an integer. This is a homogeneous, linear equation in $k = (k_1,\dots,k_q)$ and $O(\log |K|)$ independent such equations determine $K$ as the null space of the linear system.
\end{remark*}

\begin{remark*}[Remarks on HSP for {\it non}-abelian groups $G$]
Disclaimer: there is no known efficient algorithm for this problem.

As before, we can easily generate coset states
\[
\ket{g_0 K} = \frac{1}{\sqrt{|K|}} \sum_{k \in K}\ket{g_0 k}
\]
where the $g_0$ are chosen randomly. But there arise new problems with the QFT construction. In particular, there is no basis of shift invariant states because the shift operators do not commute.

So if we apply the Fourier transform to the above state, it no longer works. We can make partial progress though.

\textbf{Construction of non-abelian FT}

Suppose we have $d$-dimensional representations of $G$, which are group homomorphisms
\[
\chi : G \ra U(d)
\]
where the $U(d)$ are $d\times d$ unitary matrices. So $\chi(g_1 g_2) = \chi(g_1)\cdot \chi(g_2)$, where $\cdot$ denotes matrix multiplication.

We then say $\chi$ is \undf{irreducible} (so an irrep) if no subspace of $\C^d$ is left invariant by all matrices $\chi(g): g\in G$. In other words, we cannot simultaneously block diagonalise all the $\chi(g)$s by a basis change.

Looking back at the abelian case, we can consider the irreps as matrices also, but since all the matrices commute with each other they can all be simultaneously block diagonalised, and reduce to 1-dimensional representations.

A \undf{complete set} of irreps is a set $\chi_1,\dots,\chi_M$ such that any irrep is unitarily equivalent to one of them, by which we mean $\chi \equiv \chi'$ if $\chi' = V\chi V^{-1}$ for some $V \in U(d)$.

\begin{theorem*}[Non-Abelian Generalisation of Theorem A]
If $d_1,\dots,d_M$ are the dimensions of a complete set of irreps $\chi_1,\dots,\chi_M$, then
\begin{enumerate}[label = (\roman*)]
	\item $d_1^2 +\dots + d_m^2 = |G|$
	\item Write $\chi_{i,jk}(g)$ for the $(j,k)^{\textrm{th}}$ entry of matrix $\chi_i(g)$. Then we have (Schur's orthogonality)
	\[
	\sum_{g\in G} \chi_{i,jk}(g)\bar{\chi}_{i',j'k'}(g) = |G| \delta_{ii'}\delta_{jj'}\delta{kk'}
	\]
\end{enumerate}
\end{theorem*}
Hence the states
\[
\ket{\chi_{i,jk}} \equiv \frac{1}{\sqrt{|G|}} \sum_{g\in G}\bar{\chi}_{i,jk}(g)\ket{g}
\]
form an orthonormal basis.

$\qft$ on $G$ is then defined as the unitary map that rotates the $\{\ket{\chi_{i,jk}}\}$ basis into the standard basis $\{\ket{g}\}$.

But the $\ket{\chi_{i,jk}}$ are \undf{not} shift invariant for all $U(g_0)$s, so measurement of the coset state $\ket{g_0 K}$ in the $\ket{\chi}$ basis has output distribution that is \undf{not} independent of $g_0$.

However, a `partial' shift invariance survives. Instead of performing a complete measurement, we can do an incomplete measurement on only the $i$ labels and not the $j$.

We call this measurement $M_{\textrm{rep}}$ on $\ket{g_0 K}$ that distinguishes only irrep labels ($i$ values) and \undf{not} all $(i,j,k)$s, {\it i.e.} the measurement outcome $i$ is associated to the $d_i^2$-dimensional subspace spanned by $\{\ket{\chi_{i,jk}}\}_{j,k=1,\dots,d_i}$.

Then it can be shown that $\chi_i(g_1g_2) = \chi_i(g_1)\chi_i(g_2)$ implies that the output distribution of the $i$-values is independent of $g_0$. This gives direct, but incomplete information about $K$.

For instance, conjugate subgroups $K$ and $L = g_0 Kg_0^{-1}$ for some $g_0 \in G$ give the same output distribution of $i$s.


For efficient HSP algorithm (if we use $\qft$), we need $\qft$ to be efficiently implementable, {\it i.e.} in $\poly(\log|G|)$ times - this is unusual, and a very special thing to ask for.

This is true for abelian groups, and some non-abelian groups, such as $P_n$ - but even for this group there is still no known efficient hidden subgroup algorithm.

Consider $\Z_{2^n}$; we have a tower of subgroups $\{0\} < \Z_2 < \Z_4 <\dots < \Z_{2^n}$, and the fast Fourier transform on this group works recursively by determining the transform on the next subgroup using the previous one. There is a similar construction $\{e\}<P_2 <\dots < P_n$. However, there is still no efficient $HSP$ algorithm known.

\textbf{Known partial results}:

For normal subgroups ({\it i.e.} $gK = Kg$ for all $g\in G$), we have
\begin{theorem*}[Hallgren, Russell, Tashina SIAMJ. Comp\_ vol32 p916-934 (2003)]\ 

Suppose $G$ has $\qft$ efficiently implementable. Then if the hidden subgroup $K$ is a normal subgroup, then there is an efficient quantum HSP algorithm.
\end{theorem*}

In particular, we find $\{\ket{g_0 K}\}$ and do $M_{\textrm{rep}}$ on it, and repeat $O(\log |G|)$ times. Then $K$ normal implies the outputs suffice to efficiently determine $K$.

\begin{theorem*}[Effinger, Heyer, Krull, 2004]
For general non-abelian HSP, $M = O(\poly \log |G|)$ random coset states $\ket{g_1 K},\dots,\ket{g_M K}$ suffice to determine $K$.
\end{theorem*}
 In particular, there is always efficient {\it query} complexity. Unfortunately, there is no known method to efficiently determine $K$ from the $M$ coset states (see Sheet 1 \# 7 for a proof of this theorem).
 
 The way we do this is to use a measurement procedure on $\ket{g_1K}\otimes \dots\otimes \ket{g_M K}$ that takes exponential time in $\log |G|$ to complete.
\end{remark*}
\marginpar{Lecture 6}

\section{Quantum Phase Estimation (PE) Algorithm}

This is a unifying principle for quantum algorithms, and again uses $\qft$. It has many applications, {\it e.g.} an alternative factoring algorithm to Shor's algorithm, due to A. Kitaev (Sheet 2 \#2).

\underline{Scenario}: we are given a unitary operator in $d$ dimensions, and an eigenstate $\ket{v_\phi}:U\ket{v_{\phi}} = \e^{2\pi i \phi}\ket{v_\phi}$. We want to estimate $\phi$, with $0 < \phi < 1$, to $n$ binary bits of precision. In particular we have $\phi = 0.i_1i_2\dots i_n\dots$ in binary, and we want to determine $i_1,\dots,i_n$ for any given $n$.

We will need the \undf{controlled-$U^k$} for integers $k$:
\begin{align*}
CU^k\ket{0}\ket{\xi} &= \ket{0}\ket{\xi}\\
CU^k\ket{1}\ket{\xi} &= \ket{1}(u\ket{\xi})\\
\end{align*}

Note also that $U^k\ket{v_\phi} = \e^{2\pi i k\phi}\ket{v_\phi}$, and $C(U^k) = (CU)^k$.

\begin{remark*}
Given $U$ as a formula or circuit description, we can readily implement $CU$ {\it e.g.} by controlling each gate of the circuit.

But if $U$ is given as a black box ({\it i.e.} physical operation) then we need further information in order to implement $CU$.

We can see this since $U$ as a black box is equivalent to $\e^{i\theta}U$ as a black box, but the controlled versions of these gates are different, since the $C$-$(\e^{i\theta}U)$ gate will switch global phase on $\ket{0} + \ket{1}$ to a local phase.

It in fact suffices to have an eigenstate $\ket{\alpha}$ with known/specified eigenvalue $\e^{i\alpha}: U\ket{\alpha} = \e^{i\alpha}\ket{\alpha}$. Then $\e^{i\theta}U$ has $\alpha \mapsto \alpha + \theta$.
\end{remark*}


We will actually want a ``generalised controlled-$U$'', given for $x \in \Z_n$:
\begin{align*}
	{\ket{x}}\ket{\chi} \mapsto U^x\ket{\chi}
\end{align*}
We can make it from $cU^k$ as follows. For $x = x_{n-1}\dots x_1x_0$ in binary... [diagram].

If input $\ket{\chi} = \ket{v_\phi}$, then we get $\e^{2\pi i\phi x}\ket{x}\ket{v_\phi}$.


\begin{theorem*}[PE]
If the measurements give output $\theta = 0.y_0y_1\dots y_{n-1}$, with $\phi = 0.z_0,\dots,z_{n-1}z_{n}\dots$ then
\begin{enumerate}[label=(\alph*)]
	\item $\P(\theta$ is closest $n$ binary digit approx to $\phi) \ge 4/\pi^2 \approx 0.4$
	\item $\P(|\theta - \phi| \ge \eps)$ is at most $O(1/2^n\eps)$, and we will show it is in fact $\le 1/2^{n+1}\eps$.
\end{enumerate}
\end{theorem*}

\begin{remark*}
In Theorem PE (a), we have probability $4/\pi^2$ that {\it all} $n$ lines of $n$-line PE process give correct bits.

But: if we want $\phi$ accurate to $m$ bits with probability $1 - \eta$, then use Theorem PE (b) with $\eps = 1/2^m$. Then we'll need $n > m$ lines with $\eta = 1/2^{n+1}\eps$ and $\eps = 1/2^m$, {\it i.e.} $n = m + \log (1/\eta) -1$, where $n$ is the number of lines in the PE algorithm, $m$ is the number of bits we want with high probability, and $\log(1/\eta) -1 $ is the number of additional bits we require to ensure this accuracy.
\end{remark*}

\marginpar{Lecture 7}

\begin{proof}
	Recall that we have
	\begin{align*}
		\qft^{-1}\ket{x} = \frac{1}{\sqrt{2^n}} \sum_{y=0}^{2^n-1}\e^{-2\pi i yx/2^n}\ket{y}
	\end{align*}
	
	So for the state $\ket{A}$ used earlier, we have
	\begin{align*}
		\qft^{-1}\ket{A} = \frac{1}{2^n} \sum_{y}\left[ \e^{2\pi i (\phi - y/2^n)x}\right]\ket{y}
	\end{align*}
	So for the measurement, the probability that we see the $n$-bit integer $y = y_0y_1\dots y_{n-1}$ is
	\begin{align*}
		\frac{1}{2^{2n}}\left|\sum_{x=0}^{2^n-1}\e^{2\pi i (\phi - y/2^n)x}\right|^2
	\end{align*}
	Letting $\delta(y)\coloneqq \phi - y/2^n)$, we see that we have a geometric series with ratio $\e^{2\pi i\delta(y)}$, solve
	\begin{align*}
		\P[\textrm{see }y] = \frac{1}{2^{2n}}\left| \frac{1-\e^{2^n\cdot 2\pi i \delta(y)}}{1 - \e^{2\pi i \delta(y)}} \right|^2
	\end{align*}
	We now aim to bound/estimate this expression, which we do by bounding the numerator/denominator appropriately. Note that:
	\begin{enumerate}[label=(\roman*)]
		\item $|1 - \e^{i\alpha}| = |2\sin(\alpha/2)| \ge \frac{2}{\pi}|\alpha|$ for $|\alpha| < \pi$
		\item $|1 - \e^{i\beta}| \le \beta$, by comparing the length of the chord and the arc between $1$ and $\e^{i\beta}$ on the unit circle
	\end{enumerate}

	So for (a), in the probability equation we use (i) with $\alpha = 2^n\cdot 2\pi \delta(a) < 2^n\cdot 2\pi/2^{n+1} < \pi$, and so $|1 - \e^{i\alpha}| \ge \frac{2}{\pi}|\alpha| = 2^{n+2}\delta(a)$, where $a$ is the closest $n$-bit string, so its distance from $\phi$ is small.

	Then we use (ii) with $\beta = 2\pi\delta(a)$ to upper bound the bottom line, and hence
	\begin{align*}
		\P[\textrm{see }a] \ge \frac{1}{2^{2n}}\left(\frac{2^{n+2}\delta(a)}{2\pi \delta(a)}\right) = \frac{4}{\pi^2}
	\end{align*}

	For (b), we upper bound the probability equation and sum over all $y$ such that $|\delta(y)| > \eps$.

	For the top line, we use that $|1 - \e^{i\alpha}| \le 2$ for any $\alpha$ (trivially), and for the bottom line we use (i), so $|1 - \e^{2\pi i\delta(y)}| \ge 4\delta(y)$. Hence
	\begin{align*}
		\P[y] \le \frac{1}{2^{2n}}\left(\frac{2}{4\delta(y)}\right)^2 = \frac{1}{2^{2n+2}\delta(y)^2}
	\end{align*}
	Now we sum over all $y$ such that $|\delta(y)| > \eps$; the $\delta(y)$ values are separated by $1/2^n$s, so let $\delta_+$ (resp. $\delta_-$) be the first $\delta(y)$ with $\delta(y)\ge \eps$ (resp. $\delta(y)\le -\eps$). So $|\delta_+|,|\delta_-|\ge \eps$.

	Then if $|\delta(y)| \ge \eps$ we have $|delta(y) = \delta_+ + \frac{k}{2^n}$, $k = 0,1,\dots$ or $=\delta_- - \frac{k}{2^n}$, $k = 0,1,\dots$. So $|\delta(y)|\ge \eps +\frac{k}{2^n}$, $k = 0,1,dots$ in each case.

	So
	\begin{align*}
		\P[|\delta(y)| \ge \eps] &\le 2\sum_{k=0}^{\infty}\frac{1}{2^{2n+2}}\frac{1}{(\eps+\frac{k}{2^{n}})^2}\\
		&\le \frac{1}{2}\int_{0}^{\infty}\frac{1}{2^n\eps + k)^2}\textrm{d}k\\
		&=\frac{1}{2}\int_{2^n\eps}^{\infty}\frac{\textrm{d}k}{k^2} = \frac{1}{2^{n+1}\eps}
	\end{align*}
\end{proof}

This is an extremely useful theorem, and we will see it in various places.

\begin{remark*}[Further Remarks on use of PE]\ 
	\begin{enumerate}
		\item If $C-U^{2^k}$ is implemented as $(C-U)^{2^k}$ then the PE algorithm needs exponential time in $n$, via $1 + 2 +\dots + 2^{n-1} = 2^{n}-1$ $C-U$ gates.
		
		But for some special $U$s, $U^{2^k}$ and $C-U^{2^k}$ can be implemented in $\poly(k)$ time, so we get the polynomial time PE algorithm. For instance, we can use repeated squaring to calculate exponents efficiently.

		This leads to an alternative factoring algorithm (more generally, order-finding or periodicity algorithm) due to Kitaev using PE.

		\item If instead of $\ket{v_\phi}$ we use general $d$-dimensional input state $\ket{\xi}$, what happens? Since we know what happens on eigenstates, and these form a basis, we have that
		\begin{align*}
			\ket{xi} &= \sum_{j}c_j\ket{v_{\phi_j}}\\
			U\ket{v_{\phi_j}} &= \e^{2\pi \phi_j}\ket{v_{\phi_j}}
		\end{align*}
		We then get (before the final measurement) a unitary process:
		\begin{align*}
			\ket{0\dots 0}\ket{\xi} \xrightarrow{U_{\textrm{PE}}} \sum_{j}c_j\ket{\phi_j}\ket{v_{\phi_j}}
		\end{align*}
		and the Born rule implies the final measurement gives a choice of one of the $\phi_j$s, chosen with probability $|c_j|^2$. In particular, you don't get an arbitrary average of the $\phi_j$s, you can precisely one of them (at random), which is still useful information.

		This works perfectly if $\phi_j$s have at most $n$ digits, the number of lines in the PE algorithm. Otherwise with $m$ lines and general $\phi_j$s we get a precision issue (usually swept under the rug); more precisely:

		Using Theorem PE(b), if we want $m$ bits correct with probability $1 - \eta$, we use $n = m + o(\log 1/\eta)$ lines, and $U_{\textrm{PE}}$ acts as above with $\ket{\phi_j}$ registers replaced by
		\begin{align*}
			(\sqrt{1-\eta})\ket{\tilde{\phi}_j}+\sqrt{\eta}\ket{\textrm{perp}}
		\end{align*}
		with $\ket{\textrm{perp}}\perp \ket{\tilde{\phi}_j}$, where $\ket{\tilde{\phi}_j}$ are all $n$ bit strings with the first $m$ bits correct for $\phi$, and $\ket{perp}$ all $n$ bit strings with the first $m$ not correct. Measurement will then give $\tilde{\phi}_j$ value with $m$ correct bits with probability $|c_j|^2(1-\eta)$.

		We often ignore this prceision issue, since we can make $\eta$ very, very small with modest $o(\log 1/\eta)$ overhead. The final state is $\eta$-close to state giving $\phi$ perfectly.
	\end{enumerate}

\end{remark*}

\section*{Amplitude Amplification}

	This is the apotheosis of technique in Grover's algorithm.

	\underline{Some background}:

	\begin{remark*}[Reflection operation] Recall:
		\begin{itemize}
			\item state $\ket{\alpha}$ in $\mathcal{H}_d$ gives a $1$-dim subspace $L_\alpha$, and $(d-1)$-dime orthogonal complement $L_\alpha^{\perp}$
			\begin{align*}
				I_{\ket{\alpha}} &\coloneqq I - 2\ket{\alpha}\bra{\alpha}\\
				\therefore I_{\ket{\alpha}}\ket{\alpha} &= - \ket{\alpha}\\
				I_{\ket{\alpha}}\ket{\beta} &= \ket{\beta}\ \textrm{for any }\ket{\beta}\perp\ket{\alpha}
			\end{align*}
			\textit{i.e.} $I_{\ket{\alpha}}$ is reflection in $(d-1)$-dim mirror $L_\alpha^\perp$.

			Note for any unitary $U$, $UI_{\ket{\alpha}}U^\dagger = I_{U\ket{\alpha}}$

			\item For $k$-dim subspace $A\subseteq \mathcal{H}_d$ with any orthonormal basis $\ket{a_1},\dots \ket{a_k}$, $P_A = \sum_{i=1}^{k} \ket{a_i}\bra{a_i}$ is the projection operator into $A$ (note that this is independent of the choice of orthonormal basis). Then we have
			\begin{align*}
				I_A &\coloneqq I - 2P_A\\
				\implies I_A\ket{\xi} &= \ket{\xi}\textrm{ if }\ket{\xi}\in A^{\perp}\\
				I_A\ket{\xi} &= -\ket{\xi}\textrm{ if }\ket{\xi}\in A
			\end{align*}
			So $I_A$ is relection in the $(d-k)$-dim mirror $A^\perp$.
		\end{itemize}
	\end{remark*}

\subsection*{Recap of Grover's Algorithm}

\begin{enumerate}[label=-]
	\item search for unique `good' item in an unstructured database of $N = 2^n$ items. This is formalised as:
	
	Given an oracle for $f$:$n$-bits $\ra$ $1$-bit.

	Promise: there is a unique $x_0 \in n$-bits with $f(x_0) = 1$.

	Problem: find $x_0$.

	\item closely related to NP \& Boolean satisfiability problem
	
\end{enumerate}
\begin{itemize}
	\item Using one query to the $(n+1)$-qubit $U_f$, we can implement the reflection operator:
	\begin{align*}
		I_{\ket{x_0}}:\ket{x_0} \ra \left\lbrace \begin{array}{cc} \ket{x} & x\ne x_0 \\ -\ket{x} & x = x_0 \end{array}\right.
	\end{align*}

	Visually, we apply $U_f$ to $\ket{x}\left(\frac{\ket{0} - \ket{1}}{2}\right)$ and discard the last qubit.

	\item Then consider the Grover iteration operator on $n$ qubits
	\begin{align*}
		Q\coloneqq -H_nI_{\ket{0}}H_nI_{\ket{x_0}} = -I_{\ket{\psi_0}}I_{\ket{x_0}}
	\end{align*}
	where $H_n = H\otimes \dots\otimes H$, $\ket{\psi_0} = H_n\ket{0\dots0} = \frac{1}{\sqrt{2^n}}\sum_{x}\ket{x}$. So one application of $Q$ uses 1 query to $U_f$.
\end{itemize}

\begin{theorem*}[Grover 1996]
	In the $2$-dimensional span of $\ket{\psi_0}$ and (unknown) $\ket{x_0}$ the action of $Q$ is rotation by angle $2\alpha$ where $\sin\alpha = \frac{1}{\sqrt{N}}$.
\end{theorem*}
Hence to find $x_0$ given $U_f$:
\begin{enumerate}
	\item Make $\ket{\psi_0}$
	\item Apply $Q$ $m$ times, where
	\begin{align*}
		m = \frac{\arccos \frac{1}{\sqrt{N}}}{2\arcsin\frac{1}{\sqrt{N}}} = \frac{\beta}{2\alpha}
	\end{align*}
	with $\cos\beta = \frac{1}{\sqrt{N}}$, $\beta$ being the angle between $\ket{\psi_0}$ and $\ket{x_0}$ (nearly orthogonal).

	This rotates $\ket{\psi_0}$ very close to $\ket{x_0}$ (within $\pm \alpha$)

	\item Measure, to see $x_0$ with high probability $\approx \cos^2\alpha  = 1 - \sin^2\alpha = 1 - \frac{1}{N}$.
	
	For large $N$, $\arccos\frac{1}{\sqrt{N}} \approx \frac{\pi}{2}$ and $\arcsin\frac{1}{\sqrt{N}} \approx \frac{1}{\sqrt{N}}$. So $m = \frac{\pi}{4}\sqrt{N}$ iterations/queries to $U_f$ are sufficient (it can be shown this is also necessary).
\end{enumerate}

Classically, we need $O(N)$ queries to see $x_0$ with any constant probability (independent of $N$), so we have obtained a \underline{square root} time speed up quantumly.

\subsection*{Amplitude Amplification Problem}

Let $G$ be any subspace (``good subspace'') of state space $\mathcal{H}$ and let $G^{\perp}$ be its orthogonal complement, such that $\mathcal{H} = G \oplus G^\perp$ (the latter is the ``bad subspace'').

Given any $\ket{\psi}\in \mathcal{H}$, we have unique decomposition with real non-negative coefficients:
\begin{align*}
	\ket{\psi} = \sin\theta \ket{g} + \cos\theta\ket{b}
\end{align*}
with $\ket{g} \in G$ and $\ket{b}\in G^\perp$.

We now introduce reflections that flip $\ket{\psi}$ and good vectors:
\begin{align*}
	I_{\ket{\psi}} &= I - 2\ket{\psi}\bra{\psi}\\
	I_G &= I - 2P_G
\end{align*}
So $\sin \theta = ||P_G\ket{\psi}|| = $ length of good projection of $\ket{\psi}$.

Then introduce $Q\coloneqq -I_{\ket{\psi}}I_G$. This is a generalisation of Grover's Algorithm to any subspace.

\begin{theorem*}[Amplitude Amplification]
	In the $2$-dimensional subspace spanned by $\ket{\psi}$ and $\ket{g}$ (or equivalently by orthonormal vectors $\ket{g}$ and $\ket{b}$), $Q$ is rotation by $2\theta$ where $\sin \theta = $ length of good projection of $\ket{\psi}$.
\end{theorem*}

\begin{proof}
	W have $I_G\ket{g} = - \ket{g}$, $I_G\ket{b} = \ket{b}$ so
	\begin{align*}
		Q\ket{g} &= -I_{\ket{\psi}}I_{G}\ket{g} = I_{\ket{\psi}}\ket{g}\\
		Q\ket{b} &= -I_{\ket{\psi}}\ket{b}
	\end{align*}
	Now
	\begin{align*}
		I_{\ket{\psi}} &= I - 2(\sin\theta\ket{g} + \cos\theta\ket{b})(\sin\theta\bra{g} + \cos\theta\bra{b})\\
		&= I - 2\big[\sin^2\theta \ket{g}\bra{g} + \sin\theta\cos\theta\ket{g}\bra{b}+\sin\theta\cos\theta\ket{b}\bra{g}+\cos^2\theta\ket{b}\bra{b}\big]
	\end{align*}
	And direct calculation (using $\langle g | b \rangle = 0$, $\langle g | g\rangle = \langle b | b \rangle = 1$) gives:
	\begin{align*}
		Q\ket{b} &= \cos2\theta\ket{b} + \sin2\theta \ket{g}\\
		Q\ket{g} &= -\sin2\theta \ket{b} + \cos2\theta \ket{g}\\
		&= I\ket{g} - 2\sin^2\theta\ket{g} - 2\sin\theta\cos\theta \ket{b}\\
		&= (1-2\sin^2\theta)\ket{g} - 2\sin\theta\cos\theta\ket{b}\\
		&= \cos2\theta \ket{g} - sin2\theta \ket{b}
	\end{align*}
	So in the $\{\ket{b},\ket{g}\}$ basis, the matrix of $Q$ is
	\begin{align*}
		Q = \left[\begin{array}{cc} \cos2\theta & -\sin2\theta \\ \sin2\theta & \cos 2\theta \end{array}\right]
	\end{align*}
	Which is a rotation through $2\theta$.
\end{proof}

We can then very simply observe that $Q^n\ket{\psi} = \sin((2n+1)\theta)\ket{g} + \cos((2n+1)\theta)\ket{b}$, and if we measure $Q^n\ket{\psi}$ for good vs bad, then $\P[\textrm{good}] = \sin^2(2n+1)\theta$. This is maximised when $(2n+1)\theta = \pi/2$, \textit{i.e.} $n = \pi/4\theta - \frac{1}{2}$ (taken to the nearest integer).

\begin{remark*}[Example]
If we had $\theta = \pi/6$, then $n = \pi/4\theta - \frac{1}{2} = 1$ (exactly), and $Q^1$ rotates $\ket{\psi}$ exactly onto $\ket{g}$, hence we obtain a good result with certainty.
\end{remark*}

Generally, for given $\theta$, $n$ is not an integer so we instead take the nearest integer to $\pi/4\theta - \frac{1}{2} \approx \pi/4theta$ for small $\theta$, and $Q^n\ket{\psi}$ will be within angle $\pm \theta$ of $\ket{g}$. So $\P[\textrm{good}]\ge \cos^2\theta \approx 1 - o(\theta^2)$.

All of this can be implemented if $I_{\ket{\psi}}$ and $I_{G}$ can be implemented (see ES2).

For $I_G$, it suffices for $G$ to be spanned by computational basis states $\ket{x}$s and the indicator function ($f(x) = 1$ for $x$ good and $f(x) = 0$ for $x$ bad) is efficiently computatble.

For $I_{\ket{\psi}}$: often have $\mathcal{H} = n$-qubits and $\ket{\psi} = H_n\ket{0\dots 0}$, and then $I_{\ket{W\psi}}$ can be implemented in $O(n)$ time.

\begin{remark*}[Notes]\ 
	\begin{enumerate}
		\item In the AA process, relative amplitudes of good labels in $\ket{g}$ staty the same as they were in $\ket{\psi} = \sin\theta\ket{g} + \cos\theta \ket{b}$, and AA amplifies the overall $\ket{g}$ amplitude at the expensive of the $\ket{b}$ amplitude.
	
		This is useful for state preparations. For instance:
		\begin{align*}
			\sum_{x\in (\Z/N\Z)^\times}\ket{x}
		\end{align*}

		\item Final state is generally not exactly $\ket{g}$, but if $\sin\theta$ is known, then we can modify the AA process to make it exact, with only a very modest increasee in queries to the oracle - so we can obtain $\ket{g}$ with certainty (ES2).
	\end{enumerate}
\end{remark*}
\end{document}
