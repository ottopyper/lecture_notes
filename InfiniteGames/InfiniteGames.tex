\documentclass[]{article}

\input{/home/pyotopic/Documents/PartIII/lazyboi/lecture_notes/preamble.tex}

\newcommand{\I}{\textrm{I}}
\newcommand{\II}{\textrm{II}}
\newcommand{\om}{\omega}
\newcommand{\lom}{{<\omega}}
\newcommand{\lh}{\ell h}
\renewcommand{\ac}{\textrm{AC}}
\newcommand{\bosig}{\bm{\Sigma}}
\newcommand{\bopi}{\bm{\Pi}}
\newcommand{\bodel}{\bm{\Delta}}
\newcommand{\bg}{{\breve \Gamma}}
\newcommand{\br}[1]{{\breve #1}}
\newcommand{\Det}{\textrm{Det}}
\newcommand{\eomg}{\exists^{\om^\om}\Gamma}
\newcommand{\eom}{\exists^{\om^\om}}
\newcommand{\psp}{\textrm{PSP}}
\newcommand{\rk}{\textrm{rk}}
\newcommand{\fld}{\textrm{fld}}
\newcommand{\wf}{\textrm{WF}}
\newcommand{\hit}{\textrm{ht}}
\newcommand{\bij}[1]{\lceil #1 \rceil}
\newcommand{\bog}{\bm{\Gamma}}

%\renewcommand{\ht}{\textrm{ht}}
%\newcommand{\wf}{\textrm{WF}}
\usepackage{bm}

\newcommand{\game}{
    \begin{center}
        \begin{tabular}{c|ccccccc}
            I & $m_0$ & & $m_2$ & & $m_4 $& & $\dots $\\ \hline
            II & & $m_1$ & & $m_3 $& &$ m_5$ & $\dots$ 
        \end{tabular}
    \end{center}
}

\newcommand{\gamec}[2]{
    \begin{center}
        \begin{tabular}{c|ccccccc}
            I & $#1_0$ & & $#1_1$ & & $#1_2 $& & $\dots $\\ \hline
            II & & $#2_0$ & & $#2_1 $& &$ #2_2$ & $\dots$ 
        \end{tabular}
    \end{center}
}

\title{Infinite Games}
\author{Lectures by Benedikt L{\"o}we}
\date{}

\begin{document}
\maketitle


\reversemarginpar{Lecture 1}

\section{Introduction}
Before this course kicks off, we will first discuss a few things that this course is \it{not} about. Do bear in mind though that this is still an advanced set theory course, building off the content found in IID Logic and Set Theory.

\underline{Literature}: Some useful literature can be found in `The Higher Infinite' - in particular, Chapter 6 ``Determinacy'', sections 27 (Infinite Games) and 28 (AD and Combinatorics).

The term ``Infinite Games'' can evoke different reactions in different mathematicians. We will get on to formal definitions later, but the games we will consider have the following properties. They are:
\begin{itemize}
    \item Two-player
    \item Length $\omega$
    \item Win-lose
    \item Perfect information
    \item Perfect recall
\end{itemize}
Essentially, they are infinite versions of board games.

A notable theorem from the finite analogue of this theory is that of Zermelo, which is that very finite such game is determined - this is considered rather trivial, and we will see the difference between the application of this to the finite case versus the infinite case.

\subsection{Two Players}

We have two players: I and II.

Three-player games do not, in general, admit winning strategies. Consider the following example:

I, II, III are playing. Player I is given a gold coin.

\underline{Round 1}: I can give it to II or to III.

\underline{Round 2}: Whoever has the coin can give it to I or to II.

The person with the coin wins.

So if II gets the coin, they will keep it and win. Player I can either hand the win to II, or leave it to chance with III. III has no win condition, and II cannot force anyone to give them the coin. So no-one has a winning strategy. However, \undf{coalitions} $\{I,II\}$, $\{I,III\}$, $\{II,III\}$ can each ensure a win.

What we have encountered here is \undf{cooperation}, which fundamentally changes the strategies and payoffs; this phenomenon cannot arise in two-player games, as they players are always competing directly with each other.

\subsection{Length $\omega$}

In game theory in economics, there is research on potentially infinite games.

Consider the prisoner's dilemma, concisecly represented by:

\begin{center}
    \begin{tabular}{cc|cc}
        2 & 2 & 1 & 3 \\ \hline
        3 & 1 & 0 & 0
    \end{tabular}
\end{center}

There is a lot of research on this game as a single-move game, but it can also be thought of as a repeated game, where many rounds are played one after the other. In fact, if you fix a length of the game in advance this will affect the strategy of the players. Economists have deal with games which are, while certainly not infinte, of unknown length, and as such it happens that infinite games can serve as a useful model for this situation From there we can study asymptotic behaviour, or evolutionary phenomena.

The point here is that if we only think of \it{truly} infinite games, \it{i.e.} it will take an infinite amount of time to win, then the situation is fundamentally different.

\begin{remark}[Example] The Prime Factor Game\ \\

\begin{center}
    \begin{tabular}{cccccccccc}
        I & $k_0$ & & $k_1$ & & $k_2$ & & $k_3$ & &\dots \\
        II & & $p_0$ & & $p_1$ & & $p_2$ & & $p_3$ &\dots
    \end{tabular}
\end{center}

The $k_i\ge 2$ are natural numbers, and the $p_i$ are prime numbers. At the end of the game, we look at $K = \{k_i:i\in \N\}$ and $P = \{p_i:i \in \N\}$. We say that Player II wins if $P$ is the set of all prime factors in $K$ (and no more).

\underline{Observe}: Player II has a winning strategy.

Let $k_0 = q_0^{\ell_0}\dots q_m^{\ell_m}$. Then play as though $p_0 = q_0$, $p_1 = q_1$, $p_2 = q_2$, exhausting the finitely many prime factors of $k_0$ before moving on to $k_1$. Repeating ad infinitum, it is clear that the set $P$ is precisely what is desired.

However, if we look at how this is going for II after any finite number of moves $N \in \N$, then in most runs of the game, the finite sets $\{k_0,\dots,k_N\}$ and $\{p_0,\dots,p_N\}$ do not look like a win for player II; it will seems as though things are going worse and worse for II.

This critically highlights how the asymptotic behaviour can be drastically different from the outcome of the game after infinite time.
\end{remark}

A common objection to this type of material is that you can't play these games, so how could you know who wins?

The above example clearly highlights that even though, of course, the games cannot actually be played, we may still be able to prove that a winning strategy does or does not exist for either player. So we are replacing actually playing the game with thinking about the different strategies for it.

Let's modify the PFG slightly:

\begin{center}
    \begin{tabular}{cccccccc}
        I & & $k_0$ & & $k_1$ & & $k_2$ & \dots \\ 
        II & $p_0$ & & $p_1$ & & $p_2$ & & \dots
    \end{tabular}
\end{center}

Now Player I has a winning strategy instead. Take $p_0$, find another prime $q \ne p_0$ and play $k_i = q^{i+1}$. Then $K = \{q^{i+1}:i \in \N\}$. So II wins iff $P = \{q\}$, but $p_0 \in P$. So II loses.

\subsection{Win-Lose}

There is a related notion here called \undf{zero-sum}; in these games, there is a fixed payoff that is split between the two players. So, for instance, the Prisoner's Dilemma is \undf{not} zero-sum because the total payoff differs between some outcomes. However, the game
\begin{center}
    \begin{tabular}{cc|cc}
        1&1&0&2\\ \hline
        2&0&1&1
    \end{tabular}
\end{center}
\it{is} zero-sum.

\undf{Win-lose} simply means that the payoff is an indivisible $1$. So in our case, payoff functions are characteristic functions of a \undf{payoff set}.

\subsection{Perfect Information}

Paradigmatic: board games, after which this idea was modelled.

A non-example is \it{card games}, in which your own hand is only known to you. Unsurprisingly, this scenario is called \it{imperfect information}.

Consider yet another variant of PFG:

\begin{center}
    \begin{tabular}{cccccccccc}
        I & $k_0$ & & $k_1$ & & $k_2$ & & $k_3$ & &\dots \\
        II & & $p_0$ & & $p_1$ & & $p_2$ & & $p_3$ &\dots
    \end{tabular}
\end{center}

Here, player I picks $k_i$, but does not have to reveal $k_i$ before II has played $p_i$. Here, although it may happen with probability zero, it is possible for II to beat any set of moves that I makes simply by being lucky, and guessing only prime factors for numbers chosen by I. However, it is clear that it is impossible to ensure that this is the case.

So neither of the two players has a winning strategy in this variant. The study of these imperfect information games is closely related to probability.

\subsection{Perfect Recall}

This means that both of the players remember everything that has happened before; the opposite of course would be that the players have a finite, bounded memory.

For instance, take PFG with the additional constraint that Player II can only remember the last 1000 moves. Now Player I has a strategy that might win; on the first move, pick a natural number with at least 1001 distinct prime factors. Then II will have no idea what move to make at $N = 1001$; they might guess, and so they can still win, but they have no way to ensure this (and again it will not be very likely).

Imperfect recall is very relevant in applications of infinite games in computer science.

\reversemarginpar{Lecture 2}

We fix a set $M$ of moves. In most cases, $M$ will simply be $\N$ - but we will aim to keep this slightly more general for now.

Note that from the perspective of a set theorist, we think of $\N$ as equal to $\omega$, and in particular $n = \{0,1,\dots,n-1\}$. Moreover, functions are \it{set-theoretic} functions, \it{i.e.} sets of ordered pairs with the function property. For instance:
\begin{align*}
    M^n = \{s; s:n\ra M\}
\end{align*}
is the set of functions from the \it{set} $n$ to the set $M$. If $s\in M^n$ and $t \in M^k$, with $k>n$, then $s\subset t$ is the same as saying ``$s$ is an initial segment of $t$'', or that ``$t$ is an extension of $s$''.

Since we are thinking of sequences as functions, we can also write: if $m<n$ and $s \in M^n$, then $s\restriction m \in M^m$.

These are well-known formal definitions of these objects, but they will be used particularly ruthelessly here.

We make another important definition:
\begin{align*}
    M^{<\omega} \coloneqq \bigcup_{n\in \N}M^n
\end{align*}
This is the set of all finite sequences of elements of $M$; these will be called the \undf{positions} of the game. We also have:
\begin{align*}
    M^\omega \coloneqq \{x;x:\N\ra M\}
\end{align*}
is the set of all \undf{runs} or \undf{plays} of the game \it{i.e.} the set of all sequences of $M$ of length $\omega$. Note that if $x\in M^\omega$ is a run and $n\in \N$, then $$x\restriction n:n\ra M$$ is the position that the play producing $x$ was in after $n$ rounds.

\underline{The games on $M$}:

\begin{center}
    \begin{tabular}{c|ccccccc}
        I & $m_0$ & & $m_2$ & & $m_4 $& & $\dots $\\ \hline
        II & & $m_1$ & & $m_3 $& &$ m_5$ & $\dots$ 
    \end{tabular}
\end{center}
We are restricting our attention to games where I,II play in alternation and player I starts. [Remark: more general games can be described by these; see later.]

Then $x(i)\coloneqq m_i$ is the run produced by the game, and $s\coloneqq x\restriction n$ is the $n^\th$ position.

If $x \in M^\omega$, we write
\begin{align*}
    x_\I(i) &\coloneqq x(2i)\\
    x_\II(i) &\coloneqq x(2i+1)
\end{align*}
$x_I,x_{II}\in M^\omega$ correspond to the moves made by players I,II respectively. If $x,y\in M^\omega$, we write $x\ast y$ (\undf{interleaving}) for the sequence $z$ defined by:
\begin{align*}
    z(n) \coloneqq \left\lbrace  \begin{array}{ccc}x(k)&n = 2k\\ y(k) &n = 2k+1 \end{array}\right.
\end{align*}

Clearly, $x_\I \ast x_\II = x$.

If $A\subset M^\omega$, we call $A$ a \undf{payoff set}. In the game $G(A)$, we say that player I wins a run $x \in M^\om$ if $x \in A$; otherwise player II wins.

We call any function $$\sigma:M^{<\om} \ra M$$ a \undf{strategy}. Note that a strategy looks at the entire game up until that point to decide the next move; this is the perfect recall aspect. You may wonder why we bother defining a strategy for player I at odd length positions, and this is largely for notational convenience; it is a little easier to have this notational overkill.

Note that each strategy in this sense can be thought of a strategy for I, plus a strategy for II. Let
\begin{align*}
    O&\coloneqq \bigcup_{n\textrm{ odd}}M^n\\
    E &\coloneqq \bigcup_{n\textrm{ even}}M^n
\end{align*}
Then $\sigma\restriction E$ is a strategy for I, and $\sigma \restriction O$ is a strategy for II. So there is redundance in the notation.

If $\sigma, \tau$ are strategies, we can play them against each other by interleaving them as $\sigma\ast\tau \in M^\om$, which is defined by:
\begin{align*}
    (\sigma\ast\tau)(2n)&\coloneqq \sigma((\sigma\ast\tau)\restriction 2n)\\
    (\sigma\ast\tau)(2n+1)&\coloneqq \tau((\sigma\ast\tau)\restriction 2n+1)
\end{align*}
We say that $\sigma$ is \undf{winning for I in $G(A)$} if $\forall \tau(\sigma\ast\tau\in A)$, \it{i.e.} I always wins regardless of II's strategy. Similarly, we say that $\tau$ is \undf{winning for II in $G(A)$} if $\forall \sigma(\sigma\ast\tau\not\in A)$.

We say that a set $A$ is \undf{determined} if one of the two players has a winning strategy in $G(A)$.

\begin{remark}\ 
    \begin{itemize}
        \item Clearly, at most one player can have a winning strategy (otherwise, play them against each other).
        \item However, it is not obvious (and not true, up to the axiom of choice) that every set is determined.
        \item In fact, we will see that AC implies that there are non-determined sets, but ``every set is determined'' (Axiom of Determinacy, AD) is consistent ZF - though this requires more nuance, but we will discuss all of this later.
    \end{itemize}
\end{remark}

You may ask: is that really the most general form of games that we want to look at? What if we wanted to include things like `forbidden' moves, or allowing one or two players to make several moves at a time, or having two different move sets? It turns out that we don't need to worry about this:

A set $T\subset M^{\lom}$ is called a \undf{tree} if it is closed under initial segments, \it{i.e.} if $s\in T$ and $t\subset s$ then $t \in T$.

These trees look very much like the trees one might encounter in graph theory/combinatorics; though there are some small differences. In this set-theoretic notion of a tree, each node in the tree contains within it all of the information abou the path from the root (\it{i.e.} the empty set, $\emptyset$) to it.

If $T$ is a tree on $M$ and $x\in M^\om$, we say that $x$ is a \undf{branch through $T$} if for all $n \in \N$, $x\restriction n \in T$. We write $[T]$ for the set of branches through $T$; in some literature this is referred to as the \undf{body of $T$}.

\begin{remark}[Example]
    $M^\lom$ is a tree; $[M^\lom] = M^\om$.
\end{remark}

We can think of a tree $T$ as ``finitary'' rules for a game: if $x\not\in [T]$, then there is a least $n$ for which $x\restriction n\not\in T$. If $n$ is odd, then player I left the tree, and if $n$ is even then player II left the tree.

Define a game $G(A;T)$ where $A\subset [T]$ and $T$ is a tree on $M$.
The game is as usual:
\game
If $x \in A$, then player I wins. If $x\not\in [T]$ and the least $n$ for which $x\restriction n\not\in T$ is even, then player I wins. In all other cases, player II wins.

Now, even though this looks more general due to the introduction of the tree $T$, it can be seen that this is in fact a special case of a $G(A)$ game, since we can define: $$A_T \coloneqq \{x \in M^\om; x\in A\textrm{ or }x\not\in [T]\textrm{ and the least }n\textrm{ s.t. } x\restriction n\not\in T\textrm{ is even}\}$$. Then $G(A;T)$ and $G(A_T)$ are \undf{the same game}.

Note that we haven't quite defined what it means to be the same game, but in this particular case it should be rather clear that these two are indeed the same game.

This idea of using trees gives us a lot of flexibility with the move set.

\begin{remark}[Example 1]
    Suppose the moves for I are in $X$, and the moves for II are in $Y$. We can take $M\coloneqq X\cup Y$, $A\subset M^\om$, and
    \begin{align*}
        T\coloneqq \{s;\ \forall n\in \N,\ s(2n)\in X\textrm{ and }s(2n+1)\in Y\}
    \end{align*}
    Then $G(A;T)$ is the game we desire.
\end{remark}

\begin{remark}[Example 2]
    Suppose I can always make two moves in $X$, but II can only make one move. We then take $M\coloneqq X^2\cup X^1$, and apply the idea of Ex. 1 with $X = X^2$ and $Y = X^1$.
\end{remark}

\begin{remark}[Example 3]
    If $X\subset Y$, then every game $G(A)$ on $X$ can be thought of as a game on $Y$ by $G(A;T)$, where $$T\coloneqq X^{\lom} \subset Y^{\lom}$$
\end{remark}

\begin{defin*}[Strategic Tree]
    Let $\sigma$ be a strategy. We define the \undf{I-strategic tree} and the \undf{II-strategic tree} on $M$ as follows:
    \begin{align*}
        T_\sigma^\I &\coloneqq \{s\in M^{\lom}; \forall n(s(2n)=\sigma(s\restriction 2n))\}\\
        T_\sigma^\II &\coloneqq \{s\in M^\lom; \forall n(s(2n+1)=\sigma(s\restriction 2n+1))\}
    \end{align*}

    When drawing out these trees, for instance $T_\sigma^\I$, the layers alternate between making any choice from $M$ (representing II's moves) and making the only choice dictated by $\sigma$ for I.

    II-strategic trees look the same except that we have branching in odd length nodes and no branching in even length nodes.

    $T$ is called \undf{strategic} if there is $\sigma$ such that $T = T^\I_\sigma$ or $T = T^\II_\sigma$.
\end{defin*}

\underline{Observe}: $$T_\sigma^\I = \{(\sigma\ast \tau)\restriction n; \tau \textrm{ any strategy and }n\in \N\}$$ $$T_\sigma^\I = \{(\tau\ast \sigma)\restriction n; \tau \textrm{ any strategy and }n\in \N\}$$

\underline{Therefore}: $$ [T_\sigma^\I] = \{\sigma\ast \tau; \tau \textrm{ any strategy}\}$$
$$ [T_\sigma^\II] = \{\tau\ast\sigma; \tau \textrm{ any strategy}\}$$

\begin{remark}[Proposition]\ 
    \begin{enumerate}
        \item $\sigma$ is a winning strategy for I in $G(A)\iff [T_\sigma^\I]\subset A$
        \item $\sigma$ is a winning strategy for II in $G(AS)\iff [T_\sigma^\II]\cap A = \emptyset \iff [T_\sigma^\I]\subset M^\omega \backslash A$
    \end{enumerate}

    \underline{Also}: $A$ is determined iff either $A$ contains $[T_\sigma^\I]$ for some $\sigma$ or $M^\om \backslash A$ contains $[T_\sigma^\II]$ for some $\sigma$.
\end{remark}

\underline{Notation}: If $s,t\in M^\lom$, we write $st$ for the concatenation of $s$ and $t$. This also works if $t$ is infinite; if $x \in M^\om$ and $s\in M^\lom$, then similarly $sx\in M^\om$ is the concatenation.

If $t$ is a length 1 sequence, say $t = \langle m\rangle$, we also write $sm$ for $st = s\langle m\rangle$; this is usually unambiguous.

For the length of a sequence we write $\lh(s) = \textrm{dom}(s)$.

\begin{defin*}[Splitting Node, Perfect Tree, Perfect Set]\ 
    \begin{enumerate}[label=\arabic*)]
        \item If $T$ is a tree and $s \in T$ we say $s$ is a \undf{splitting node} if there are $m\ne m'$ such that both $sm,sm' \in T$.
        \item $T$ is \undf{perfect} if for each $s \in T$ there is a $t\supseteq s$ such that $t\in T$ and $t$ is splitting in $T$.
        
        [Remark: every strategic tree is perfect]

        \item $A\subset M^\om$ is \undf{perfect} if there is a perfect tree $T$ such that $A = [T]$.
        
        \underline{Remark}: Compare to the topological notion of a \undf{perfect set}: clsoed without isolated points. We will find out later that, with the right toplology on $M^\om$, these notions will coincide.

    \end{enumerate}
\end{defin*}

\begin{theorem*}[Cantor]
    Suppose $A\subset 2^\om \equiv \{0,1\}^\om$ is perfect and non-empty. Then $A$ has cardinality $2^{\aleph_0}$.
\end{theorem*}
\begin{proof}
    $A\subset 2^\om$ and $|2^\om| = 2^{\aleph_0}$, so $|A| \le 2^{\aleph_0}$. So by Cantor-Schr{\"o}der-Bernstein, it is enough to show that there is an injection from $2^\om$ into $A$.

    We define this injection via a function $\phi : 2^{\lom} \ra T$, where $T$ is perfect such that $A = [T]$. We will define this by recursion (this is known as a \it{Cantor scheme}):
    \begin{align*}
        \phi(\emptyset) &\coloneqq \emptyset\\
    \end{align*}
    Suppose $\phi(s) = t \in T$. Since $T$ was perfect, find $u\supseteq t, u \in T$ that is splitting: $u0,u1\in T$. To ensure this is uniquely defined (to potentially avoid issues with Choice), take the minimal one. Then:
    \begin{align*}
        \phi(s0) &\coloneqq u0\\
        \phi(s1) &\coloneqq u1
    \end{align*}
    This finishes the definition of $\phi$. We then define:
    \begin{align*}
        \hat{\phi}&:2^\om \ra [T] = A\\
        \hat{\phi}(x)&\coloneqq \bigcup_{n\in \N}\phi(x\restriction n)
    \end{align*}
    We need to check some things:
    \begin{enumerate}
        \item $\lh(\phi(x\restriction n)) \ge n$
        \item $\phi(x\restriction n)\subset \phi(x\restriction m)$ if $n\le m$
        
        $\implies \hat{\phi}:2^\om\ra2^\om$

        \item $\hat{\phi}(x)\restriction u\subset \phi(x\restriction k)$ for some $k$ so $\hat{\phi}(x)\restriction u\in T$, so $\hat{\phi}(x)\in [T]$.
        
        So we indeed have that $\hat{\phi}:2^\om \ra [T]$.
    \end{enumerate}

    It remains to show that $\hat{\phi}$ is an injection:

    Suppose $x\ne y$. Find $n$ such that $x\restriction n = y\restriction n$, but $x(n)\ne y(n)$. WLOG, say $x(n) = 0$ and $y(n) = 1$. But then $\phi(x\restriction n+1)\ne \phi(y\restriction n+1)$, since the former ends in $0$ and the latter in $1$. This implies that $\bigcup_{k\in \N}\phi(x\restriction k)\ne \bigcup_{k\in \N}\phi(y\restriction k)$, hence $\hat{\phi}(x)\ne \hat{\phi}(y)$.
\end{proof}

\begin{remark}
    If $|M|\ge 2$ and $T$ is a perfect tree on $M$, then the same proof shows that $2^{\aleph_0}\le |[T]|$.
\end{remark}

\begin{remark}[Corollary]
    If $|M|\ge 2$, then:
    \begin{enumerate}[label = (\roman*)]
        \item if player I has a winning strategy in $G(A)$, then $|A|\ge 2^{\aleph_0}$
        \item if player II has a winning strategy in $G(A)$ then $|M^\om \backslash A| \ge 2^{\aleph_0}$.
    \end{enumerate}
    This follows from:
    \begin{enumerate}
        \item strategic trees are perfect
        \item perfect sets are large
        \item winning startegy means ``includes strategic tree''
    \end{enumerate}
\end{remark}

Note that if $A\subset M^\om$ with $|M|\ge 2$, then either $|A|\ge 2^{\aleph_0}$ or $|M\backslash A| \ge 2^{\aleph_0}$.

The corollary gives a necessary condition on when a fixed player has a winning strategy, but no non-trivial necessary condition for determinacy.

\subsection*{Sufficient Conditions}

Let's do the following as a warmup.

Prove that if $A$ is countable, then player II has a winning strategy in $G(A)$.

\begin{remark}[Proposition]
    If $A = \{a_i;i \in \N\}$ is countable, then player II has a winning strategy in $G(A)$.
\end{remark}
\begin{proof}
    In II's round $k$ [that means digit $2k+1$], II takes care of $a_k$, simply by playing $1 - a_k(2k+1)$ (assume again we are playing on $M = \{0,1\}$; on anything else just pick something different to $a_k(2k+1)$).

    So the strategy $\tau$ is:
    \begin{itemize}
        \item ignore everything player I does
        \item blindly play $1 - a_k(2k+1)$ in your $k^\th$ move.
    \end{itemize}

    Clearly then for any $\sigma$,
    \begin{align*}
        (\sigma\ast \tau)_\II(k) &= (\sigma \ast \tau)(2k+1)\\
        &= 1 - a_k(2k+1)\\
        &\ne a_k(2k+1)
    \end{align*}
    So $\sigma \ast \tau\ne a_k$ for arbitrary $k$, so $\sigma\ast \tau \not \in A$. Thus $\tau$ is winning.
\end{proof}

\reversemarginpar{Lecture 3}

\underline{Necessary}: we have determined some necessary conditions for wins:
\begin{itemize}
    \item I wins $G(A)\implies |A| = 2^{\aleph_0}$
    \item II wins $G(A)\implies |\om^\om\backslash A| = 2^{\aleph_0}$
\end{itemize}
\underline{Sufficient}: we also have the sufficient condition:
\begin{itemize}
    \item if $A$ is countable, then player II wins.
\end{itemize}

Note that we write `I/II' wins as shorthand for `I/II has a w.s.'
\ \\

\begin{theorem*}\ \\
    \begin{enumerate}
        \item If $A\subset \om^\om$ such that $|A| < 2^{\aleph_0}$, then player II has a winning strategy in $G(A)$.
        \item If $A\subset \om^\om$ such that $|\om^\om\backslash A| < 2^{\aleph_0}$ then player I has a winning strategy in $G(A)$.
    \end{enumerate}
\end{theorem*}
\begin{proof}
    The proofs of 1 and 2 are essentially just switching the roles of I,II. So we are just going to prove 1.

    \underline{Caution}: our games are \it{not} fully symmetric; I is not in the same situation as II. Moving first can sometimes be an advantage, and sometimes a disadvantage. The above claim must thus be checkd carefully.

    Let $|A| < 2^{\aleph_0}$. Define an equivalence relation $\sim$ on $\om^\om$ by $$x\sim y \iff x_{II} = y_{II}$$. So equivalence classes look like this:
    \begin{align*}
        C_z \coloneqq \{x; x_{II} = z\}
    \end{align*}
    So there is a bijection between the $\sim$-equivalence classes and $\om^\om$. In particular, there are $2^{\aleph_0}$ such equivalence classes. By the pigeonhole principle, we find $z$ such that $$C_z \cap A = \emptyset$$. Then define $\tau$ as:
    \begin{itemize}
        \item ignore everything player I does
        \item just play the next digit of $z$
    \end{itemize}
    Formally, we can say $\tau(s)\coloneqq z(n)$ if $\lh(s) = 2n+1$, and whatevery you like on the even entries. Then if $\sigma$ is any strategy, we have
    \begin{align*}
        (\sigma\ast\tau)_{\II} &= z\\
        \implies \sigma\ast\tau &\in C_z\\
        \implies \sigma\ast\tau&\not\in A
    \end{align*}
    So $\tau$ is a w.s. for II.
\end{proof}

This is called a \undf{blindfolded strategy}, since II doesn't care about what I is doing (and doesn't need to know). Formally, this is when there is $z\in \om^\om$ such that for player II, $\tau(s)\coloneqq z(n)$ if $\lh(s) = 2n+1$, or similarly for player I $\sigma(s)\coloneqq z(n)$ if $\lh(s) = 2n$. We normally denote this as $\tau_z$ if for player II, and $\sigma_z$ if for player I.

\underline{Consequence}: If we have any set $A$ that is not determined, then it must be the case that $|A| = |\om^\om \backslash A| = 2^{\aleph_0}$. So we have a bit of an idea that a non-determined set must look a bit symmetric.

\underline{Next goal}: Find such a non-determined set.

\begin{theorem*}[uses AC]
    There is a non-determined subset $A\subset \om^\om$.
\end{theorem*}
\begin{proof}
    The idea here is to ensure that $A$ contains no strategic trees, which we do by enumerating them and then distributing the branches between $A$ and its complement.

    We did prove in Lecture 3 that if $T$ is a strategic tree, then $|[T]| = 2^{\aleph_0}$.
    
    \underline{Question}: How many strategic trees are there?

    \underline{Notation}: We write Trees $\coloneqq \{T;T\textrm{ is a tree on }\om\}$, and STrees$\coloneqq \{T;T\textrm{ is a strategic tree on }\om\}$.

    We remark that a tree $T\subset \om^\om$, which is countable, so this gives an upper bound on the size of Trees. So we have $|$STrees$|\le|$Trees$|\le2^{\aleph_0}$. Can we also find a lower bound? This is where the blindfolded strats come in...

    If $z\ne z'\in \om^\om$, then $[T^\I_{\sigma_z}]\cap[T^\I_{\sigma_{z'}}] = \emptyset$. So $T_{\sigma_z}^\I \ne T^\I_{\sigma_{z'}}$.

    Together (with Cantor-Schr{\"o}der-Bernstein), we get a bijection between $2^{\aleph_0}$ and STrees.

    Note that so far we haven't used AC, with the mild exception that the notation $2^{\aleph_0}$ implies the existence of an ordinal in bijection with the powerset of $\om$, which requires AC. However, the above can be reformulated as saying that we have injections $\om^\om \xhookrightarrow{} \dots \xhookrightarrow{} \om^\om$, and then use CSB; choiceless.

    However, we need a little bit of choice now. We aren't going to use the full AC, but only that the set $\om^\om$ is wellorderable. This implies:
    \begin{itemize}
        \item $2^\aleph_0$ \it{is} an ordinal (so we can do transfinite recursion on it)
        \item there is a choice funcntion $c:\mathcal{P}\om^\om\backslash \emptyset \ra \om^\om$ (\it{i.e.} $c(A)\in A$)
    \end{itemize}

    Equipped with this, we do the construction. We had that $|\textrm{STrees}| = 2^{\aleph_0}$, so write STrees $=\{T_\alpha; \alpha < 2^{\aleph_0}\}$ and do the following transfinite recursion:

    We are going to define sets $A_\alpha,B_\alpha$ in stages for $\alpha < 2^{\aleph_0}$ in such a way that $|A_\alpha| = |B_\alpha| = |\alpha|$ ($\ast$). In the end we will see $A_\alpha \cap B_\alpha = \emptyset$.

    \underline{$\alpha = 0$}: $A_0 = B_0 = \emptyset$.

    \underline{$\alpha = \beta+1$}: Suppose we have $A_\beta,B_\beta$. Consider $T_\beta\in$ STrees. Then $|[T_\beta]| = 2^{\aleph_0}$. By $(\ast)$, $|A_\beta| = |B_\beta| = |\beta|<2^{\aleph_0}$. This implies that $|A_\beta\cup B_\beta|<2^{\aleph_0}$. Thus $[T_\beta]\backslash (A_\beta \cup B_\beta)\ne\emptyset$ (even better, it has $2^{\aleph_0}$ many elements).

    Define:
    \begin{align*}
        a_\beta & \coloneqq c([T_\beta]\backslash(A_\beta\cup B_\beta))\\
        b_\beta & \coloneqq c([T_\beta]\backslash (A_\beta\cup B_\beta\cup \{a_\beta\}))
    \end{align*}
    Note that the latter input for $c$ is still non-empty since $|[T_\beta]\backslash (A_\beta\cup B_\beta)| = 2^{\aleph_0}$.

    Then let $A_\alpha \coloneqq A_\beta \cup \{a_\beta\}$, and similarly $B_\alpha \coloneqq B_\beta\cup\{b_\beta\}$. Moreover, $|A_\alpha| = |\beta + 1| = |\alpha| = |B_\alpha|$, satisfying IH.

    \underline{$\alpha$ is a limit}: For all $\beta < \alpha$, $A_\beta$, $B_\beta$ are defined and satisfy $(\ast)$. So we let:
    \begin{align*}
        A_\alpha &\coloneqq \bigcup_{\beta<\alpha}A_\beta\\
        B_\alpha &\coloneqq \bigcup_{\beta<\alpha}B_\beta
    \end{align*}
    Obviously, $|A_\alpha| = |\alpha| = |B_\alpha|$ since they are each unions of things of the right size (there is an increasing sequence of bijections that converges to what we want, formally), so $(\ast)$ is still satisfied.

    Now we let
    \begin{align*}
        A &\coloneqq \bigcup_{\alpha <2^{\aleph_0}}A_\alpha\\
        B &\coloneqq \bigcup_{\alpha < 2^{\aleph_0}}B_\alpha
    \end{align*}
    \underline{Note 1}: $A\cap B = \emptyset$; if not, then $a_\alpha = b_\beta$ for some $\alpha,\beta$. WLOG $\alpha \le \beta$. This then contradicts the choice of $b_\beta$.

    \underline{Note 2}: $|A| = 2^{\aleph_0} = |B|$. This is good, since it was a necessary condition for $A$ and $B$ being non-determined, as we found earlier.

    \underline{Claim}: $A$ is not determined (and similarly $B$).

    \underline{Proof of Claim}: Suppose $A$ is determiend. Then there is a strategic tree $T_\alpha$, $\alpha <2^{\aleph_0}$, such that either $[T_\alpha] \subset A$ or $[T_\alpha]\cap A = \emptyset$. But consider $a_\alpha,b_\alpha \in [T_\alpha]$. We have $a_\alpha \in A$, $b_\alpha \in B$, \it{i.e.} $b_\alpha\not\in B$. This rules out both cases, so contradiction. This proves the theorem.
\end{proof}

You may notice that this is the very same diagonalisation argument that crops up all over the place.

\underline{Discussion}: we used AC to produce a non-determined set. [Usually, AC implies the existence of pathologies, \it{e.g.} a non-Lebesgue measurable set, or the Banach-Tarski decomposition of the unit ball. AC does not produce a constructive method for teh pathological objects, since the construction depends on the choice function.

\underline{Motto (hope)}: If a set $A$ is `nice' or `simple', then it is not pathological.

Similarly here; though we have just proved that non-determined sets may exist, the ones we have found are all pathological. We might ask if non-determined sets only arise this way. Hence:

\underline{Goal}: Make `nice' and `simple' precise, and prove that nice sets are determined.

\reversemarginpar{Lecture 5}

\begin{defin*}[Quasistrategy]
    A function $$\sigma:M^{\lom}\ra \mathcal{P}(M)\backslash \{\emptyset\}$$ is called a \undf{quasi-strategy}. Strategies can be identified as a special case of quasistrategies: $$(\forall s)|\sigma(s)| = 1$$ which clearly induced a strategy as we have defined it.

    We also have a notion of \undf{quasistrategic trees}:
    \begin{align*}
        Q_\sigma^\I &\coloneqq \{s\in M^\lom; (\forall n) s(2n)\in \sigma(s\restriction 2n)\}\\
        Q_\sigma^\II &\coloneqq \{s\in M^{\lom}; (\forall n) s(2n+1)\in \sigma(s\restriction 2n+1)\}
    \end{align*}
    A quasistrategy is \undf{winning for I in $G(A)$} if $[Q_\sigma^\I]\subset A$, and \undf{winning for II in $G(A)$} if $[Q_\sigma^\II]\cap A = \emptyset$.

    As before, at worst one of the two players can have a winning quasistrategy.
\end{defin*}

\begin{defin*}[Quasidetermined Set]
    A set $A\subset M^\om$ is called \undf{quasidetermined} if either I or II has a winning qs in $G(A)$.
\end{defin*}

\begin{remark*}[Lemma]
    If $M$ is wellorderable, then every quasistrategic tree on $M$ contains a strategic tree on $M$.
\end{remark*}

[\underline{Consequence}: if $M$ is wellorderable and $A\subset M^\om$ is quasidetermined, then it is determined.]

\begin{proof}
    Let $\sigma$ be a quasistrategy $\sigma :M^\lom \ra \mathcal{P}(M)\backslash \{\emptyset\}$. If $M$ is wellorderable, then there is a choice function $c:\mathcal{P}(M)\backslash \{\emptyset\}\ra M$ (\it{i.e.} such that $c(A)\in A$ for each $A$).

    Then define $\sigma^\ast \coloneqq c\circ \sigma:M^\lom \ra M$. By construction, $T_{\sigma^\ast}^\I \subset Q_\sigma^\I$ and $T_{\sigma^\ast}^\II \subset Q_\sigma^\II$.
\end{proof}

Note that we needed a bit of choice here - that $M$ is wellorderable.

Compare with out proof of the existence of a non-determined set from Lecture 4 (we used a wellordering of $M^\om$ to get $A\subset M^\om$ non-determined) to this, where we just use a wellordering of $M$. This requires significantly less choice, and it is often the case that $M$ comes equipped with a wellordering but $M^\om$ does not, \it{e.g.} $M = \N$.

\begin{defin*}[Closed Set]
    A set $A\subset M^\om$ is called \undf{closed} if there is a tree $T$ on $M$ such that $A = [T]$.
\end{defin*}

\begin{remark*}[Remarks]\ 
    \begin{enumerate}
        \item This is actually the notion of being closed in a topological space; we will see this space in the next lecture.
        \item Zermelo's finite games can be represented by closed payoff sets.
        
        Finite game of length $n$: let's say $f:M^n\ra \{\I,\II\}$ is the functino labelling the leaves according to which player wins.

        Let $A\coloneq \{x\in M^\om ; f(x\restriction n) = \I\}$. Then the finite game is just $G(A)$. This is just playing an infinite game, but having decided the outcome already after $n$ moves.

        We can also define:
        \begin{align*}
            T\coloneqq \{s\in M^\lom; f(s\restriction n) = \I\textrm{ and }\lh(s)\ge n \textrm{ or }\lh(s) < n\textrm{ and there is a }t\supseteq s \textrm{ s.t. } f(t)=\I\}
        \end{align*}
        Clearly, $[T] = A$. Thus all finite games are closed games.
    \end{enumerate}
\end{remark*}

\begin{theorem*}[Gale-Stewart]
    All closed sets $A\subset M^\om$ are quasidetermined.
\end{theorem*}
\begin{proof}
    If $A = [T]$, this means that if $x\not \in A$, then $x\not\in [T] = \{x\in M^\lom; (\forall n)x\restriction n\in T\}$. This implies there is some $n$ such that $x\restriction n\not \in T$. These are positions thare are won for sure by player II.

    Define a partial function $$\ell:M^\lom \ra \{\I,\II\}$$ by $\ell(s) = \II\iff s\not\in T$. Apply the following recursion rules to the partial labellings:

    We extend $\ell$ to $\ell^+\supseteq \ell$ according to the following rules. If $\ell(s)$ is undefined:
    \begin{itemize}
        \item and $\lh(s)$ is even [I moves] and $\forall m\in M$, $\ell(sm)=\II$, then $\ell^+(s)\coloneqq = \II$
        \item and $\lh(s)$ is odd [II moves] and $\exists m\in M$, $\ell(sm) = \II$, then $\ell^+(s) = \II$
    \end{itemize}
    Our transfinite recursion is then in the normal way:
    \begin{itemize}
        \item $\ell_0\coloneqq \ell$
        \item $\ell_{\alpha+1} \coloneqq (\ell_\alpha)^+$
        \item $\ell_{\lambda} \coloneqq \bigcup_{\alpha < \lambda} \ell_\alpha$
    \end{itemize}
    It's easy to construct examples of truly transfinite processes like this [needs $|M|\ge \aleph_0$].

    \underline{Claim}: this process terminates at some ordinal $\alpha$, \it{i.e.} $\ell_{\alpha} = \ell_{\alpha+1} = (\ell_{\alpha})^+$.

    \underline{Proof of Claim}: for $s\in M^\om$, we can define an \it{age function}:
    \begin{align*}
        \textrm{age}(s)\coloneqq \left\lbrace \begin{array}{c}\textrm{least }\beta\textrm{ s.t. }\ell_{\beta}(s)\textrm{ is defined}\\ 0\quad\textrm{ if }\ell_{\beta}(s)\textrm{ is never defined}\end{array}\right.
    \end{align*}
    So if the process never terminates, then age is a surjection from the set $M^\lom$ onto the (proper) class Ord. This contradicts the Axiom of Replacement.

    Let $\alpha$ be this termination point. We can then define:
    \begin{align*}
        \hat{\ell}(s)\coloneqq \left\lbrace \begin{array}{c}\II\quad \textrm{ if }s\in \textrm{dom}(\ell_\alpha)\\ \I\qquad \ \ \ \textrm{otherwise}\end{array}\right.
    \end{align*}
    Then $\hat{\ell}\supseteq \ell_\alpha$, effectively just taking $\ell_\alpha$ and filling everything else in with $\I$s. So $\hat{\ell}$ is a total function.

    \underline{Claim}: If $\hat{\ell}(\emptyset) = \I$, then player I has a winning quasistrategy; otherwise, $\hat{\ell}(\emptyset) = \II$ and player II has a winning q.s.

    Given this, the proof is complete.

    \marginpar{Lecture 6}

    \underline{Subclaim 1}: If $\hat{\ell}(\emptyset) = \I$, define
    \begin{align*}
        Q_\I \coloneqq \{s \in \om^\lom; \hat{\ell}(s) = \I\}
    \end{align*}
    and if $\hat{\ell}(\emptyset) = \II$, define $Q_\II$ similarly.l

    Then $Q_\I/Q_\II$ is a I/II-quasistrategic tree.

    [Need to show:
    \begin{enumerate}
        \item if $\hat{\ell}(s) = \I$ and $\lh(s)$ is even then there is $m$ such that $\hat{\ell}(sm) = \I$]
        \item if $\hat{\ell}(s) = \I$ and $\lh(s)$ is odd then for all $m$, $\hat{\ell}(sm) = \I$
        \item if $\hat{\ell}(s) = \II$ and $\lh(s)$ is even then for all $m$, $\hat{\ell}(sm) = \II$
        \item if $\hat{\ell}(s) = \II $ and $\lh(s)$ is odd then there is $m$ such that $\hat{\ell}(sm) = \II$
    \end{enumerate}

    We had $\ell_\alpha = \ell_{\alpha+1} = (\ell_\alpha)^+$, so 3 and 4 follow immediately from the recursion definition of $\ell^+$.

    Similarly, if $\hat{\ell}(s) = \I$ and $\lh(s)$ is even then $s\not\in \textrm{dom}(\ell_\alpha)$. This implies there is an $m$ such that $sm \not\in \textrm{dom}(\ell_\alpha)$, so $\hat{\ell}(sm) = \I$. 2 is similar.]

    \underline{Subclaim 2}: If $\hat{\ell}(\emptyset) = \I$, then $Q_\I$ is a w.q.s for $\I$.

    [Need to show that $[Q_\I] \subset A$. So fix some $x \in [Q_\I]$. So for all $x$,
    \begin{align*}
        x\restriction u \in Q_\I &\implies \hat{\ell}(x\restriction u) = \I\\
        &\implies \hat{\ell}(x\restriction u)\ne \II\\
        &\implies \ell(x\restriction u)\not\in \II\\
        &\implies x\restriction u \in T
    \end{align*}
    So $x \in A$.]


\begin{remark*}: What we have done so far hasn't really needed trees/closed sets. Instead, we could let $$\ell :M^\lom \ra \{\II\}$$ be any partial labelling. Do the transfinite recursion $\ell_{\alpha+1} \coloneqq (\ell_\alpha)^+$, $\ell_0 \coloneqq \ell,\dots$, find fixed point $\ell_\alpha$; define $\hat{\ell}$, define $Q_\I$. Then $\Q_\I$ is a q.s. that avoids all $s \in \textrm{dom}(\ell)$.
\end{remark*}

For player II, it is not always the case that $Q_\II$ is winning [\it{c.f.} Example 12 on ES\#1] since you could stay on labels II without ever leaving the tree. So, we need to work slightly harder and find a sub-quasistrategy that is in fact winning.

Recall the age function:
\begin{align*}
    &\textrm{age}:Q_\II \ra \alpha + 1\\
    &\textrm{age}(s) \coloneqq \textrm{the least }\beta\textrm{ such that } s \in \textrm{dom}(\ell_{\beta})
\end{align*}
This means:
\begin{align*}
    \textrm{age}(s) =  0 &\iff s \in \textrm{dom}(\ell_0) = \textrm{dom}(\ell)\\
    &\iff s\not\in T
\end{align*}

\underline{Subclaim 3}: If $\hat{\ell}(s) = \II$ and $\lh(s)$ is even, then if $\textrm{age}(s) = 0$ or for all $m$, $\textrm{age}(sm) < \textrm{age}(s)$. If $\hat{\ell}(s) = \II$ and $\lh(s)$ is odd then either $\textrm{age}(s) = 0$ or there is $m$ such that $\textrm{age}(sm) < \textrm{age}(s)$.

[This follows directly from the recursive construction step.]

Now define $\hat{Q}_\II \subset Q_\II$ by:
\begin{itemize}
    \item $\emptyset \in \hat{Q}_{\II}$
    \item $sm \in \hat{Q}_\II :\iff \textrm{age}(sm) = 0\textrm{ or }sm \in Q_\II \textrm{ and }\textrm{age}(sm) < \textrm{age}(s)$
\end{itemize}

Informatlly, playing by $\hat{Q}_\II$ means: ``play into positions labelled II reducing the age if you can''.

If $\hat{\ell}(\emptyset) = \II$, then by Subclaim 3 $\hat{Q}_\II$ is a q.s.

\underline{Subclaim 4}: If $\hat{\ell}(\emptyset) = \II$, then $\hat{Q}_\II$ is winning for II: $[\hat{Q}_\II]\cap A = \emptyset$.

[Suppose $x \in [\hat{Q}_\II]$. Consider $a_n \coloneqq \textrm{age}(x\restriction n)$. This is a decreasing sequence of ordinals until it hits 0 by construction of $\hat{Q}_\II$. Since no infinite, strictly decreasing sequence of ordinals exists, we find $k$ such that $a_k = \textrm{age}(x\restriction k) = 0$. This implies $x\restriction k \not \in T$, hence $x\not\in A$.]

This finishes the claim, and hence concludes the entire proof.
\end{proof}

\begin{remark*}
    If $M$ is wellorderable (\it{e.g.} $M = \N$), then GST says that every closed subset of $M^\om$ is determined, and also that every complement of a closed set is determined. [Follows directly from the proof.]
\end{remark*}

Recall our motto/hope from the end of lecture 2: if a set is \it{nice} or \it{simple}, then it is determined. If by `nice' we mean closed, then this is just GST.

\underline{Next goal}: Define a topology on $M^\lom$.

Let's focus on the case $M = \N$, or even $M = 2 = \{0,1\}$.

\begin{defin*}[Baire Space]
    If $x,y \in \om^\om$, we can define
    \begin{align*}
        d(x,y) \coloneqq \left\lbrace \begin{array}{cc} 0\quad & \textrm{ if }x = y\\ 2^{-m} & \quad \textrm{ if }x\restriction m = y\restriction m\textrm{ and }x(m)\ne y(m) \end{array}\right.
    \end{align*}
    which is a metric on $\om^\om$.

    What are the open balls for this metric? Let $\eps = 2^{-n}$:
    \begin{align*}
        B_\eps(x) &= \{y\in \om^\om : d(x,y) < \eps\}\\
        &= \{y; y\restriction (n+1) = x \restriction (n+1)\}
    \end{align*}
    In particular, the open balls are determined by finite sequences.

    If $s \in \om^\om$, write:
    \begin{align*}
        [s]\coloneqq \{x \in \om^\om ;s \subset x\}
    \end{align*}
    So $B_{2^{-n}}(x) = [x\restriction (n+1)]$. Thus the topology of the metric space is generated by the basic open sets $\{[s];s \in \om^\om\}$.

    This topological space on $\om^\om$ is called \undf{Baire space}. If we restrict to $2^\om$, then it is called \undf{Cantor space}.
\end{defin*}

If you think of $\om^\om$ as $$\prod_{i\in \om}Y_i$$ with $Y_i = \om$, and $2^\om$ as $$\prod_{i\in \om}Y_i$$ with $Y_i = 2 = \{0,1\}$, then Baire space is just the product topology on $\prod_{i\in \om}X_i$ with the discrete topology on $\om$, and Cantor space is the product topology on $\prod_{i\in \om}Y_i$ with the discrete topology on 2.

Tychonoff implies that Cantor space is compact, but Baire space is not. Indeed, the latter can even by seen with Tychonoff:
\begin{align*}
    \om^\om = \bigcup_{m\in \om}[<m>]
\end{align*}
Since $[<m>] = \{x;x(0)=m\}$, this union is disjoint so this open cover clearly has no finite subcover, and tells us that Baire space is (very) disconnected.

Next time, we show that $A = [T] \subset \om^\om \iff A$ is closed in Baire space.

\marginpar{Lecture 7}

We now study the Baire space and Cantor space in detail. Firstly, consider convergence:

\begin{align*}
    x_n \ra x &\iff \forall \eps\ \exists N\ \forall x > N\ d(x_n,x) < \eps\\
    &\iff \forall m\ \exists N \ \forall n>N\ d(x_n,x) < 2^{-m} \\
    &\iff \forall m\ \exists N\ \forall n > N\ x_n\restriction m  = x\restriction m
\end{align*}
If $A\subset \om^\om$, we can define
\begin{align*}
    T_A \coloneqq \{x\restriction n; x \in A, n \in \N\}
\end{align*}
\underline{Observe}: $A \subset [T_A]$, since $x \in A \implies x\restriction n \in T_A\textrm{ for all }n\implies x \in [T_A]$.

\begin{remark*}[Proposition]\emph{
$[T_A]$ is the closure of $A$, \it{i.e.} $\{x;\exists(x_n)\textrm{ with }x_n\in A\textrm{ and }x_n\ra x\}$
}
\end{remark*}
\begin{proof}
    Suppose $x_n \in A$ and $x_n\ra x$. By our characterisation of convergence, this means that $x\restriction k = x_n\restriction k$ for some $n$, so $x\restriction k \in T_A$. Since $k$ was arbitrary, we have that $x \in [T_A]$.

    Conversely, suppose that $x \in [T_A]$. For every $k \in \N$, $x\restriction k \in T_A$, so there is some $x_k \in A$ such that $x\restriction k = x_k\restriction k$. Then again by the characterisation of convergence, we have that $x_k \ra x$. So $x$ is in the closure of $A$.
\end{proof}
\begin{remark*}[Corollary]
    $A\subset \om^\om$ is closed $\iff (\exists T)(A = [T])$ (we know that $T\coloneqq T_A$ does it).

    This is sometimes known as the \undf{tree representation theorem for closed sets}.
\end{remark*}

Some more topological properties:

Basic open sets are $[s] = [T_s]$, where $T_s \coloneqq \{t;s\subset t\textrm{ of }t\subset s\}$. So basic open sets are closed; we call these \undf{clopen}. Spaces like this are called \undf{zero-dimensional}

If $x \in \om^\om$, then $\{x\} = [T_x]$, with $T_x \coloneqq \{x\restriction n;n\in \N\}$. So singletons are closed, and not open.

We can easily see that this set is \undf{Hausdorff}: if $x \ne y$, find $n$ such that $x\restriction n \ne y \restriction n$. Then $x \in [x\restriction n]$, $y \in [y\restriction n]$, but $[x\restriction n]\cap[y\restriction n] = \emptyset$.

\underline{Continuous Functions}: [proof on ES\#2] If $g:\om^\lom \ra \om^\lom$ such that:
\begin{enumerate}
    \item $g$ is order-preserving, \it{i.e.} $s\subset t \ra g(s)\subset g(t)$
    \item $g$ is ``unbounded'', \it{i.e.} if $x \in \om^\om$, then $\lh(g(x\restriction n))\ra\infty$
\end{enumerate}
then define $$\hat{g}(x) \coloneqq \bigcup_{n\in \N}g(x\restriction n)$$ which is a function $\om^\om$.

\begin{remark*}[Proposition]
    $f:\om^\om$ is continuous iff there is $g:\om^\lom \ra \om^\lom$ with 1 \& 2 satisfied such that $f = \hat{g}$
\end{remark*}

The \undf{rule of thumb} here is that $f$ is continuous iff in order to determine $f(x)(k)$ you only need $x\restriction n$ for some finite $n$.

Now consider functions from $(\om^\om)^2$ to $\om^\om$ and vice versa and $\om^\om$ to $\om^\om$:
\begin{itemize}
    \item $x \mapsto x_\I$
    \item $x \mapsto x_{\II}$
    \item $(x,y)\mapsto x\ast y$
    \item $x \mapsto (x_\I,x_\II)$
\end{itemize}
These are all continuous. Moreover, we see that $(\om^\om)^2$ and $(\om^\om)$ are homeomorphic by $(x,y)\mapsto x\ast y$ with inverse $x\mapsto (x_\I,x_\II)$. This is unusual, and this phenomenon may explain the name \it{zero-dimensional}. [Similarly, $(\om^\om)^k \cong (\om^\om)^\ell$ for any $k,\ell > 0$]. 

\begin{theorem*}
    Baire space is homeomorphic to $\R\backslash \Q$.
\end{theorem*}
[The proof uses continued fractions: if $x \in \R\backslash \Q$, then there is a sequence $a_i \in \Z^\om$ such that $x = [0;a_0,a_1,a_2,\dots]$.]

So while topologically quite different from $\R$, Baire space is set-theoretically very close to $\R$: many set theoretic properties/proofs depend only on cardinality, and we have only removed a countable (dense) subset.

\begin{remark*}[Example]
    ES\#1 (4) has choice principles $\textrm{AC}_X(Y)$. These are invariant under replacing $X$ or $Y$ with $X',Y'$ such that $X$ is in bijection with $X'$ and $Y$ is in bijection with $Y'$.

    In particular,
    \begin{align*}
        \textrm{AC}_\om(\R) &\iff \ac_\om(\om^\om)\\
        &\iff \ac_\om(2^\om)\\
        &\iff \ac_\om(X)
    \end{align*}
    where $X$ is any set in bijection with $\R$.
\end{remark*}

In set theory, we often refer to elements of $2^\om$ or $\om^\om$ as ``reals'' and abuse the notation by sometimes writing $\R \coloneqq \om^\om$.

We now repeate our motto/hope: if $A$ is ``simple'', then $A$ is determined.

To make precise what `simple' means, we need a complexity hierarchy on Baire space:

\begin{defin*}[Borel Hierarchy]
    Let $X$ be any topological space. We then define \undf{[boldface] sigma zero one} as
    \begin{align*}
        \bm{\Sigma}_{0}^{1}\coloneqq \{A\subset X; A\textrm{ is open in }X\}
    \end{align*}
    Then if $\bm{\Sigma}^0_\alpha$ is defined, we define
    \begin{align*}
        \bm{\Pi}^0_\alpha \coloneqq \{X\backslash A; A \in \bm{\Sigma}^0_\alpha \}
    \end{align*}
    If $\alpha$ is an ordinal and for all $\gamma < \alpha$, $\bopi^0_\gamma$ is defined, then
    \begin{align*}
        \bosig^0_\alpha \coloneqq \{A; \exists (A_n)\textrm{ such that }\forall n\ A_n\in \bigcup_{\gamma<\alpha}\bopi^0_\gamma\textrm{ and }A = \bigcup_{n\in\N}A_n\}
    \end{align*}
    We also have
    \begin{align*}
        \bodel^0_\alpha \coloneqq \bosig^0_\alpha \cap \bopi^0_\alpha
    \end{align*}

    So we get the $\bosig$s from countable unions, and the $\bopi$s from complements.
\end{defin*}

\underline{Properties}: By definition, $\bodel ^0_\alpha \subset \bosig^0_\alpha,\bopi^0_\alpha$.

Moreover, by definition $\alpha \le \beta \implies \bosig^0_\alpha \subset \bosig^0_\beta$. This also gives us that $\bopi^0_\alpha \subset \bopi^0_\beta$.

To see the full structure of the hierarchy, we need to show that for $\alpha < \beta$, $\bopi^0_\alpha \subset \bosig^0_\beta$ (equivalently, $\bosig^0_\alpha \subset \bopi^0_\beta$). This follows from the definition of $\sigma^0_\beta$ by letting $A_n\coloneqq A$, so $\bigcup_{n\in \N}A_n = A$.

\underline{Question}: When does the Borel hierarchy terminate? This will, of course, depend on the topological space.

\marginpar{Lecture 8}

\begin{defin*}[$G_\delta$ space]
    A topological space is called a \undf{$G_\delta$ space} if $\bopi^0_1 \subseteq \bopi^0_2$. That is to say, `every closed set is a $G_\delta$ set'.
\end{defin*}

\underline{Note}: every metric space is a $G_\delta$ space.

For Cantor and Baire space, we proved that there is a countable topology base of clopen sets, and this implies being in $G_\delta$.

\begin{remark*}[Proposition]
    If $X$ has a countable, clopen topology base then $X$ is $G_\delta$.
\end{remark*}
\begin{proof}
    Let $F\subset X$ be closed, and let $G = X\backslash F$; $G$ is open. For every $x \in G$, find $B_x$ in the topology base such that $x \in B_x\subset G$. Since $B_x$ is clopen, $X\backslash B_x$ is also open.

    Now consider $\{B_x ; x \in G\}$. This is countable, since the basis is countable, so write it as $\{B_n; n\in \N\}$. Then $F = \bigcap_{n\in\N}X\backslash B_n \in \bopi_2^0$.

    Note that since countability implies wellorderability, no choice is needed.
\end{proof}

This is slightly irrelevant to what we wanted to do, but it felt like it was worth covering.

In principle, the Borel Hierarchy is defined on arbitary spaces, but it of course cannot go on forever; it must terminate on some ordinal, and this may differ between spaces.

\underline{Question}: By the Axiom of Replacement, the Borel Hierarchy termiantes at some ordinal $\alpha$ [\it{i.e.}, $\bosig_\alpha^0 = \bopi_\alpha^0$]; what can we say about $\alpha$?

The upper bound that we get by just using Replacement is pretty bad.

\begin{remark*}[Observations]\ 
    \begin{enumerate}
    \item If $X$ is discrete, then every subset of $X$ is clopen, so $$\bodel_1^0 = \bosig_1^0 = \bopi_1^0$$
    \item If singletons are closed and $X$ is countable, then $$\bodel_2^0 = \bosig_2^0 = \bopi_2^0$$
    
    [If $A = \{x; x \in A\}$ is countable, then $A = \bigcup_{x\in A}\{x\}$] 
    \end{enumerate}
\end{remark*}

We can obtain a better upper bound than by the cardinality of $X$.

\begin{remark*}[Proposition (ZFC)]
    \emph{
    For arbitrary $X$, $\bodel_{\aleph_1} = \bosig_{\aleph_1} = \bopi_{\aleph_1}$.
    }
\end{remark*}
\begin{proof}
    It is enough to show that $$ \bosig_{\aleph_1}^0 = \bigcup_{\alpha < \aleph_1} \bopi_{\alpha}^0$$
    The $\supseteq$ inclusion is clear. For the other direction, consider the following.

    If $A \in \bosig_{\aleph_1}^0$, there are $A_n$ such that $A = \bigcup_{n\in\N}A_n$ and $\alpha_n < \aleph_1$ such that $A_n \in \bopi_{\alpha_n}^0$. Since $\aleph_1$ is a regular cardinal, every countable subset $A \subset \aleph_1$ is bounded, \it{i.e.} there is $\beta < \aleph_1$ such that $A\subset \beta$.

    So we then look at the countable subset $\{\alpha_n ; n \in \N\}\subset \aleph_1$, and find for it a countable bound $\beta < \aleph_1$. Then $\{\alpha_n ; n\in\N\} \subset \beta$. Then for all $n$, $A_n \in \bigcup_{\alpha < \beta}\bopi_\alpha^0$. Hence $A \in \bosig_{\beta+1}^0\subset \bopi_{\beta+2}^0$. But $\beta+2$ is still countable, so $A$ is in the union as in the claim.

    The AC required was in showing that $\aleph_1$ is regular.
\end{proof}

Hence the height of the Borel hierarchy (in ZFC) is $1 \le \beta \le \aleph_1$.

\begin{theorem*}[ZFC]
    If $X$ is Cantor space, Baire space or $\R$, then the height of the Borel hierarchy is $\aleph_1$.

    [This is not just the case for these spaces; in general, this holds if $X$ is an uncountable Polish space.]
\end{theorem*}

This means that if $\alpha < \aleph_1$, then $\bosig_{\alpha}^0 \ne \bopi_{\alpha}^0$. The proof of the theorem uses the \undf{method of universal sets}.

\begin{defin*}[Pointclass]
    A \undf{pointclass} is an operation that assigns to each topological space $X$ a set of subsets of $X$.
\end{defin*}
\begin{remark*}[Examples]\ 
    \begin{itemize}
        \item ``open''/$\bosig_1^0$
        \item ``closed''/$\bopi_1^0$
        \item $\bosig_\alpha^0/\bopi_\alpha^0/\bodel_\alpha^0$
    \end{itemize}
\end{remark*}
If $\Gamma$ is a pointclass, we define ${\breve \Gamma}$ by $$\bg(X) \coloneqq \{X\backslash A; A \in \bg(X)\}$$ called the \undf{dual pointclass} of $\Gamma$, pronounced ``Gamma dual'', and $\Delta_\Gamma$ by $$\Delta_\Gamma(X)\coloneqq \Gamma(X) \cap \bg (X)$$ called the \undf{ambiguous pointclass} of $\Gamma$.

For example, $\bopi_\alpha^0$ is $\br{\bosig_\alpha^0}$, and $\bodel_\alpha^0$ is  $\Delta_{\bosig_{\alpha}^0}$ (and $\Delta_{\bopi_\alpha^0}$).

\subsection*{Closure Properties of Pointclasses}

\begin{center}
    \begin{tabular}{cc|c}
        & YES & NO\\
        closed under finite unions & $\bosig_\alpha^0,\bopi_\alpha^0,\bodel_\alpha^0$& \\
        closed under finite intersections &$\bosig_\alpha^0,\bopi_\alpha^0,\bodel_\alpha^0$ & \\
        closed under countable unions & $\bosig_{\alpha}^0$ & $\bopi_\alpha^0,\bodel_\alpha^0$ \\
        closed under countable intersections &$\bopi_\alpha^0$ &$\bosig_\alpha^0,\bodel_\alpha^0$ \\
        closed under complements &$\bodel_\alpha^0$ &$\bosig_{\alpha}^0,\bopi_\alpha^0$ \\
    \end{tabular}
\end{center}
Here, `no' means `if the space is Baire space and $\alpha$ is countable then no' (\it{i.e.} correctly chosen $\alpha$ and space $X$).

These properties are entirely local; we have another closure property that links the meaning of pointclasses in different spaces.

We say that $\Gamma$ is \undf{closed under continuous pre-images} if whenever $f : X \ra Y$ is continuous and $A \in \Gamma(Y)$, then $f^{-1}[A] \in \Gamma(X)$. This property is also called \undf{boldface}; this is silly because the notion has been named after the notation used. A simple inductive argument shows that this is consistent with the `boldface' notation we have been using for the Borel classes $\bosig_\alpha^0$, $\bopi_\alpha^0$, $\bodel_\alpha^0$.

Similarly, $\Gamma$ is \undf{closed under continuous images} if whenever $f : X \ra Y$ is continuous and $A \in \Gamma(X)$ then $f[A] \in \Gamma(Y)$.

We're going to talk more about continuous images in Lectures 9 \& 10.

By restricting our focus to boldface pointclasses, we eliminate any pathological issues whereby pointclasses among different spaces do not correspond in any way.

\begin{defin*}[]
    Let $X,Y$ be topological spaces, and $\Gamma$ a pointclass. A set $U \subset X \times Y$ is called \undf{$X$-universal for $\Gamma(Y)$} if:
    \begin{enumerate}
        \item $U \in \Gamma(X\times Y)$ (under the product topology)
        \item For every $A \in \Gamma(Y)$, there is some $x \in X$ such that $U_x = A$, where $U_x = \{y \in Y ; (x,y)\in U\}$ is the `section of $U$ at $x$'.
    \end{enumerate}
\end{defin*}

\begin{remark*}[Lemma]
    \emph
    {
        Suppose $U$ is $X$-universal for $\Gamma(X)$ and $\Gamma$ is boldface. Then $\Gamma(X) \ne \bg(X)$ (\undf{non-selfdual}).
    }
\end{remark*}
\begin{proof}
    Consider $X\times X\backslash U \in \bg(X\times X)$, and consider $x\mapsto (x,x)$ the diagonal map $X \ra X \times X$, which is continuous. Let $D\coloneqq \{x;(x,x)\not\in U\} \in \bg(X)$.

    Assume that $\Gamma(X) = \bg(X)$. Then find $d \in X$ such that $D = U_d$. Then
    \begin{align*}
        d \in D &\iff (d,d) \in U\\
        &\iff d \in U_d\\
        &\iff d\not\in D
    \end{align*}
    which is a contradiction.
\end{proof}
This is once again a standard diagonalisation proof that one often encounters in Logic \& Set Theory, \it{e.g.} uncountability of the reals, the halting problem, \it{etc}...

In Lecture 9, will prove that for $\alpha < \aleph_1$, $\bosig_\alpha^0$ has an $\om^\om$-universal set. Then by the Lemma, this implies our theorem.

\marginpar{Lecture 9}

We will use AC fairly liberally, but keeping track of our uses of it when we are done.

\begin{proof} (Proof of Theorem).
    
    Proof by induction:
    \begin{itemize}
        \item Induction base $\bosig_1^0$
        \item Complementation step $\bosig \ra \bopi$
        \item Countable union step $\bopi \ra \bosig$
    \end{itemize}
    This will be done in three lemmas.

    \begin{remark*}[Lemma 1]\emph{
        There is an $\om^\om$-universal set for $\bosig_1^0(\om^\om$)
    }   
    \end{remark*}

    \underline{Proof of Lemma 1}: an open set is an arbitrary union of basic open sets. Since there are only countably many basic open sets, we can say this is in fact a countable union. So we can write $$P = \bigcup_{i\in I}[s_i]$$ where $I$ is a countable index set.

    Let $\{s_i ; i \in \N\}$ be your favourite enumeration of $\om^\lom$. Thus $\{[s_i];i\in\N\}$ is an enumeration of the basic open sets. Then define $$U\coloneqq \{(x,y); \exists i \in \N, (x(i)\ne 0)\land (s_i\subset y)\}$$

    This is univeral for $\bosig_1^0(\om^\om)$:
    \begin{enumerate}
        \item $U$ is open: if $(x,y)\in U$ then there is $i\in \N$ with $x(i)\ne 0$ and $s_i\subset y$. Define $t = x\restriction (i+1)$. Then $[t,s_i]\subset U$. Note that we haven't exactly defined basic open sets on Baire space squared, but the notation is intuitive/obvious.
        \item If $P$ is open, then let
        \begin{align*}
            x(i)\coloneqq \left\lbrace \begin{array}{cc} 1 & \textrm{ if }[s_i]\subset P\\ 0 & \textrm{ if }[s_i]\not\subset P\end{array}\right.
        \end{align*}
        Then $P = \bigcup_{x(i)\ne 0}[s_i]$. Thus $P = U_x$.
    \end{enumerate}
    Wo we are done. \qedhere

    \begin{remark*}[Lemma 2]\emph{
        If $U\subset X\times X$ is $X$-universal for $\Gamma(X)$, then $X\times X \backslash U$ is $X$-universal for $\bg(X)$.
    }
    \end{remark*}
    \underline{Proof of Lemma 2}: Obvious.

    \begin{remark*}[Lemma 3]\emph{
        Let $\lambda < \om_1$. Suppose that for each $\alpha < \lambda$, there is an $\om^\om$-universal set $U_\alpha$ for $\bopi_\alpha^0(\om^\om)$. Then there is an $\om^\om$-universal set for $\bosig_\lambda^0$.
    }
    \end{remark*}
    \underline{Proof of Lemma 3}:

    If $lambda$ is a successor ordinal, \it{i.e.} $\lambda = \mu + 1$, then let $\alpha_n \coloneqq \mu$ for all $n$. If $\lambda$ is a limit, pick a sequence $\alpha_n$ such that $\bigcup \alpha_n = \lambda$.

    Observe that if $A = \bigcup_{n\in\N}A_n$, where $A_n \in \bigcup_{\alpha < \lambda}\bopi_\alpha^0$, then I find (by ``postponing if necessary'') a sequence $A_n'\in \bopi_{\alpha_n}^0$ such that $$\bigcup_{n\in\N}A_n = \bigcup_{n\in\N}A_n'\qquad (\ast)$$

    To simplify notation, write $U_n \coloneqq U_{\alpha_n}$.

    \underline{Encoding countable sequences of $\om^\om$ by an element of $\om^\om$}:

    Take your favourite bijection $\lceil \cdot , \dot \rceil:\om\times \om \ra \om$. If $x \in \om^\om$ and $n \in \N$, define $(x)_n \in \om^\om$ by $(x)_n(m) \coloneqq x(\lceil n,m\rceil)$. Then $x\mapsto ((x)_n;n\in\N)$ is a bijection between $\om^\om$ and $(\om^\om)^\om$.
    
    Note also that the map $x\mapsto (x)_n$ is continuous, because we only require a finite amount of information to determine what $x$ at $n$ is, and by our earlier characterisation this means we have continuity.

    Now define $$U\coloneqq \{(x,y);\exists n((x)_n,y)\in U_n\}$$

    \underline{Claim}: $U$ is $\om^\om$-universal for $\bosig_\lambda^0$.
    \begin{itemize}
        \item $\overline{U}_n\coloneqq \{(x,y);((x)_n,y)\in U_n\}$ is the pre-image of $U_n$ under the continuous map $x,y\mapsto ((x)_n,y)$, so it's in $\bopi_{\alpha_n}^0$ [closure of the Borel classes under continuous pre-images]. But $U = \bigcup_{n\in\N}\overline{U}_n$, so $U$ is $\sigma_{\lambda}^0$.
        \item Let $A$ be $\sigma_\lambda^0$. By ($\ast$), we find $A_n \in \bopi_{\alpha_n}^0$ such that $A = \bigcup_{n\in\N}A_n$. By universality of $U_n$, we find $x_n$ such that $A_n = (U_n)_{x_n}$. Now fold up the sequence $(x_n;n\in \om)$ into a single element of $\om^\om$ such that $(x)_n = x_n$ for all $n$. We do this by defining $x(\lceil n,m\rceil)\coloneqq x_n(m)$.
        
        Here's the situation:
        \begin{enumerate}
            \item $A_n = (U_n)_{x_n}$ 
            \item $(x)_n = x_n$ 
            \item $A = \bigcup_{n\in\N}A_n$
            \item $U = \{(x,y);\exists n ((x)_n,y)\in U_n\}$
        \end{enumerate}

        \underline{Claim}: $U_x = A$:
        \begin{align*}
            y \in A &\xLeftrightarrow{3} \exists n\ y\in A_n\\
            &\xLeftrightarrow{1}\exists n\ y \in (U_n)_{x_n}\\
            &\xLeftrightarrow{ } \exists n\ (x_n,y)\in U_n\\
            &\xLeftrightarrow{2} \exists n\ ((x)_n,y)\in U_n\\
            &\xLeftrightarrow{4} (x,y)\in U\\
            &\xLeftrightarrow y \in U_x
        \end{align*}
    \end{itemize}
\end{proof}

\begin{remark*}[Corollary] \textbf{Borel Hierarchy Theorem}
\end{remark*}
\begin{proof}
    This is an inductive proof using L1 - L3. [Recursive definition of a $\om^\om$-universal set for $\bosig_{\lambda}^0$ for each $\lambda < \om_1$.]
\end{proof}

\begin{remark*}
    Let's check how much choice we used.

    \underline{Lemma 1} is a ZF theorem.

    \underline{Lemma 2} is a ZF theorem.

    \underline{Lemma 3}: $\lambda \mapsto $ pick $\alpha_n$ such that $\bigcup \alpha_n = \lambda$; if $\lambda$ fixed, no choice is needed. However, after declaring that there \it{exists} a universal set $U_n$ for each $n$, we then picked a concrete example of one for each $n$ to play around with. So this needed choice. Perhaps it would have been more prudent to simply formulate Lemma 3 by just assuming that there exists a choice function \it{only where we need it} for the universal sets. Then we don't need to use the more general Axiom of Choice.

    We also made another choice in the presentation of $A_n$; if $A \in \bosig_\lambda^0$, then $$S_A\coloneqq \{(A_n)_n; A = \bigcup_{n\in\N}A_n\}\ne\emptyset$$ for every such $A$, so we use a choice function for this family too.

    But we are still not done; while we didn't need choice for $\lambda$ fixed in Lemma 3, we have to use Lemma 3 infinitely many times in the proof of the corollary; so we need choice to pick for each limit $\lambda < \om_1$ a sequence $\alpha_n$ in order to apply L3.
\end{remark*}

Back to games.

\underline{Notation}: if $\Gamma$ is a pointclass, write $\Det(\Gamma)$ for ``$\forall A \in \Gamma(\om^\om)$, $A$ is determined''.

G-S proved $\Det(\bopi_1^0)$. The proof also implies $\Det(\bosig_1^0)$.

ES\#1 (11): in general, the class of determined sets is not closed under complementation.

ES\#1 (10): if a pointclass $\Gamma$ is closed under the operation $A\mapsto \{mx;x\in A\}$, then $\Det(\Gamma) \implies \Det(\bg)$. Note that Borel pointclasses are closed under this operation.

Wolfe (1955) proved $\Det(\bosig_2^0)$; Davis (1964) proved $\Det(\bosig_3^0)$; Paris (1972) proved $\Det(\bosig_4^0)$.

Friedman proved that you cannot prove $\Det(\bosig_5^0)$ without using iterations of the power set axiom. This paved the way for Martin (1975) to prove that \it{all} Borel sets are determined.

\marginpar{Lecture 10}

The Borel sets, from the point of view of the ordinary analyst, look extremely complicated already. So while they are not all the sets, you might expect that all `reasonable' (for some definition of reasonable) sets \it{are} Borel, so a proof that every Borel set has some property is in practice equivalent to proving that all sets have that property. But this might not be the case, which begs that question: what \it{is} the size of the set of Borel sets?

Denote the set of all Borel sets by $\mathcal{B}$. Clearly then $|\mathcal{B}| \le 2^{2^{\aleph_0}}$, but we can show that it is in fact much smaller:

\begin{theorem*}\textbf{(ZFC)}
    $$|\mathcal{B}| = 2^{\aleph_0} < 2^{2^{\aleph_0}}$$
\end{theorem*}
\begin{proof}
    Since $\{x\}\in \mathcal{B}$ for every $x \in \om^\om$, $x\mapsto \{x\}$ is an injectino from $\om^\om$ into $\mathcal{B}$. So $2^{\aleph_0} \le |\mathcal{B}|$.

    \underline{Upper Bound}: Proof by induction.

    We prove that $|\bosig_\alpha^0| = 2^{\aleph_0}$ for all $\alpha$. This then implies the Theorem:

    $$ |\mathcal{B}| = \left|\bigcup_{\alpha < \om_1} \bosig_{\alpha}^0 \right| \le \aleph_1 \cdot 2^{\aleph_0} = 2^{\aleph_0}$$

    \underline{Base case}: for $\bosig_{1}^{0}$, every open set is of the form $$\bigcup_{i\in I}[s_i]$$ where $I\subset \N$ and $s_i$ is our enumeration of $\om^\lom$. So $I\mapsto \bigcup_{i\in I}[s_i]$ is a surjection from $\mathcal{P}\N$ onto $\bosig_{1}^{0}$. Hence $|\bosig_1^0| \le 2^{\aleph_0}$.

    Going from $\bosig \ra \bopi$ is easy , since $A\mapsto \om^\om \backslash A$ is a bijection between $\bosig_\alpha^0$ and $\bopi_\alpha^0$, hence $|\bosig_\alpha^0| = |\bopi_\alpha^0|$.

    From $\bopi \ra \bosig$: Suppose for each $\alpha < \lambda$, we have $|\bopi_\alpha^0| \le 2^{\aleph_0}$. Using AC, pick surjections $s_\alpha : \om^\om \twoheadrightarrow \bopi_\alpha^0$. Define surjection $S$ by
    \begin{align*}
        S : \lambda^\om \times \om^\om &\ra \bosig_\lambda ^0 \\
        ((\alpha_i;i\in \om),x)&\mapsto \bigcup_{i\in \N}S_{\alpha_i}((x)_i)
    \end{align*}
    This clearly is a surjection. Since $\lambda$ is countable, $|\lambda^\om| = 2^{\aleph_0}$. So $|\lambda^\om \times \om^\om| = 2^{\aleph_0}$.
\end{proof}

\begin{remark*}
    We used AC in this proof, and that is not avoidable; consider the \undf{Feferman-Levy Model $\M$}, which models the theory `ZF + ``$\R$ is a countable union of countable sets'''.

    In the FL model, $\R = \bigcup_{n\in\N}A_n$. So if $X \subset \R$, then $X = \bigcup_{n\in\N} A_n\cap X$. Since $A_n\cap X \subset A_n$, this is still countable. Hence, in this model, every subset of the reals is a countable union of countable sets. Now, all countable sets are Borel since they are a countable union of closed sets. But the Borel sets are closed under countable unions, so this means that \it{every} set is Borel. In particular, $|\mathcal{B}| = \mathcal{P}\R$. So we needed AC after all.
\end{remark*}

So the Borel sets are in fact only a very small part of the collection of all sets in Baire space. What else is out there?

\undf{The famous mistake of Henri Lebesgue}.

Measures are defined on $\sigma$-algebras $\mathcal{A}$. In general, $\mathcal{A} \ne \mathcal{P}\R$. [Involves AC; Vitali set is a non-Lebesgue-measurable set that can be constructed AC.]

The smallest $\sigma$-algebra, namely the Borel $\sigma$-algebra (the smallest one containing the open sets), is the minimal setting for measures, and Lebesgue made an argument for this:

\begin{remark*}[Lebesgue]
    \emph{
        ``All sets we care about are Borel.''
    }
\end{remark*}

He believed that if $f:\R \ra \R$ is continuous and if $A\subset \R$ is Borel, then $f[A]$ is Borel. However, this is in fact FALSE.

The mistake was spotted in 1917, when when Suslin proved that there are non-Borel sets which are continuous images of Borel sets - these are called \undf{analytic sets}. We can in fact prove this. We don't even need the continuous functions to be complicated at all (projection).

\begin{defin*}[Projection]
    Let $A\subset X^{n+1}$. Then we call $$B = \{(x_1,\dots,x_n); \exists x \in X (x,x_1,\dots,x_n)\in A\}$$ the \undf{projection} of $A$. Write $pA = B$.

    The map $$\pi : (x,x_1,\dots,x_n) \mapsto (x_1,\dots,x_n)$$ is clearly continuous, so $pA = \pi[A]$, and thus projections are indeed special cases of continuous images.
\end{defin*}

\begin{defin*}
    Let $\Gamma$ be a pointclass. We define $\exists^{\om^\om} \Gamma$ a pointclass by:
    \begin{align*}
        \exists^{\om^\om}\Gamma(X) \coloneqq \{pA; A \in \Gamma(\om^\om\times X)\}
    \end{align*}

    We say $\Gamma$ is \undf{closed under projections} if $\eomg \subset \Gamma$.
\end{defin*}

Suslin's Theorem now says: ``the pointclass BOREL is not closed under projections''.

\begin{defin*}[The Projective Hierarchy]
    We start by defining $\bopi_0^1(\om^\om) = \bopi_1^0(\om^\om)$. [Note that if $X \ne \om^\om$, this won't necessarily be the right starting point; we might want to use $\bopi^0_2$ instead.]

    We then define 
    \begin{align*}
        \bosig_{n+1}^1 &\coloneqq \eom \bopi_n^1\\
        \bopi_{n+1}^1 &\coloneqq \breve{\bosig}_{n+1}^1
    \end{align*}

    $\bosig_1^1$ is called the \undf{analytic sets}, and $\bopi_1^1$ is called the $\undf{co-analytic sets}$.

    We also define
    \begin{align*}
        \bodel_n^1(X) \coloneqq \bosig_n^1 (X) \cap \bopi_n^1(X)
    \end{align*}
\end{defin*}

Lebesgue believed that all of these were contained in $\mathcal{B}$; he was wrong. We already have the technique to prove this, which is the technique of universal sets.

\begin{theorem*}
    The projective hierarchy does not collapse.
\end{theorem*}
\begin{proof}
    Using the technique of universal sets. we know that $\bopi_0^1 = \bopi_1^0$ has a universal set. We know that if $\bosig_n^1$ has a universal set, then $\bopi_n^1$ has a universal set. So all that is left to show is that if $V$ is universal for $\bopi_n^1$, then we can find $U$ universal for $\bosig_{n+1}^1$.

    Let $V\subset \om^\om \times \om^\om \times (\om^\om)^k$ be universal fotr $\bopi_n^1$. Define $$U \coloneqq \{(0,\vec{x})\in \om^\om \times (\om^\om)^k; \exists v \in \om^\om (u,v,\vec{x}) \in V\}$$
    It is clear that $U \in \bosig_{n+1}^1(\om^\om \times (\om^\om)^k)$, and the same $x$ that is the code for the set $A$ [in $V$] is the code for $pA$ in $U$.
\end{proof}

\begin{remark*}[Proposition]
\emph{
    Every Borel set is $\bosig_1^1$
}    
\end{remark*}
\begin{proof}
    (ES\#2)
\end{proof}

\begin{remark*}[Corollary]
    \emph{
        Suslin's Theorem: there is a $\bosig_1^1$ set that is not Borel.
    }
\end{remark*}

\underline{Question}: Does $\Det(\bosig_1^1)$ hold? Perhaps $\bosig_2^1$, or $\bosig_3^1$ \it{etc...}? These questions are much more interesting set-theoretically. These are not ZFC theorems, but are closely connected to:
\begin{enumerate}
    \item Large Carindal Axioms
    \item Definability of wellorders of $\om^\om$
\end{enumerate}
These are the two topics that will cover the remainder of this course.

\marginpar{Lecture 11}

\section*{Applications of Infinite Games}

\subsection*{The Continuum Problem}

The first, and arguably the most significant application, is to the famous Continuum Hypothesis: $2^{\aleph_0} = \aleph_1$.

In ZFC, there is an equivalent formulation of the problem, which is that every uncountable set of reals $(A\subset \om^\om)$ is in bijection with the set of all reals. $(\ast\ast)$

Note that the first formulation implies that $\om^\om$ is wellordered, whereas the second one does not. So we may think of the second formulation as the choice-free version of CH.

\begin{defin*}[Perfect Set Property]
    We say that a set $A\subset \om^\om$ has the \undf{perfect set property} if it is either countable or there is a perfect tree $T$ such that $[T]\subset A$
\end{defin*}
\begin{remark*}
    Since every perfect set $[T]$ has size $2^{\aleph_0}$, having the perfect set property implies not being a counterexample to $(\ast\ast)$.
\end{remark*}
\begin{theorem*}[Cantor-Bendixson]
    Every uncountable closed set of reals contains a non-empty perfect subset.

    Equivalently, every closed set has the perfect set propety.
\end{theorem*}
\begin{proof}[Sketch.]
    Take $A\subset \om^\om$, remove isolated points to obtain $A' = \{x\in A;x\textrm{ is not isolated}\}$, also known as the \undf{Cantor-Bendixson derivative}. But removing isolated points might create new isolated points, so we need to repeat this:

    $A_0 = A$, $A_{\alpha+1} = (A_\alpha)'$, $A_\lambda \coloneqq \bigcap_{\alpha < \lambda}A_{\alpha}$. Since $\om^\om$ is second countable, each $A_{\alpha+1} \backslash A_\alpha$ is countable. There is then a fixed point $A_\beta = A_{\beta+1}$, with $\beta < \aleph_1$.
    
    \underline{Case 1}: $A_\beta = \emptyset$. Then $A$ was countable.

    \underline{Case 2}: $A_\beta \ne \emptyset $ and is perfect.
\end{proof}
This was one of the first proofs requiring a transfinite recursion, and as such was very important for the development of ordinals and set theory.

\begin{defin*}
    If $\Gamma$ is a pointclass, write $\psp(\Gamma)$ to mean ``for every $A \in \Gamma$, $A$ has the p.s.p.''
\end{defin*}

Cantor-Bendixson now says $\psp(\bopi_1^0)$.

\begin{defin*}
    Write $\psp$ for ``every set has the p.s.p.''
\end{defin*}

\underline{Observation}: $\psp \implies \textrm{CH}$. [In the case of $(\ast\ast)$.]

\begin{theorem*}[Bernstein]
    $$\ac \implies \neg\psp$$
\end{theorem*}
[So, this approach is not going to solve the Continuum Problem, unless you are willing to give up AC.]

We already saw the proof of this theorem when we constructed a non-determined set using AC; just replace the notion of `strategic tree' with `perfect tree'.

\begin{theorem*}[Hausdorff]
    PSP(Borel)
\end{theorem*}

We are going to prove Hausdorff's Theorem from Borel determinacy, using games.

\begin{theorem*}
    If $\Gamma$ is a boldface pointclass, then $\Det(\Gamma)\implies \psp(\Gamma)$.
\end{theorem*}
\begin{proof}
    For technical simplicity, we do this on Cantor space.

    So fix $A\subset 2^\om$. We define the \undf{asymmetric game $G^\ast(A)$} played with moves in $2^{\lom}$ by player I and moves in $2$ by player II:

    \gamec{s}{b}

    If $z = (s_0,b_0,s_1,b_2,\dots) \in (2^\lom \cup 2)^\om$, we form $z^\ast = s_0b_0s_1b_1\dots \in 2^\om$ by concatenation. We then say player I wins if $z^\ast \in A$.

    \underline{Notation}: a \it{position} in the game has the form $p = (s_0,b_0,\dots,s_n/b_n)$ (depending on the parity of $n$). If $\tau$ is a strategy for II and $(s_0,\dots,s_n)$ is a sequence of elements of $2^\lom$, then $t\ast \tau$ is the position obtained by playing $\tau$ against $t$.

    If $p = (s_0,b_0,\dots,s_n,b_n),s\in 2^\lom$, $\tau$ is a strategy for II, write $ps\tau$ for the position obtained by playing $s$ \& $\tau$.

    \underline{Claim}: If $A \in \Gamma$ and $\Det(\Gamma)$ holds then $G^\ast(A)$ is determined.

    \underline{Proof}: Find $A^\ast \subset \om^\om$ such that $G(A^\ast)$ and $G^\ast(A)$ are the same game and $A^\ast$ is a continuous pre-image of $A$.

    Fix your favourite bijection $\pi : 2^\lom \ra \om$, and define for $x \in \om^\om$:
    \begin{align*}
        x^\pi(n) \coloneqq \left\lbrace \begin{array}{cc}\pi(x(n))&\textrm{ if }n\textrm{ is even}\\ x(n)\mod 2&\textrm{ if }n\textrm{ is odd}\end{array}\right.
    \end{align*}
    Then $x^\pi$ is a run of $G^\ast(A)$. Define $A^\ast \coloneqq \{x\in\om^\om;(x^\pi)^\ast \in A\}$. Then $A^\ast$ is the preimage of the map $x\mapsto (x^\pi)^\ast$ of $A$. But this map is continuous, since we need only finite information to determine $x^\pi(n)$ from $x$. \qedsymbol

    We now continue the proof with some claims.

    \underline{Claim 1}: If player I has a winning strategy in $G^\ast(A)$, then $A$ contains a perfect subset.

    \underline{Proof of Claim 1}: By construction, a strategic tree for $G^\ast(A)$ is a perfect tree on $2$. \qedsymbol

    \underline{Claim 2}: If II has a winning strategy, then $A$ is countable.

    Let $p$ be a position, $x \in 2^\om$ and $\tau$ any strategy for II in $G^\ast(A)$. We say that $p$ is \undf{$\tau$-decisive for $x$} if, for $p = (s_0,b_0,\dots,s_n,b_n)$, $p^\ast = s_0b_0\dots s_nb_n \in 2^\lom$, we have $p^\ast \subset x$ but for all $ s \in 2^\lom$, $(ps\tau)^\ast \not\subset x$.
    [So $p$ is the `maximal' position consistent with $\tau$ \& $x$.] \qedsymbol

    \underline{Subclaim 2a}: If $\tau$ is winning for II, then for each $x\in A$ there is a $\tau$-decisive position $p$ for $x$.

    \underline{Proof of Subclaim 2a}: Suppose not. Then for every $p$ we find $s$ such that $ps\tau^\ast \subset x$. Recursively define a sequence $s = (s_i;i\in \N)$ such that $s_{i+1}$ is the witness that $(s_0,\dots,s_i)\ast \tau$ is not $\tau$-decisive. Then $s\ast \tau$ is a sequence that is entirely consistent with $\tau$, and $(s\ast \tau)^\ast = x \in A$. So $\tau$ is not winning. \qedsymbol

    \underline{Subclaim 2b}: Every position $p$ is $\tau$-decisive for at most one $x \in 2^\om$.

    \marginpar{Lecture 12}

    \underline{Proof of Subclaim 2b}: Let $p$ be $\tau$-decisive for $x$ and show that every $x(k)$ is determined uniquely by $p$ and $\tau$.

    By definition $p^\ast \subset x$. If $\ell \coloneqq \lh(p^\ast)$ and $ k < \ell$, then $x(k) = p^\ast(k)$, so determined by $p$.

    Consider now $x(\ell + n)$, where $n\in\N$. We determine this recursively:
    \begin{itemize}
        \item $x(\ell + 0) = x(\ell)$. If $s_0 \coloneqq \emptyset$, then $ps_0\tau^\ast \not\subset x$. $\lh(ps_0\tau^\ast) = \ell + 1$. So $ps_0\tau^\ast(\ell)\ne x(\ell)$. Thus $x(\ell) = 1 - ps_0\tau^\ast(\ell)$ [since we are in Cantor space].
        
        This determines $x(\ell)$ by just $p,\tau$.

        \item Assume we know $x(\ell + 0),\dots,x(\ell + n - 1)$ and determine $x(\ell + n)$.
        
        Let $s_n\coloneqq (x(\ell + 0),\dots,x(\ell + n - 1))$. So $\lh(s_n) = n$. Consider $ps_n\tau$. By decisiveness, we have $ps_n\tau^\ast\not\subset x$, of length $\ell + n + 1$. So by choice of $s_n$, we must have that $ps_n\tau^\ast(\ell + n)\ne x(\ell + n)$. Hence $x(\ell + n) = 1 - ps_n\tau^\ast(\ell + n)$.

        So, once more, $x(\ell + n)$ is determined just by $p$ and $\tau$. \qedsymbol
    \end{itemize}

    This concludes Subclaim 2b, hence Claim 2, and hence the theorem.
\end{proof}

\begin{remark*}[Corollary]
    \emph{
        ZFC $\proves$PSP(Borel)
    [Our proof is modulo Borel Determinacy, which we did not prove.]}
    \emph{Moreover}:
    \begin{itemize}
        \item $\Det(\bopi_1^1) \implies \psp(\bopi_1^1)$
        \item $\Det(\bopi_n^1) \implies \psp(\bopi_n^1)$
    \end{itemize}
\end{remark*}

This yields necessary conditions for axioms of determinacy in the projective hierarchy: if $\Det(\bopi_2^1)$, then we can't have $\bopi_2^1$ sets violating CH.

These conditions are non-trivial:

\begin{theorem*}[G{\"o}del-Addison]
    There is a model of ZFC + $\neg \psp(\bopi_1^1)$
\end{theorem*}
\begin{remark*}
    This is \undf{G{\"o}del's Construcible Universe}, usually denoted by $\mathbf{L}$. The reason for this is that $\mathbf{L}$ has a $\bodel_2^1$ wellorder of $\om^\om$.

    What does that even mean?
    
    If $\le$ is a wellorder of $\om^\om$, then it is a binary relation on $\om^\om$, so $\le \subset \om^\om\times\om^\om$.

    Therefore, it is perfectly reasonable to ask whether $\le \in \bodel^1_2((\om^\om)^2)$
\end{remark*}

Our next goal:

\begin{theorem*}
    If there is a $\bodel_n^1$ wellorder of $\om^\om$, then there is a set in $\bopi^1_n$ without the perfect set property.
\end{theorem*}

\begin{remark*}
    This is not optimal, as the G{\"o}del-Addison theorem shows.
\end{remark*}

Proving this theorem will require:
\begin{enumerate}
    \item a structural analysis of $\bopi^1_1$
    \item a relation between $\bopi^1_1$ and the ordinal $\om_1$
\end{enumerate}

\subsection*{Structure Theory of Co-Analytic Sets}

Tree representation theorem for closed sets:

$ A \in \bopi^0_1 \iff $ there is a tree $T$ such that $A = [T]$. ($\ast$)

The pointclass $\bosig^1_1$ was defined in terms of projections and closed sets. In particular,
\begin{align*}
A \in \bosig^1_1&\iff \exists C\in \bopi^0_1 \textrm{ s.t. } A = pC\\
&\xLeftrightarrow{(\ast)} \exists T\textrm{ tree s.t. }A = p[T]
\end{align*}

Let's slightly reformulate this. If $T$ is a tree on $\om \times \om$ and $x \in \om^\om$, we can define
\begin{align*}
    T_x\coloneqq \left\lbrace s; (s,x\restriction \lh(s))\in T\right\rbrace
\end{align*}
Then $A$ is $\bosig^1_1$ if and only if: $\exists T \textrm{ tree s.t. } x \in A \iff [T_x]\ne \emptyset$.

\begin{defin*}
    A tree $T$ is called \undf{illfounded} if $[T] \ne \emptyset$ and \undf{wellfounded} if $[T] = \emptyset$.

    With some axiom of choice, this is equivalent to $(T,\supseteq)$ being ill/wellfounded. So we can reformulate this as
    \begin{align*}
        A \in \bosig^1_1 \iff \exists T\textrm{ tree s.t. }\forall x(x\in A \iff T_x\textrm{ is illfounded})\\
        A \in \bopi^1_1 \iff \exists T\textrm{ tree s.t.}\forall x(x\in A \iff T_x\textrm{ is wellfounded})
    \end{align*}

    This is \undf{tree representation of analytic and co-analytic sets}.
\end{defin*}

\underline{Coding trees on $\om$ or $\om\times\om$ as elements of Baire space}:

Pick your favourite bijection between $\om\ra \om^\lom$ and write $\{s_i;i\in \om\} = \om^\lom$. Define $R$ by $iRj$ iff $s_i\supseteq s_j$. Then $F_T\coloneqq \{i;s_i \in T\}$. Then $(T,\supseteq)\cong (F_T,R)$. In particular, $T$ is wellfounded $\iff (F_T,R)$ is wellfounded.

One of the benefits of wellfounded relations is that we can define rank functions on them. If I have a wellrounded relation $R$ on $F$, I can recursively define a rank function:
\begin{itemize}
    \item $i\in F$: let rk$(i)\coloneqq \sup \{\rk(j)+1;jRi\}$
\end{itemize}
By the recursion theorem, if $R$ is wellfounded, then $\rk$ is a function assigning an ordinal to each element of $F$: $\{\rk(i);i\in F\}$ is an ordinal. But the $i$s in question are natural numbers, so this must be a countable ordinal.

We now identify our relation on subsets of $\om$ with elements of Baire space:
$$ \lceil n,m\rceil :\om\times\om\ra\om$$
your favourite bijcetion; $x \in \om^\om$. Define:
\begin{align*}
    \fld(x)&\coloneqq \{i;x(\lceil i,i\rceil) \ne 0\}\\
    R_x &\coloneqq \{(i,j); x(\lceil i,j\rceil)\ne 0\}
\end{align*}
Then $(\fld(x),R_x)$ is a reflexive relation.

If $(A,R)$ is any such structure, \it{i.e.} $A\subset \om$, $R\subset A\times A$ reflexive, then define
\begin{align*}
    x_A(\lceil i,j\rceil)\coloneqq \left\lbrace \begin{array}{cc} 1 & \textrm{ if }i,j\in A,iRj\\ 0 & \textrm{ o/w}\end{array}\right.
\end{align*}
Then $\fld(x_A) = A$, and $iRj\iff iR_{x_A}j$.

\marginpar{Lecture 13}

 \begin{defin*}
     $\wf\subset\om^\om$ is defined to be $$\wf \coloneqq \{x \in \om^\om ; (\fld(x),R_x)\textrm{ is wellfounded}\}$$

     Then the rank function $$\rk : \fld(x) \ra \alpha$$ gives an order-preserving map from $\fld(x)$ into $\alpha =: \hit(\fld(x),R_x)$, the \undf{height} of the relation.

     If $x \in \wf$, $||x|| \coloneqq \hit(\fld(x),R_x)$. This operation $||\cdot || : \wf \ra \omega_1$ is a surjection.

     [Indeed, let $\alpha < \omega_1$. There is some injection $f : \alpha \ra \N$. Define $F\coloneqq f[\alpha]$. Then define $f(\beta) R f(\gamma)$ by $\beta\le \gamma$. Then by construction $(F,R)\simeq (\alpha,\le)$. So if $A\coloneqq (F,R)$ and $x \coloneqq x_A$, then $||x_A|| = \alpha$.]

     Define:
     \begin{align*}
         \wf_\alpha &\coloneqq \{x \in \wf; ||x|| = \alpha \}\\
         \wf_{<\alpha} &\coloneqq \bigcup_{\beta<\alpha}\wf_\beta\\
         \wf_{\le \alpha} &\coloneqq \bigcup_{\beta\le\alpha}\wf_\beta
     \end{align*}
     Thus $\wf$ can be thought of as \undf{stratified} in $\om_1$ may levels.
 \end{defin*}

 \begin{theorem*}
     $\wf$ is $\bopi^1_1$.
 \end{theorem*}
 \begin{proof}
     If $A = (F,R)$ is a relation on $\N$, we can define ``$y\in\om^\om$ is an \undf{$A$-descending sequence}'' if $\forall i[(y(i+1)Ry(i))\land(y(i+1)\ne y(i))]$. Then $x\in \wf \iff \forall y\ y$ is not an $(\fld(x),R_x)$-descending sequence, and $x \not\in \wf\iff \exists y\ y$ is a $(\fld(x),R_x)$-descending sequence.

     Hence $ x \not\in \wf \iff \exists y [\forall i\ x(\lceil y(i+1),y(i)\rceil)\ne0\ \land\ y(i+1)\ne y(i)]$.

     Now consider $C\coloneqq \{(y,x); \forall i\ x(\lceil y(i+1),y(i)\rceil)\ne 0\ land\ y(i+1)\ne y(i)\}$. $C$ is closed in $\om^\om\times\om^\om$ (can easily check that these conditions form a tree). So by definition, $\om^\om \backslash \wf$ is $\bosig^1_1$, and hence $\wf$ is $\bopi^1_1$.
 \end{proof}

\begin{remark*}
    The general proof technique extracted from this is that if $C$ is $\bopi^1_x(\om^\om\times\om^\om)$ and $x \in A \iff \exists y (y,x)\in C$ then $A$ is $\bosig^1_{n+1}$, and similarly if $C$ is $\bopi^1_n$ and $x \in A \iff \forall y (y,x)\in C$ then $A$ is $\bopi^1_{n+1}$.
\end{remark*}

Now check the complexity of the sets $\wf_\alpha,\wf_{<\alpha},\wf_{\le\alpha}$. We have $x\in \wf_{<\alpha} \iff x \in \wf$ and there is no order-preserving map from $\alpha$ into $(\fld(x),R_x)$; define $$N_\alpha \coloneqq \{x; \textrm{ there is no o.p. map from }\alpha \textrm{ into } (\fld(x),R_x)\}$$

Fix some $a \in \om^\om$ such that $(\fld(a),R_a)\cong (\alpha,\le)$. [We saw that this exists.] Hence we have that
\begin{align*}
    N_\alpha =&\{x;\textrm{ there is no o.p. map from }(\fld(a),R_a)\textrm{ into }(\fld(x),R_x)\}\\
    =& \big\{x; \forall y\textrm{ it is not the case that: }\\
    &[\forall i\ a(\lceil i,i\rceil)\ne 0 \implies x(\lceil y(i),y(i)\rceil)\ne 0\textrm{ and }\forall i,j\ a(\lceil i,j\rceil)\ne0 \implies x(\lceil y(i),y(j)\rceil)\ne 0]\big\}
\end{align*}
So $N_\alpha$ is $\bopi^1_1$, and since $\wf_{<\alpha} = \wf \cap N_\alpha$, we thus have that $\wf_{<\alpha}$ is $\bopi^1_1$. Similarly, $\wf_{\le \alpha},\wf_\alpha$ are $\bopi^1_1$.

$\wf_{\le\alpha}$ is also $\bosig^1_1$: $\wf_{\le\alpha} = \{x; (\fld(x),R_x)\textrm{ o.p. maps into }(\fld(a),R_a)\}$. We can write this as:
\begin{align*}
    x \in \wf_{\le\alpha} &\iff \exists y[\forall i,j x(\bij{i,j})\ne 0\implies a(\bij{y(i),y(j)})\ne 0]
\end{align*}
and again we see the bit in square brackets defines a closed set of $x$s, and hence $\wf_{\le\alpha}$ is $\bosig^1_1$.

\underline{Summary}: For every $\alpha < \om_1$, $\wf_\alpha,\wf_{<\alpha},\wf_{\le\alpha}$ are $\bodel^1_1$.

On ES\#2, we show that $\bodel^1_1 = \textrm{Borel}$.

\begin{remark*}[Corollary]
    \emph{
        $\wf$ can be written as a union of $\om_1$ many Borel sets: $$\wf = \bigcup_{\alpha < \om_1}\wf_\alpha$$
    }
\end{remark*}

\begin{defin*}[$\bog$-complete]
    Let $\bog$ be a boldface pointclass. A set $A\subset\om^\om$ is called \undf{$\bog$-hard} if for all $B \in \bog(\om^\om)$ there is a continuous function $f : \om^\om \ra \om^\om$ such that $B = f^{-1}[A]$. $A$ is \undf{$\bog$-complete} if it is $\bog$-hard and $A \in \bog(\om^\om)$.
\end{defin*}

\begin{theorem*}
    $\wf$ is $\bopi^1_1$-complete.
\end{theorem*}
\begin{proof}
    Tree representation theorem says: if $B$ is $\bopi^1_1$, then there is a tree $T$ such that $\forall x\ x\in B\iff T_x$ is wellfounded. This almost has the form that we want, but we're talking about trees instead of elements of $\om^\om$. So we map $x\mapsto c_{T_x} \in \om^\om$ such that:
    \begin{align*}
        c_{T_x}(\bij{i,j}) \coloneqq \left\lbrace \begin{array}{cl} 1 & \textrm{ if }s_i,s_j\in T_x\textrm{ and } s_i\supseteq s_j\\ 0 & \textrm{ o/w}\end{array}\right.
    \end{align*}
    Consider $x\mapsto c_{T_x}$ and check that it is continuous. Given $i,j$, how much information about $x$ do I need to determine whether $c_{T_x}(\bij{i,j}) = 0$ or $1$? Note that whether $s_i\supseteq s_j$ or not does not depend on $x$ at all. What does $s_i \in T_x$ mean? It means $(s_i,x\restriction \lh(s_i))\in T$.

    So if we know $x\restriction \max(\lh(s_i),\lh(s_j))$, then we can calculate $c_{T_x}(\bij{i,j})$. So $x\mapsto c_{T_x}$ is a continuous function. So we have:
    \begin{align*}
        x \in B &\iff [T_x]\ne\emptyset\\
        &\iff T_x\textrm{ is wellfounded}\\
        &\iff c_{T_x}\in \wf
    \end{align*}
    So $B$ is the continuous preimage of $\wf$.
\end{proof}

\begin{remark*}[Corollary]
    \emph{
        $\wf$ is not $\bosig^1_1$
    }
\end{remark*}
\begin{proof}
    We know that $\bosig^1_1 \ne \bosig^1_1$. However, if $B \in \bopi^1_1$ arbitrary, by completeness of $\wf$ if $\wf$ is $\bosig^1_1$ then $B$ is $\bosig^1_1$. Contradiction.
\end{proof}

\begin{remark*}[Corollary]
    \emph{
        Every $\bopi^1_1$ set is an $\om_1$-union of Borel sets.
    }
\end{remark*}
\begin{proof}
    If $B \in \bopi^1_1$, find $f$ such that $B = f^{-1}[\wf]$. So:
    \begin{align*}
        B &= f^{-1}\left[ \bigcup_{\alpha < \om_1}\wf_\alpha\right]\\
        &=\bigcup_{\alpha<\om_1}f^{-1}[\wf_\alpha]        
    \end{align*}
    and each $f^{-1}[\wf_\alpha]$ is Borel.
\end{proof}
\end{document}