\documentclass[]{article}

\input{/home/pyotopic/Documents/PartIII/lazyboi/lecture_notes/preamble.tex}

\newcommand{\I}{\textrm{I}}
\newcommand{\II}{\textrm{II}}
\newcommand{\om}{\omega}
\newcommand{\lom}{{<\omega}}
\newcommand{\lh}{\ell h}
\renewcommand{\ac}{\textrm{AC}}
\newcommand{\bosig}{\bm{\Sigma}}
\newcommand{\bopi}{\bm{\Pi}}
\newcommand{\bodel}{\bm{\Delta}}
\usepackage{bm}

\newcommand{\game}{
    \begin{center}
        \begin{tabular}{c|ccccccc}
            I & $m_0$ & & $m_2$ & & $m_4 $& & $\dots $\\ \hline
            II & & $m_1$ & & $m_3 $& &$ m_5$ & $\dots$ 
        \end{tabular}
    \end{center}
}

\title{Infinite Games}
\author{Lectures by Benedikt L{\"o}we}
\date{}

\begin{document}
\maketitle


\reversemarginpar{Lecture 1}

\section{Introduction}
Before this course kicks off, we will first discuss a few things that this course is \it{not} about. Do bear in mind though that this is still an advanced set theory course, building off the content found in IID Logic and Set Theory.

\underline{Literature}: Some useful literature can be found in `The Higher Infinite' - in particular, Chapter 6 ``Determinacy'', sections 27 (Infinite Games) and 28 (AD and Combinatorics).

The term ``Infinite Games'' can evoke different reactions in different mathematicians. We will get on to formal definitions later, but the games we will consider have the following properties. They are:
\begin{itemize}
    \item Two-player
    \item Length $\omega$
    \item Win-lose
    \item Perfect information
    \item Perfect recall
\end{itemize}
Essentially, they are infinite versions of board games.

A notable theorem from the finite analogue of this theory is that of Zermelo, which is that very finite such game is determined - this is considered rather trivial, and we will see the difference between the application of this to the finite case versus the infinite case.

\subsection{Two Players}

We have two players: I and II.

Three-player games do not, in general, admit winning strategies. Consider the following example:

I, II, III are playing. Player I is given a gold coin.

\underline{Round 1}: I can give it to II or to III.

\underline{Round 2}: Whoever has the coin can give it to I or to II.

The person with the coin wins.

So if II gets the coin, they will keep it and win. Player I can either hand the win to II, or leave it to chance with III. III has no win condition, and II cannot force anyone to give them the coin. So no-one has a winning strategy. However, \undf{coalitions} $\{I,II\}$, $\{I,III\}$, $\{II,III\}$ can each ensure a win.

What we have encountered here is \undf{cooperation}, which fundamentally changes the strategies and payoffs; this phenomenon cannot arise in two-player games, as they players are always competing directly with each other.

\subsection{Length $\omega$}

In game theory in economics, there is research on potentially infinite games.

Consider the prisoner's dilemma, concisecly represented by:

\begin{center}
    \begin{tabular}{cc|cc}
        2 & 2 & 1 & 3 \\ \hline
        3 & 1 & 0 & 0
    \end{tabular}
\end{center}

There is a lot of research on this game as a single-move game, but it can also be thought of as a repeated game, where many rounds are played one after the other. In fact, if you fix a length of the game in advance this will affect the strategy of the players. Economists have deal with games which are, while certainly not infinte, of unknown length, and as such it happens that infinite games can serve as a useful model for this situation From there we can study asymptotic behaviour, or evolutionary phenomena.

The point here is that if we only think of \it{truly} infinite games, \it{i.e.} it will take an infinite amount of time to win, then the situation is fundamentally different.

\begin{remark}[Example] The Prime Factor Game\ \\

\begin{center}
    \begin{tabular}{cccccccccc}
        I & $k_0$ & & $k_1$ & & $k_2$ & & $k_3$ & &\dots \\
        II & & $p_0$ & & $p_1$ & & $p_2$ & & $p_3$ &\dots
    \end{tabular}
\end{center}

The $k_i\ge 2$ are natural numbers, and the $p_i$ are prime numbers. At the end of the game, we look at $K = \{k_i:i\in \N\}$ and $P = \{p_i:i \in \N\}$. We say that Player II wins if $P$ is the set of all prime factors in $K$ (and no more).

\underline{Observe}: Player II has a winning strategy.

Let $k_0 = q_0^{\ell_0}\dots q_m^{\ell_m}$. Then play as though $p_0 = q_0$, $p_1 = q_1$, $p_2 = q_2$, exhausting the finitely many prime factors of $k_0$ before moving on to $k_1$. Repeating ad infinitum, it is clear that the set $P$ is precisely what is desired.

However, if we look at how this is going for II after any finite number of moves $N \in \N$, then in most runs of the game, the finite sets $\{k_0,\dots,k_N\}$ and $\{p_0,\dots,p_N\}$ do not look like a win for player II; it will seems as though things are going worse and worse for II.

This critically highlights how the asymptotic behaviour can be drastically different from the outcome of the game after infinite time.
\end{remark}

A common objection to this type of material is that you can't play these games, so how could you know who wins?

The above example clearly highlights that even though, of course, the games cannot actually be played, we may still be able to prove that a winning strategy does or does not exist for either player. So we are replacing actually playing the game with thinking about the different strategies for it.

Let's modify the PFG slightly:

\begin{center}
    \begin{tabular}{cccccccc}
        I & & $k_0$ & & $k_1$ & & $k_2$ & \dots \\ 
        II & $p_0$ & & $p_1$ & & $p_2$ & & \dots
    \end{tabular}
\end{center}

Now Player I has a winning strategy instead. Take $p_0$, find another prime $q \ne p_0$ and play $k_i = q^{i+1}$. Then $K = \{q^{i+1}:i \in \N\}$. So II wins iff $P = \{q\}$, but $p_0 \in P$. So II loses.

\subsection{Win-Lose}

There is a related notion here called \undf{zero-sum}; in these games, there is a fixed payoff that is split between the two players. So, for instance, the Prisoner's Dilemma is \undf{not} zero-sum because the total payoff differs between some outcomes. However, the game
\begin{center}
    \begin{tabular}{cc|cc}
        1&1&0&2\\ \hline
        2&0&1&1
    \end{tabular}
\end{center}
\it{is} zero-sum.

\undf{Win-lose} simply means that the payoff is an indivisible $1$. So in our case, payoff functions are characteristic functions of a \undf{payoff set}.

\subsection{Perfect Information}

Paradigmatic: board games, after which this idea was modelled.

A non-example is \it{card games}, in which your own hand is only known to you. Unsurprisingly, this scenario is called \it{imperfect information}.

Consider yet another variant of PFG:

\begin{center}
    \begin{tabular}{cccccccccc}
        I & $k_0$ & & $k_1$ & & $k_2$ & & $k_3$ & &\dots \\
        II & & $p_0$ & & $p_1$ & & $p_2$ & & $p_3$ &\dots
    \end{tabular}
\end{center}

Here, player I picks $k_i$, but does not have to reveal $k_i$ before II has played $p_i$. Here, although it may happen with probability zero, it is possible for II to beat any set of moves that I makes simply by being lucky, and guessing only prime factors for numbers chosen by I. However, it is clear that it is impossible to ensure that this is the case.

So neither of the two players has a winning strategy in this variant. The study of these imperfect information games is closely related to probability.

\subsection{Perfect Recall}

This means that both of the players remember everything that has happened before; the opposite of course would be that the players have a finite, bounded memory.

For instance, take PFG with the additional constraint that Player II can only remember the last 1000 moves. Now Player I has a strategy that might win; on the first move, pick a natural number with at least 1001 distinct prime factors. Then II will have no idea what move to make at $N = 1001$; they might guess, and so they can still win, but they have no way to ensure this (and again it will not be very likely).

Imperfect recall is very relevant in applications of infinite games in computer science.

\reversemarginpar{Lecture 2}

We fix a set $M$ of moves. In most cases, $M$ will simply be $\N$ - but we will aim to keep this slightly more general for now.

Note that from the perspective of a set theorist, we think of $\N$ as equal to $\omega$, and in particular $n = \{0,1,\dots,n-1\}$. Moreover, functions are \it{set-theoretic} functions, \it{i.e.} sets of ordered pairs with the function property. For instance:
\begin{align*}
    M^n = \{s; s:n\ra M\}
\end{align*}
is the set of functions from the \it{set} $n$ to the set $M$. If $s\in M^n$ and $t \in M^k$, with $k>n$, then $s\subset t$ is the same as saying ``$s$ is an initial segment of $t$'', or that ``$t$ is an extension of $s$''.

Since we are thinking of sequences as functions, we can also write: if $m<n$ and $s \in M^n$, then $s\restriction m \in M^m$.

These are well-known formal definitions of these objects, but they will be used particularly ruthelessly here.

We make another important definition:
\begin{align*}
    M^{<\omega} \coloneqq \bigcup_{n\in \N}M^n
\end{align*}
This is the set of all finite sequences of elements of $M$; these will be called the \undf{positions} of the game. We also have:
\begin{align*}
    M^\omega \coloneqq \{x;x:\N\ra M\}
\end{align*}
is the set of all \undf{runs} or \undf{plays} of the game \it{i.e.} the set of all sequences of $M$ of length $\omega$. Note that if $x\in M^\omega$ is a run and $n\in \N$, then $$x\restriction n:n\ra M$$ is the position that the play producing $x$ was in after $n$ rounds.

\underline{The games on $M$}:

\begin{center}
    \begin{tabular}{c|ccccccc}
        I & $m_0$ & & $m_2$ & & $m_4 $& & $\dots $\\ \hline
        II & & $m_1$ & & $m_3 $& &$ m_5$ & $\dots$ 
    \end{tabular}
\end{center}
We are restricting our attention to games where I,II play in alternation and player I starts. [Remark: more general games can be described by these; see later.]

Then $x(i)\coloneqq m_i$ is the run produced by the game, and $s\coloneqq x\restriction n$ is the $n^\th$ position.

If $x \in M^\omega$, we write
\begin{align*}
    x_\I(i) &\coloneqq x(2i)\\
    x_\II(i) &\coloneqq x(2i+1)
\end{align*}
$x_I,x_{II}\in M^\omega$ correspond to the moves made by players I,II respectively. If $x,y\in M^\omega$, we write $x\ast y$ (\undf{interleaving}) for the sequence $z$ defined by:
\begin{align*}
    z(n) \coloneqq \left\lbrace  \begin{array}{ccc}x(k)&n = 2k\\ y(k) &n = 2k+1 \end{array}\right.
\end{align*}

Clearly, $x_\I \ast x_\II = x$.

If $A\subset M^\omega$, we call $A$ a \undf{payoff set}. In the game $G(A)$, we say that player I wins a run $x \in M^\om$ if $x \in A$; otherwise player II wins.

We call any function $$\sigma:M^{<\om} \ra M$$ a \undf{strategy}. Note that a strategy looks at the entire game up until that point to decide the next move; this is the perfect recall aspect. You may wonder why we bother defining a strategy for player I at odd length positions, and this is largely for notational convenience; it is a little easier to have this notational overkill.

Note that each strategy in this sense can be thought of a strategy for I, plus a strategy for II. Let
\begin{align*}
    O&\coloneqq \bigcup_{n\textrm{ odd}}M^n\\
    E &\coloneqq \bigcup_{n\textrm{ even}}M^n
\end{align*}
Then $\sigma\restriction E$ is a strategy for I, and $\sigma \restriction O$ is a strategy for II. So there is redundance in the notation.

If $\sigma, \tau$ are strategies, we can play them against each other by interleaving them as $\sigma\ast\tau \in M^\om$, which is defined by:
\begin{align*}
    (\sigma\ast\tau)(2n)&\coloneqq \sigma((\sigma\ast\tau)\restriction 2n)\\
    (\sigma\ast\tau)(2n+1)&\coloneqq \tau((\sigma\ast\tau)\restriction 2n+1)
\end{align*}
We say that $\sigma$ is \undf{winning for I in $G(A)$} if $\forall \tau(\sigma\ast\tau\in A)$, \it{i.e.} I always wins regardless of II's strategy. Similarly, we say that $\tau$ is \undf{winning for II in $G(A)$} if $\forall \sigma(\sigma\ast\tau\not\in A)$.

We say that a set $A$ is \undf{determined} if one of the two players has a winning strategy in $G(A)$.

\begin{remark}\ 
    \begin{itemize}
        \item Clearly, at most one player can have a winning strategy (otherwise, play them against each other).
        \item However, it is not obvious (and not true, up to the axiom of choice) that every set is determined.
        \item In fact, we will see that AC implies that there are non-determined sets, but ``every set is determined'' (Axiom of Determinacy, AD) is consistent ZF - though this requires more nuance, but we will discuss all of this later.
    \end{itemize}
\end{remark}

You may ask: is that really the most general form of games that we want to look at? What if we wanted to include things like `forbidden' moves, or allowing one or two players to make several moves at a time, or having two different move sets? It turns out that we don't need to worry about this:

A set $T\subset M^{\lom}$ is called a \undf{tree} if it is closed under initial segments, \it{i.e.} if $s\in T$ and $t\subset s$ then $t \in T$.

These trees look very much like the trees one might encounter in graph theory/combinatorics; though there are some small differences. In this set-theoretic notion of a tree, each node in the tree contains within it all of the information abou the path from the root (\it{i.e.} the empty set, $\emptyset$) to it.

If $T$ is a tree on $M$ and $x\in M^\om$, we say that $x$ is a \undf{branch through $T$} if for all $n \in \N$, $x\restriction n \in T$. We write $[T]$ for the set of branches through $T$; in some literature this is referred to as the \undf{body of $T$}.

\begin{remark}[Example]
    $M^\lom$ is a tree; $[M^\lom] = M^\om$.
\end{remark}

We can think of a tree $T$ as ``finitary'' rules for a game: if $x\not\in [T]$, then there is a least $n$ for which $x\restriction n\not\in T$. If $n$ is odd, then player I left the tree, and if $n$ is even then player II left the tree.

Define a game $G(A;T)$ where $A\subset [T]$ and $T$ is a tree on $M$.
The game is as usual:
\game
If $x \in A$, then player I wins. If $x\not\in [T]$ and the least $n$ for which $x\restriction n\not\in T$ is even, then player I wins. In all other cases, player II wins.

Now, even though this looks more general due to the introduction of the tree $T$, it can be seen that this is in fact a special case of a $G(A)$ game, since we can define: $$A_T \coloneqq \{x \in M^\om; x\in A\textrm{ or }x\not\in [T]\textrm{ and the least }n\textrm{ s.t. } x\restriction n\not\in T\textrm{ is even}\}$$. Then $G(A;T)$ and $G(A_T)$ are \undf{the same game}.

Note that we haven't quite defined what it means to be the same game, but in this particular case it should be rather clear that these two are indeed the same game.

This idea of using trees gives us a lot of flexibility with the move set.

\begin{remark}[Example 1]
    Suppose the moves for I are in $X$, and the moves for II are in $Y$. We can take $M\coloneqq X\cup Y$, $A\subset M^\om$, and
    \begin{align*}
        T\coloneqq \{s;\ \forall n\in \N,\ s(2n)\in X\textrm{ and }s(2n+1)\in Y\}
    \end{align*}
    Then $G(A;T)$ is the game we desire.
\end{remark}

\begin{remark}[Example 2]
    Suppose I can always make two moves in $X$, but II can only make one move. We then take $M\coloneqq X^2\cup X^1$, and apply the idea of Ex. 1 with $X = X^2$ and $Y = X^1$.
\end{remark}

\begin{remark}[Example 3]
    If $X\subset Y$, then every game $G(A)$ on $X$ can be thought of as a game on $Y$ by $G(A;T)$, where $$T\coloneqq X^{\lom} \subset Y^{\lom}$$
\end{remark}

\begin{defin*}[Strategic Tree]
    Let $\sigma$ be a strategy. We define the \undf{I-strategic tree} and the \undf{II-strategic tree} on $M$ as follows:
    \begin{align*}
        T_\sigma^\I &\coloneqq \{s\in M^{\lom}; \forall n(s(2n)=\sigma(s\restriction 2n))\}\\
        T_\sigma^\II &\coloneqq \{s\in M^\lom; \forall n(s(2n+1)=\sigma(s\restriction 2n+1))\}
    \end{align*}

    When drawing out these trees, for instance $T_\sigma^\I$, the layers alternate between making any choice from $M$ (representing II's moves) and making the only choice dictated by $\sigma$ for I.

    II-strategic trees look the same except that we have branching in odd length nodes and no branching in even length nodes.

    $T$ is called \undf{strategic} if there is $\sigma$ such that $T = T^\I_\sigma$ or $T = T^\II_\sigma$.
\end{defin*}

\underline{Observe}: $$T_\sigma^\I = \{(\sigma\ast \tau)\restriction n; \tau \textrm{ any strategy and }n\in \N\}$$ $$T_\sigma^\I = \{(\tau\ast \sigma)\restriction n; \tau \textrm{ any strategy and }n\in \N\}$$

\underline{Therefore}: $$ [T_\sigma^\I] = \{\sigma\ast \tau; \tau \textrm{ any strategy}\}$$
$$ [T_\sigma^\II] = \{\tau\ast\sigma; \tau \textrm{ any strategy}\}$$

\begin{remark}[Proposition]\ 
    \begin{enumerate}
        \item $\sigma$ is a winning strategy for I in $G(A)\iff [T_\sigma^\I]\subset A$
        \item $\sigma$ is a winning strategy for II in $G(AS)\iff [T_\sigma^\II]\cap A = \emptyset \iff [T_\sigma^\I]\subset M^\omega \backslash A$
    \end{enumerate}

    \underline{Also}: $A$ is determined iff either $A$ contains $[T_\sigma^\I]$ for some $\sigma$ or $M^\om \backslash A$ contains $[T_\sigma^\II]$ for some $\sigma$.
\end{remark}

\underline{Notation}: If $s,t\in M^\lom$, we write $st$ for the concatenation of $s$ and $t$. This also works if $t$ is infinite; if $x \in M^\om$ and $s\in M^\lom$, then similarly $sx\in M^\om$ is the concatenation.

If $t$ is a length 1 sequence, say $t = \langle m\rangle$, we also write $sm$ for $st = s\langle m\rangle$; this is usually unambiguous.

For the length of a sequence we write $\lh(s) = \textrm{dom}(s)$.

\begin{defin*}[Splitting Node, Perfect Tree, Perfect Set]\ 
    \begin{enumerate}[label=\arabic*)]
        \item If $T$ is a tree and $s \in T$ we say $s$ is a \undf{splitting node} if there are $m\ne m'$ such that both $sm,sm' \in T$.
        \item $T$ is \undf{perfect} if for each $s \in T$ there is a $t\supseteq s$ such that $t\in T$ and $t$ is splitting in $T$.
        
        [Remark: every strategic tree is perfect]

        \item $A\subset M^\om$ is \undf{perfect} if there is a perfect tree $T$ such that $A = [T]$.
        
        \underline{Remark}: Compare to the topological notion of a \undf{perfect set}: clsoed without isolated points. We will find out later that, with the right toplology on $M^\om$, these notions will coincide.

    \end{enumerate}
\end{defin*}

\begin{theorem*}[Cantor]
    Suppose $A\subset 2^\om \equiv \{0,1\}^\om$ is perfect and non-empty. Then $A$ has cardinality $2^{\aleph_0}$.
\end{theorem*}
\begin{proof}
    $A\subset 2^\om$ and $|2^\om| = 2^{\aleph_0}$, so $|A| \le 2^{\aleph_0}$. So by Cantor-Schr{\"o}der-Bernstein, it is enough to show that there is an injection from $2^\om$ into $A$.

    We define this injection via a function $\phi : 2^{\lom} \ra T$, where $T$ is perfect such that $A = [T]$. We will define this by recursion (this is known as a \it{Cantor scheme}):
    \begin{align*}
        \phi(\emptyset) &\coloneqq \emptyset\\
    \end{align*}
    Suppose $\phi(s) = t \in T$. Since $T$ was perfect, find $u\supseteq t, u \in T$ that is splitting: $u0,u1\in T$. To ensure this is uniquely defined (to potentially avoid issues with Choice), take the minimal one. Then:
    \begin{align*}
        \phi(s0) &\coloneqq u0\\
        \phi(s1) &\coloneqq u1
    \end{align*}
    This finishes the definition of $\phi$. We then define:
    \begin{align*}
        \hat{\phi}&:2^\om \ra [T] = A\\
        \hat{\phi}(x)&\coloneqq \bigcup_{n\in \N}\phi(x\restriction n)
    \end{align*}
    We need to check some things:
    \begin{enumerate}
        \item $\lh(\phi(x\restriction n)) \ge n$
        \item $\phi(x\restriction n)\subset \phi(x\restriction m)$ if $n\le m$
        
        $\implies \hat{\phi}:2^\om\ra2^\om$

        \item $\hat{\phi}(x)\restriction u\subset \phi(x\restriction k)$ for some $k$ so $\hat{\phi}(x)\restriction u\in T$, so $\hat{\phi}(x)\in [T]$.
        
        So we indeed have that $\hat{\phi}:2^\om \ra [T]$.
    \end{enumerate}

    It remains to show that $\hat{\phi}$ is an injection:

    Suppose $x\ne y$. Find $n$ such that $x\restriction n = y\restriction n$, but $x(n)\ne y(n)$. WLOG, say $x(n) = 0$ and $y(n) = 1$. But then $\phi(x\restriction n+1)\ne \phi(y\restriction n+1)$, since the former ends in $0$ and the latter in $1$. This implies that $\bigcup_{k\in \N}\phi(x\restriction k)\ne \bigcup_{k\in \N}\phi(y\restriction k)$, hence $\hat{\phi}(x)\ne \hat{\phi}(y)$.
\end{proof}

\begin{remark}
    If $|M|\ge 2$ and $T$ is a perfect tree on $M$, then the same proof shows that $2^{\aleph_0}\le |[T]|$.
\end{remark}

\begin{remark}[Corollary]
    If $|M|\ge 2$, then:
    \begin{enumerate}[label = (\roman*)]
        \item if player I has a winning strategy in $G(A)$, then $|A|\ge 2^{\aleph_0}$
        \item if player II has a winning strategy in $G(A)$ then $|M^\om \backslash A| \ge 2^{\aleph_0}$.
    \end{enumerate}
    This follows from:
    \begin{enumerate}
        \item strategic trees are perfect
        \item perfect sets are large
        \item winning startegy means ``includes strategic tree''
    \end{enumerate}
\end{remark}

Note that if $A\subset M^\om$ with $|M|\ge 2$, then either $|A|\ge 2^{\aleph_0}$ or $|M\backslash A| \ge 2^{\aleph_0}$.

The corollary gives a necessary condition on when a fixed player has a winning strategy, but no non-trivial necessary condition for determinacy.

\subsection*{Sufficient Conditions}

Let's do the following as a warmup.

Prove that if $A$ is countable, then player II has a winning strategy in $G(A)$.

\begin{remark}[Proposition]
    If $A = \{a_i;i \in \N\}$ is countable, then player II has a winning strategy in $G(A)$.
\end{remark}
\begin{proof}
    In II's round $k$ [that means digit $2k+1$], II takes care of $a_k$, simply by playing $1 - a_k(2k+1)$ (assume again we are playing on $M = \{0,1\}$; on anything else just pick something different to $a_k(2k+1)$).

    So the strategy $\tau$ is:
    \begin{itemize}
        \item ignore everything player I does
        \item blindly play $1 - a_k(2k+1)$ in your $k^\th$ move.
    \end{itemize}

    Clearly then for any $\sigma$,
    \begin{align*}
        (\sigma\ast \tau)_\II(k) &= (\sigma \ast \tau)(2k+1)\\
        &= 1 - a_k(2k+1)\\
        &\ne a_k(2k+1)
    \end{align*}
    So $\sigma \ast \tau\ne a_k$ for arbitrary $k$, so $\sigma\ast \tau \not \in A$. Thus $\tau$ is winning.
\end{proof}

\reversemarginpar{Lecture 3}

\underline{Necessary}: we have determined some necessary conditions for wins:
\begin{itemize}
    \item I wins $G(A)\implies |A| = 2^{\aleph_0}$
    \item II wins $G(A)\implies |\om^\om\backslash A| = 2^{\aleph_0}$
\end{itemize}
\underline{Sufficient}: we also have the sufficient condition:
\begin{itemize}
    \item if $A$ is countable, then player II wins.
\end{itemize}

Note that we write `I/II' wins as shorthand for `I/II has a w.s.'
\ \\

\begin{theorem*}\ \\
    \begin{enumerate}
        \item If $A\subset \om^\om$ such that $|A| < 2^{\aleph_0}$, then player II has a winning strategy in $G(A)$.
        \item If $A\subset \om^\om$ such that $|\om^\om\backslash A| < 2^{\aleph_0}$ then player I has a winning strategy in $G(A)$.
    \end{enumerate}
\end{theorem*}
\begin{proof}
    The proofs of 1 and 2 are essentially just switching the roles of I,II. So we are just going to prove 1.

    \underline{Caution}: our games are \it{not} fully symmetric; I is not in the same situation as II. Moving first can sometimes be an advantage, and sometimes a disadvantage. The above claim must thus be checkd carefully.

    Let $|A| < 2^{\aleph_0}$. Define an equivalence relation $\sim$ on $\om^\om$ by $$x\sim y \iff x_{II} = y_{II}$$. So equivalence classes look like this:
    \begin{align*}
        C_z \coloneqq \{x; x_{II} = z\}
    \end{align*}
    So there is a bijection between the $\sim$-equivalence classes and $\om^\om$. In particular, there are $2^{\aleph_0}$ such equivalence classes. By the pigeonhole principle, we find $z$ such that $$C_z \cap A = \emptyset$$. Then define $\tau$ as:
    \begin{itemize}
        \item ignore everything player I does
        \item just play the next digit of $z$
    \end{itemize}
    Formally, we can say $\tau(s)\coloneqq z(n)$ if $\lh(s) = 2n+1$, and whatevery you like on the even entries. Then if $\sigma$ is any strategy, we have
    \begin{align*}
        (\sigma\ast\tau)_{\II} &= z\\
        \implies \sigma\ast\tau &\in C_z\\
        \implies \sigma\ast\tau&\not\in A
    \end{align*}
    So $\tau$ is a w.s. for II.
\end{proof}

This is called a \undf{blindfolded strategy}, since II doesn't care about what I is doing (and doesn't need to know). Formally, this is when there is $z\in \om^\om$ such that for player II, $\tau(s)\coloneqq z(n)$ if $\lh(s) = 2n+1$, or similarly for player I $\sigma(s)\coloneqq z(n)$ if $\lh(s) = 2n$. We normally denote this as $\tau_z$ if for player II, and $\sigma_z$ if for player I.

\underline{Consequence}: If we have any set $A$ that is not determined, then it must be the case that $|A| = |\om^\om \backslash A| = 2^{\aleph_0}$. So we have a bit of an idea that a non-determined set must look a bit symmetric.

\underline{Next goal}: Find such a non-determined set.

\begin{theorem*}[uses AC]
    There is a non-determined subset $A\subset \om^\om$.
\end{theorem*}
\begin{proof}
    The idea here is to ensure that $A$ contains no strategic trees, which we do by enumerating them and then distributing the branches between $A$ and its complement.

    We did prove in Lecture 3 that if $T$ is a strategic tree, then $|[T]| = 2^{\aleph_0}$.
    
    \underline{Question}: How many strategic trees are there?

    \underline{Notation}: We write Trees $\coloneqq \{T;T\textrm{ is a tree on }\om\}$, and STrees$\coloneqq \{T;T\textrm{ is a strategic tree on }\om\}$.

    We remark that a tree $T\subset \om^\om$, which is countable, so this gives an upper bound on the size of Trees. So we have $|$STrees$|\le|$Trees$|\le2^{\aleph_0}$. Can we also find a lower bound? This is where the blindfolded strats come in...

    If $z\ne z'\in \om^\om$, then $[T^\I_{\sigma_z}]\cap[T^\I_{\sigma_{z'}}] = \emptyset$. So $T_{\sigma_z}^\I \ne T^\I_{\sigma_{z'}}$.

    Together (with Cantor-Schr{\"o}der-Bernstein), we get a bijection between $2^{\aleph_0}$ and STrees.

    Note that so far we haven't used AC, with the mild exception that the notation $2^{\aleph_0}$ implies the existence of an ordinal in bijection with the powerset of $\om$, which requires AC. However, the above can be reformulated as saying that we have injections $\om^\om \xhookrightarrow{} \dots \xhookrightarrow{} \om^\om$, and then use CSB; choiceless.

    However, we need a little bit of choice now. We aren't going to use the full AC, but only that the set $\om^\om$ is wellorderable. This implies:
    \begin{itemize}
        \item $2^\aleph_0$ \it{is} an ordinal (so we can do transfinite recursion on it)
        \item there is a choice funcntion $c:\mathcal{P}\om^\om\backslash \emptyset \ra \om^\om$ (\it{i.e.} $c(A)\in A$)
    \end{itemize}

    Equipped with this, we do the construction. We had that $|\textrm{STrees}| = 2^{\aleph_0}$, so write STrees $=\{T_\alpha; \alpha < 2^{\aleph_0}\}$ and do the following transfinite recursion:

    We are going to define sets $A_\alpha,B_\alpha$ in stages for $\alpha < 2^{\aleph_0}$ in such a way that $|A_\alpha| = |B_\alpha| = |\alpha|$ ($\ast$). In the end we will see $A_\alpha \cap B_\alpha = \emptyset$.

    \underline{$\alpha = 0$}: $A_0 = B_0 = \emptyset$.

    \underline{$\alpha = \beta+1$}: Suppose we have $A_\beta,B_\beta$. Consider $T_\beta\in$ STrees. Then $|[T_\beta]| = 2^{\aleph_0}$. By $(\ast)$, $|A_\beta| = |B_\beta| = |\beta|<2^{\aleph_0}$. This implies that $|A_\beta\cup B_\beta|<2^{\aleph_0}$. Thus $[T_\beta]\backslash (A_\beta \cup B_\beta)\ne\emptyset$ (even better, it has $2^{\aleph_0}$ many elements).

    Define:
    \begin{align*}
        a_\beta & \coloneqq c([T_\beta]\backslash(A_\beta\cup B_\beta))\\
        b_\beta & \coloneqq c([T_\beta]\backslash (A_\beta\cup B_\beta\cup \{a_\beta\}))
    \end{align*}
    Note that the latter input for $c$ is still non-empty since $|[T_\beta]\backslash (A_\beta\cup B_\beta)| = 2^{\aleph_0}$.

    Then let $A_\alpha \coloneqq A_\beta \cup \{a_\beta\}$, and similarly $B_\alpha \coloneqq B_\beta\cup\{b_\beta\}$. Moreover, $|A_\alpha| = |\beta + 1| = |\alpha| = |B_\alpha|$, satisfying IH.

    \underline{$\alpha$ is a limit}: For all $\beta < \alpha$, $A_\beta$, $B_\beta$ are defined and satisfy $(\ast)$. So we let:
    \begin{align*}
        A_\alpha &\coloneqq \bigcup_{\beta<\alpha}A_\beta\\
        B_\alpha &\coloneqq \bigcup_{\beta<\alpha}B_\beta
    \end{align*}
    Obviously, $|A_\alpha| = |\alpha| = |B_\alpha|$ since they are each unions of things of the right size (there is an increasing sequence of bijections that converges to what we want, formally), so $(\ast)$ is still satisfied.

    Now we let
    \begin{align*}
        A &\coloneqq \bigcup_{\alpha <2^{\aleph_0}}A_\alpha\\
        B &\coloneqq \bigcup_{\alpha < 2^{\aleph_0}}B_\alpha
    \end{align*}
    \underline{Note 1}: $A\cap B = \emptyset$; if not, then $a_\alpha = b_\beta$ for some $\alpha,\beta$. WLOG $\alpha \le \beta$. This then contradicts the choice of $b_\beta$.

    \underline{Note 2}: $|A| = 2^{\aleph_0} = |B|$. This is good, since it was a necessary condition for $A$ and $B$ being non-determined, as we found earlier.

    \underline{Claim}: $A$ is not determined (and similarly $B$).

    \underline{Proof of Claim}: Suppose $A$ is determiend. Then there is a strategic tree $T_\alpha$, $\alpha <2^{\aleph_0}$, such that either $[T_\alpha] \subset A$ or $[T_\alpha]\cap A = \emptyset$. But consider $a_\alpha,b_\alpha \in [T_\alpha]$. We have $a_\alpha \in A$, $b_\alpha \in B$, \it{i.e.} $b_\alpha\not\in B$. This rules out both cases, so contradiction. This proves the theorem.
\end{proof}

You may notice that this is the very same diagonalisation argument that crops up all over the place.

\underline{Discussion}: we used AC to produce a non-determined set. [Usually, AC implies the existence of pathologies, \it{e.g.} a non-Lebesgue measurable set, or the Banach-Tarski decomposition of the unit ball. AC does not produce a constructive method for teh pathological objects, since the construction depends on the choice function.

\underline{Motto (hope)}: If a set $A$ is `nice' or `simple', then it is not pathological.

Similarly here; though we have just proved that non-determined sets may exist, the ones we have found are all pathological. We might ask if non-determined sets only arise this way. Hence:

\underline{Goal}: Make `nice' and `simple' precise, and prove that nice sets are determined.

\reversemarginpar{Lecture 5}

\begin{defin*}[Quasistrategy]
    A function $$\sigma:M^{\lom}\ra \mathcal{P}(M)\backslash \{\emptyset\}$$ is called a \undf{quasi-strategy}. Strategies can be identified as a special case of quasistrategies: $$(\forall s)|\sigma(s)| = 1$$ which clearly induced a strategy as we have defined it.

    We also have a notion of \undf{quasistrategic trees}:
    \begin{align*}
        Q_\sigma^\I &\coloneqq \{s\in M^\lom; (\forall n) s(2n)\in \sigma(s\restriction 2n)\}\\
        Q_\sigma^\II &\coloneqq \{s\in M^{\lom}; (\forall n) s(2n+1)\in \sigma(s\restriction 2n+1)\}
    \end{align*}
    A quasistrategy is \undf{winning for I in $G(A)$} if $[Q_\sigma^\I]\subset A$, and \undf{winning for II in $G(A)$} if $[Q_\sigma^\II]\cap A = \emptyset$.

    As before, at worst one of the two players can have a winning quasistrategy.
\end{defin*}

\begin{defin*}[Quasidetermined Set]
    A set $A\subset M^\om$ is called \undf{quasidetermined} if either I or II has a winning qs in $G(A)$.
\end{defin*}

\begin{remark*}[Lemma]
    If $M$ is wellorderable, then every quasistrategic tree on $M$ contains a strategic tree on $M$.
\end{remark*}

[\underline{Consequence}: if $M$ is wellorderable and $A\subset M^\om$ is quasidetermined, then it is determined.]

\begin{proof}
    Let $\sigma$ be a quasistrategy $\sigma :M^\lom \ra \mathcal{P}(M)\backslash \{\emptyset\}$. If $M$ is wellorderable, then there is a choice function $c:\mathcal{P}(M)\backslash \{\emptyset\}\ra M$ (\it{i.e.} such that $c(A)\in A$ for each $A$).

    Then define $\sigma^\ast \coloneqq c\circ \sigma:M^\lom \ra M$. By construction, $T_{\sigma^\ast}^\I \subset Q_\sigma^\I$ and $T_{\sigma^\ast}^\II \subset Q_\sigma^\II$.
\end{proof}

Note that we needed a bit of choice here - that $M$ is wellorderable.

Compare with out proof of the existence of a non-determined set from Lecture 4 (we used a wellordering of $M^\om$ to get $A\subset M^\om$ non-determined) to this, where we just use a wellordering of $M$. This requires significantly less choice, and it is often the case that $M$ comes equipped with a wellordering but $M^\om$ does not, \it{e.g.} $M = \N$.

\begin{defin*}[Closed Set]
    A set $A\subset M^\om$ is called \undf{closed} if there is a tree $T$ on $M$ such that $A = [T]$.
\end{defin*}

\begin{remark*}[Remarks]\ 
    \begin{enumerate}
        \item This is actually the notion of being closed in a topological space; we will see this space in the next lecture.
        \item Zermelo's finite games can be represented by closed payoff sets.
        
        Finite game of length $n$: let's say $f:M^n\ra \{\I,\II\}$ is the functino labelling the leaves according to which player wins.

        Let $A\coloneq \{x\in M^\om ; f(x\restriction n) = \I\}$. Then the finite game is just $G(A)$. This is just playing an infinite game, but having decided the outcome already after $n$ moves.

        We can also define:
        \begin{align*}
            T\coloneqq \{s\in M^\lom; f(s\restriction n) = \I\textrm{ and }\lh(s)\ge n \textrm{ or }\lh(s) < n\textrm{ and there is a }t\supseteq s \textrm{ s.t. } f(t)=\I\}
        \end{align*}
        Clearly, $[T] = A$. Thus all finite games are closed games.
    \end{enumerate}
\end{remark*}

\begin{theorem*}[Gale-Stewart]
    All closed sets $A\subset M^\om$ are quasidetermined.
\end{theorem*}
\begin{proof}
    If $A = [T]$, this means that if $x\not \in A$, then $x\not\in [T] = \{x\in M^\lom; (\forall n)x\restriction n\in T\}$. This implies there is some $n$ such that $x\restriction n\not \in T$. These are positions thare are won for sure by player II.

    Define a partial function $$\ell:M^\lom \ra \{\I,\II\}$$ by $\ell(s) = \II\iff s\not\in T$. Apply the following recursion rules to the partial labellings:

    We extend $\ell$ to $\ell^+\supseteq \ell$ according to the following rules. If $\ell(s)$ is undefined:
    \begin{itemize}
        \item and $\lh(s)$ is even [I moves] and $\forall m\in M$, $\ell(sm)=\II$, then $\ell^+(s)\coloneqq = \II$
        \item and $\lh(s)$ is odd [II moves] and $\exists m\in M$, $\ell(sm) = \II$, then $\ell^+(s) = \II$
    \end{itemize}
    Our transfinite recursion is then in the normal way:
    \begin{itemize}
        \item $\ell_0\coloneqq \ell$
        \item $\ell_{\alpha+1} \coloneqq (\ell_\alpha)^+$
        \item $\ell_{\lambda} \coloneqq \bigcup_{\alpha < \lambda} \ell_\alpha$
    \end{itemize}
    It's easy to construct examples of truly transfinite processes like this [needs $|M|\ge \aleph_0$].

    \underline{Claim}: this process terminates at some ordinal $\alpha$, \it{i.e.} $\ell_{\alpha} = \ell_{\alpha+1} = (\ell_{\alpha})^+$.

    \underline{Proof of Claim}: for $s\in M^\om$, we can define an \it{age function}:
    \begin{align*}
        \textrm{age}(s)\coloneqq \left\lbrace \begin{array}{c}\textrm{least }\beta\textrm{ s.t. }\ell_{\beta}(s)\textrm{ is defined}\\ 0\quad\textrm{ if }\ell_{\beta}(s)\textrm{ is never defined}\end{array}\right.
    \end{align*}
    So if the process never terminates, then age is a surjection from the set $M^\lom$ onto the (proper) class Ord. This contradicts the Axiom of Replacement.

    Let $\alpha$ be this termination point. We can then define:
    \begin{align*}
        \hat{\ell}(s)\coloneqq \left\lbrace \begin{array}{c}\II\quad \textrm{ if }s\in \textrm{dom}(\ell_\alpha)\\ \I\qquad \ \ \ \textrm{otherwise}\end{array}\right.
    \end{align*}
    Then $\hat{\ell}\supseteq \ell_\alpha$, effectively just taking $\ell_\alpha$ and filling everything else in with $\I$s. So $\hat{\ell}$ is a total function.

    \underline{Claim}: If $\hat{\ell}(\emptyset) = \I$, then player I has a winning quasistrategy; otherwise, $\hat{\ell}(\emptyset) = \II$ and player II has a winning q.s.

    Given this, the proof is complete.

    \marginpar{Lecture 6}

    \underline{Subclaim 1}: If $\hat{\ell}(\emptyset) = \I$, define
    \begin{align*}
        Q_\I \coloneqq \{s \in \om^\lom; \hat{\ell}(s) = \I\}
    \end{align*}
    and if $\hat{\ell}(\emptyset) = \II$, define $Q_\II$ similarly.l

    Then $Q_\I/Q_\II$ is a I/II-quasistrategic tree.

    [Need to show:
    \begin{enumerate}
        \item if $\hat{\ell}(s) = \I$ and $\lh(s)$ is even then there is $m$ such that $\hat{\ell}(sm) = \I$]
        \item if $\hat{\ell}(s) = \I$ and $\lh(s)$ is odd then for all $m$, $\hat{\ell}(sm) = \I$
        \item if $\hat{\ell}(s) = \II$ and $\lh(s)$ is even then for all $m$, $\hat{\ell}(sm) = \II$
        \item if $\hat{\ell}(s) = \II $ and $\lh(s)$ is odd then there is $m$ such that $\hat{\ell}(sm) = \II$
    \end{enumerate}

    We had $\ell_\alpha = \ell_{\alpha+1} = (\ell_\alpha)^+$, so 3 and 4 follow immediately from the recursion definition of $\ell^+$.

    Similarly, if $\hat{\ell}(s) = \I$ and $\lh(s)$ is even then $s\not\in \textrm{dom}(\ell_\alpha)$. This implies there is an $m$ such that $sm \not\in \textrm{dom}(\ell_\alpha)$, so $\hat{\ell}(sm) = \I$. 2 is similar.]

    \underline{Subclaim 2}: If $\hat{\ell}(\emptyset) = \I$, then $Q_\I$ is a w.q.s for $\I$.

    [Need to show that $[Q_\I] \subset A$. So fix some $x \in [Q_\I]$. So for all $x$,
    \begin{align*}
        x\restriction u \in Q_\I &\implies \hat{\ell}(x\restriction u) = \I\\
        &\implies \hat{\ell}(x\restriction u)\ne \II\\
        &\implies \ell(x\restriction u)\not\in \II\\
        &\implies x\restriction u \in T
    \end{align*}
    So $x \in A$.]


\begin{remark*}: What we have done so far hasn't really needed trees/closed sets. Instead, we could let $$\ell :M^\lom \ra \{\II\}$$ be any partial labelling. Do the transfinite recursion $\ell_{\alpha+1} \coloneqq (\ell_\alpha)^+$, $\ell_0 \coloneqq \ell,\dots$, find fixed point $\ell_\alpha$; define $\hat{\ell}$, define $Q_\I$. Then $\Q_\I$ is a q.s. that avoids all $s \in \textrm{dom}(\ell)$.
\end{remark*}

For player II, it is not always the case that $Q_\II$ is winning [\it{c.f.} Example 12 on ES\#1] since you could stay on labels II without ever leaving the tree. So, we need to work slightly harder and find a sub-quasistrategy that is in fact winning.

Recall the age function:
\begin{align*}
    &\textrm{age}:Q_\II \ra \alpha + 1\\
    &\textrm{age}(s) \coloneqq \textrm{the least }\beta\textrm{ such that } s \in \textrm{dom}(\ell_{\beta})
\end{align*}
This means:
\begin{align*}
    \textrm{age}(s) =  0 &\iff s \in \textrm{dom}(\ell_0) = \textrm{dom}(\ell)\\
    &\iff s\not\in T
\end{align*}

\underline{Subclaim 3}: If $\hat{\ell}(s) = \II$ and $\lh(s)$ is even, then if $\textrm{age}(s) = 0$ or for all $m$, $\textrm{age}(sm) < \textrm{age}(s)$. If $\hat{\ell}(s) = \II$ and $\lh(s)$ is odd then either $\textrm{age}(s) = 0$ or there is $m$ such that $\textrm{age}(sm) < \textrm{age}(s)$.

[This follows directly from the recursive construction step.]

Now define $\hat{Q}_\II \subset Q_\II$ by:
\begin{itemize}
    \item $\emptyset \in \hat{Q}_{\II}$
    \item $sm \in \hat{Q}_\II :\iff \textrm{age}(sm) = 0\textrm{ or }sm \in Q_\II \textrm{ and }\textrm{age}(sm) < \textrm{age}(s)$
\end{itemize}

Informatlly, playing by $\hat{Q}_\II$ means: ``play into positions labelled II reducing the age if you can''.

If $\hat{\ell}(\emptyset) = \II$, then by Subclaim 3 $\hat{Q}_\II$ is a q.s.

\underline{Subclaim 4}: If $\hat{\ell}(\emptyset) = \II$, then $\hat{Q}_\II$ is winning for II: $[\hat{Q}_\II]\cap A = \emptyset$.

[Suppose $x \in [\hat{Q}_\II]$. Consider $a_n \coloneqq \textrm{age}(x\restriction n)$. This is a decreasing sequence of ordinals until it hits 0 by construction of $\hat{Q}_\II$. Since no infinite, strictly decreasing sequence of ordinals exists, we find $k$ such that $a_k = \textrm{age}(x\restriction k) = 0$. This implies $x\restriction k \not \in T$, hence $x\not\in A$.]

This finishes the claim, and hence concludes the entire proof.
\end{proof}

\begin{remark*}
    If $M$ is wellorderable (\it{e.g.} $M = \N$), then GST says that every closed subset of $M^\om$ is determined, and also that every complement of a closed set is determined. [Follows directly from the proof.]
\end{remark*}

Recall our motto/hope from the end of lecture 2: if a set is \it{nice} or \it{simple}, then it is determined. If by `nice' we mean closed, then this is just GST.

\underline{Next goal}: Define a topology on $M^\lom$.

Let's focus on the case $M = \N$, or even $M = 2 = \{0,1\}$.

\begin{defin*}[Baire Space]
    If $x,y \in \om^\om$, we can define
    \begin{align*}
        d(x,y) \coloneqq \left\lbrace \begin{array}{cc} 0\quad & \textrm{ if }x = y\\ 2^{-m} & \quad \textrm{ if }x\restriction m = y\restriction m\textrm{ and }x(m)\ne y(m) \end{array}\right.
    \end{align*}
    which is a metric on $\om^\om$.

    What are the open balls for this metric? Let $\eps = 2^{-n}$:
    \begin{align*}
        B_\eps(x) &= \{y\in \om^\om : d(x,y) < \eps\}\\
        &= \{y; y\restriction (n+1) = x \restriction (n+1)\}
    \end{align*}
    In particular, the open balls are determined by finite sequences.

    If $s \in \om^\om$, write:
    \begin{align*}
        [s]\coloneqq \{x \in \om^\om ;s \subset x\}
    \end{align*}
    So $B_{2^{-n}}(x) = [x\restriction (n+1)]$. Thus the topology of the metric space is generated by the basic open sets $\{[s];s \in \om^\om\}$.

    This topological space on $\om^\om$ is called \undf{Baire space}. If we restrict to $2^\om$, then it is called \undf{Cantor space}.
\end{defin*}

If you think of $\om^\om$ as $$\prod_{i\in \om}Y_i$$ with $Y_i = \om$, and $2^\om$ as $$\prod_{i\in \om}Y_i$$ with $Y_i = 2 = \{0,1\}$, then Baire space is just the product topology on $\prod_{i\in \om}X_i$ with the discrete topology on $\om$, and Cantor space is the product topology on $\prod_{i\in \om}Y_i$ with the discrete topology on 2.

Tychonoff implies that Cantor space is compact, but Baire space is not. Indeed, the latter can even by seen with Tychonoff:
\begin{align*}
    \om^\om = \bigcup_{m\in \om}[<m>]
\end{align*}
Since $[<m>] = \{x;x(0)=m\}$, this union is disjoint so this open cover clearly has no finite subcover, and tells us that Baire space is (very) disconnected.

Next time, we show that $A = [T] \subset \om^\om \iff A$ is closed in Baire space.

\marginpar{Lecture 7}

We now study the Baire space and Cantor space in detail. Firstly, consider convergence:

\begin{align*}
    x_n \ra x &\iff \forall \eps\ \exists N\ \forall x > N\ d(x_n,x) < \eps\\
    &\iff \forall m\ \exists N \ \forall n>N\ d(x_n,x) < 2^{-m} \\
    &\iff \forall m\ \exists N\ \forall n > N\ x_n\restriction m  = x\restriction m
\end{align*}
If $A\subset \om^\om$, we can define
\begin{align*}
    T_A \coloneqq \{x\restriction n; x \in A, n \in \N\}
\end{align*}
\underline{Observe}: $A \subset [T_A]$, since $x \in A \implies x\restriction n \in T_A\textrm{ for all }n\implies x \in [T_A]$.

\begin{remark*}[Proposition]\emph{
$[T_A]$ is the closure of $A$, \it{i.e.} $\{x;\exists(x_n)\textrm{ with }x_n\in A\textrm{ and }x_n\ra x\}$
}
\end{remark*}
\begin{proof}
    Suppose $x_n \in A$ and $x_n\ra x$. By our characterisation of convergence, this means that $x\restriction k = x_n\restriction k$ for some $n$, so $x\restriction k \in T_A$. Since $k$ was arbitrary, we have that $x \in [T_A]$.

    Conversely, suppose that $x \in [T_A]$. For every $k \in \N$, $x\restriction k \in T_A$, so there is some $x_k \in A$ such that $x\restriction k = x_k\restriction k$. Then again by the characterisation of convergence, we have that $x_k \ra x$. So $x$ is in the closure of $A$.
\end{proof}
\begin{remark*}[Corollary]
    $A\subset \om^\om$ is closed $\iff (\exists T)(A = [T])$ (we know that $T\coloneqq T_A$ does it).

    This is sometimes known as the \undf{tree representation theorem for closed sets}.
\end{remark*}

Some more topological properties:

Basic open sets are $[s] = [T_s]$, where $T_s \coloneqq \{t;s\subset t\textrm{ of }t\subset s\}$. So basic open sets are closed; we call these \undf{clopen}. Spaces like this are called \undf{zero-dimensional}

If $x \in \om^\om$, then $\{x\} = [T_x]$, with $T_x \coloneqq \{x\restriction n;n\in \N\}$. So singletons are closed, and not open.

We can easily see that this set is \undf{Hausdorff}: if $x \ne y$, find $n$ such that $x\restriction n \ne y \restriction n$. Then $x \in [x\restriction n]$, $y \in [y\restriction n]$, but $[x\restriction n]\cap[y\restriction n] = \emptyset$.

\underline{Continuous Functions}: [proof on ES\#2] If $g:\om^\lom \ra \om^\lom$ such that:
\begin{enumerate}
    \item $g$ is order-preserving, \it{i.e.} $s\subset t \ra g(s)\subset g(t)$
    \item $g$ is ``unbounded'', \it{i.e.} if $x \in \om^\om$, then $\lh(g(x\restriction n))\ra\infty$
\end{enumerate}
then define $$\hat{g}(x) \coloneqq \bigcup_{n\in \N}g(x\restriction n)$$ which is a function $\om^\om$.

\begin{remark*}[Proposition]
    $f:\om^\om$ is continuous iff there is $g:\om^\lom \ra \om^\lom$ with 1 \& 2 satisfied such that $f = \hat{g}$
\end{remark*}

The \undf{rule of thumb} here is that $f$ is continuous iff in order to determine $f(x)(k)$ you only need $x\restriction n$ for some finite $n$.

Now consider functions from $(\om^\om)^2$ to $\om^\om$ and vice versa and $\om^\om$ to $\om^\om$:
\begin{itemize}
    \item $x \mapsto x_\I$
    \item $x \mapsto x_{\II}$
    \item $(x,y)\mapsto x\ast y$
    \item $x \mapsto (x_\I,x_\II)$
\end{itemize}
These are all continuous. Moreover, we see that $(\om^\om)^2$ and $(\om^\om)$ are homeomorphic by $(x,y)\mapsto x\ast y$ with inverse $x\mapsto (x_\I,x_\II)$. This is unusual, and this phenomenon may explain the name \it{zero-dimensional}. [Similarly, $(\om^\om)^k \cong (\om^\om)^\ell$ for any $k,\ell > 0$]. 

\begin{theorem*}
    Baire space is homeomorphic to $\R\backslash \Q$.
\end{theorem*}
[The proof uses continued fractions: if $x \in \R\backslash \Q$, then there is a sequence $a_i \in \Z^\om$ such that $x = [0;a_0,a_1,a_2,\dots]$.]

So while topologically quite different from $\R$, Baire space is set-theoretically very close to $\R$: many set theoretic properties/proofs depend only on cardinality, and we have only removed a countable (dense) subset.

\begin{remark*}[Example]
    ES\#1 (4) has choice principles $\textrm{AC}_X(Y)$. These are invariant under replacing $X$ or $Y$ with $X',Y'$ such that $X$ is in bijection with $X'$ and $Y$ is in bijection with $Y'$.

    In particular,
    \begin{align*}
        \textrm{AC}_\om(\R) &\iff \ac_\om(\om^\om)\\
        &\iff \ac_\om(2^\om)\\
        &\iff \ac_\om(X)
    \end{align*}
    where $X$ is any set in bijection with $\R$.
\end{remark*}

In set theory, we often refer to elements of $2^\om$ or $\om^\om$ as ``reals'' and abuse the notation by sometimes writing $\R \coloneqq \om^\om$.

We now repeate our motto/hope: if $A$ is ``simple'', then $A$ is determined.

To make precise what `simple' means, we need a complexity hierarchy on Baire space:

\begin{defin*}[Borel Hierarchy]
    Let $X$ be any topological space. We then define \undf{[boldface] sigma zero one} as
    \begin{align*}
        \bm{\Sigma}_{0}^{1}\coloneqq \{A\subset X; A\textrm{ is open in }X\}
    \end{align*}
    Then if $\bm{\Sigma}^0_\alpha$ is defined, we define
    \begin{align*}
        \bm{\Pi}^0_\alpha \coloneqq \{X\backslash A; A \in \bm{\Sigma}^0_\alpha \}
    \end{align*}
    If $\alpha$ is an ordinal and for all $\gamma < \alpha$, $\bopi^0_\gamma$ is defined, then
    \begin{align*}
        \bosig^0_\alpha \coloneqq \{A; \exists (A_n)\textrm{ such that }\forall n\ A_n\in \bigcup_{\gamma<\alpha}\bopi^0_\gamma\textrm{ and }A = \bigcup_{n\in\N}A_n\}
    \end{align*}
    We also have
    \begin{align*}
        \bodel^0_\alpha \coloneqq \bosig^0_\alpha \cap \bopi^0_\alpha
    \end{align*}

    So we get the $\bosig$s from countable unions, and the $\bopi$s from complements.
\end{defin*}

\underline{Properties}: By definition, $\bodel ^0_\alpha \subset \bosig^0_\alpha,\bopi^0_\alpha$.

Moreover, by definition $\alpha \le \beta \implies \bosig^0_\alpha \subset \bosig^0_\beta$. This also gives us that $\bopi^0_\alpha \subset \bopi^0_\beta$.

To see the full structure of the hierarchy, we need to show that for $\alpha < \beta$, $\bopi^0_\alpha \subset \bosig^0_\beta$ (equivalently, $\bosig^0_\alpha \subset \bopi^0_\beta$). This follows from the definition of $\sigma^0_\beta$ by letting $A_n\coloneqq A$, so $\bigcup_{n\in \N}A_n = A$.

\underline{Question}: When does the Borel hierarchy terminate? This will, of course, depend on the topological space.
\end{document}